[
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html",
    "title": "Analysis of double platform data",
    "section": "",
    "text": "Analysis of double platform data\nThese solutions are applicable to both the Distance for Windows and mrds R versions."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#and-2.-estimation-of-p-fi---mr-dist-and-fi---mr-distsizesexexp",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#and-2.-estimation-of-p-fi---mr-dist-and-fi---mr-distsizesexexp",
    "title": "Analysis of double platform data",
    "section": "1. and 2. Estimation of p; FI - MR dist and FI - MR dist+size+sex+exp",
    "text": "1. and 2. Estimation of p; FI - MR dist and FI - MR dist+size+sex+exp\n\nThe model with more covariates is modelling more of the heterogeneity in detection probability and so should be less biased. This seems to be the case: the estimated N for the model “FI – MR dist + size + sex + exp” is closer to truth than the “FI – MR dist” (recall that there were really 760 individual tees).\n\n\nThere is some evidence of unmodelled heterogeneity in both cases (noticeably more so with the ‘FI – MR dist’ in that the fitted detection function for observer 1 declines slower than the histogram as distance increases (Figure 1). This is less the case for the ‘FI – MR dist + size + sex + exp’ model – not surprisingly, because it models the effect of more variables causing the heterogeneity.\n\n\nBoth are still somewhat negatively biased, but the 95% confidence intervals do include the true value1. Both models are reasonable fits to the data (non-significant chi-squares, Cramer-von Mises and KS tests) – although the fit is noticeably worse in the case of the ‘FI – MR dist’ model. The ‘dist + size + sex + exp’ model has a much lower AIC and so is to be preferred on that basis.\n\n\nSpecifying new models\n\n\nI tried two models with interaction terms (although many other models could have been tried) – one with a sex times exposure interaction (‘FI – MR dist + sex x exp’) and one with a three-way interaction between distance, sex and exposure (‘FI – MR dist x sex x exp’). The former had a slightly lower AIC than the model with the 3-way interaction. The estimated N from this model was also closer to truth (Table 1).\n\n\nPoint independence\n\n\nThe point independence model with just Distance in the MR model (‘PI – MR dist DS hn’) had a slightly lower AIC than the corresponding full independence model (‘FI – MR dist’), however, the abundance estimate is much closer to truth (Table 1). We can expect the bias to be smaller for the point independence model because the assumption of independence only on the trackline is weaker than assuming independence everywhere.\n\n\nComparing the previous best FI model (‘FI – MR dist + sex x exp’) with the equivalent PI model with no covariates in the DS part (‘PI – MR dist + sex x exp DS hn’), the former had a lower AIC, and similarly for a model with no interactions in the MR model (model ‘PI – MR dist + sex + exp DS hn’). The difference in bias between FI and PI models is less for these models with more covariates, as there is less unmodelled heterogeneity that can contribute to non-independence away from the trackline (i.e., violation of the independence assumption of the FI model).\n\n\nAdding sex as a covariate into the DS model (‘PI – MR dist + sex + exp DS hn sex’) produced a model with the lowest AIC yet, and also the closest estimate (695) to true N. This model was found to have lowest AIC in a comparison of 40 models in Chapter 6 of Buckland et al. (2004, Table 6.5). The estimate is still less than the true N indicating, perhaps, some unmodelled heterogeneity on the trackline (or perhaps just bad luck – remember that this is only one survey).\n\n\nWas this complex modelling worthwhile? In this case, the estimated p(0) for the best model was 0.96. If we ran a conventional distance sampling analysis (i.e. single platform), pooling the data from the two observers, we should get a very robust estimate of N. We did this in the final analysis in the solutions Distance project (GolfteeSolutions.zip). (To do this, we selected only records where Observer = 1 regardless of whether they were seen by that observer or not – i.e. we use data from both observers combined, who will have a higher p(0) than either of them on their own.) The estimate of N from the CDS analysis is 706 – slightly closer to truth than our best MRDS model. (You can do the same thing in the mrds package in R, by specifying in the ddf function method = “ds”. Once you have a fitted detection function you can then pass this into the dht function to get an abundance estimate. The resulting estimate of abundance of clusters is identical (assuming you used the same half-normal key function we used in the Distance project; the estimate of abundance of individual is slightly different because Distance for Windows uses cluster size regression by default, while ddf does not – feel free to ask about this if you’re interested!)\nTable 1 Summary of the fitted models, AIC and estimated individual abundance, N.\n\n\n\n\nModel name\nAIC\nEstimated N\n\n\n\n\nFI-MR dist\n452.81\n593\n\n\nFI-MR dist + size + sex + exp\n407.40\n642\n\n\nFI-MR dist + sex * exp\n403.80\n682\n\n\nFI-MR dist * sex * exp\n404.46\n679\n\n\nPI-MR dist DS hn\n452.03\n688\n\n\nPI-MR dist + sex * exp DS hn\n406.34\n675\n\n\nPI-MR dist + sex + exp DS hn\n406.04\n666\n\n\nPI-MR dist + sex + exp DS hn sex\n399.26\n695\n\n\n\n\nFigure 1 Fitted detection function using the models ‘FI-MR dist’ (left plot) and ‘FI-MR dist+size+sex+exp’ (right plot).\n\n \nII. Crabeater Seal Survey\nThe solution is divided into Distance in windows and Distance in R section.\nDistance in Windows\n\nThe MCDS goodness-of-fit statistics all indicate adequate fit (none are significant at the 5% level) and the abundance estimate is not far from that for the PI model used in the paper: 3,820 with CI (3,168; 4,606) vs 3,969 with CI (3,274; 4,812) from the MRDS model. Use of an MCDS model results in an estimate only 4% lower than that from the MRDS model and the CVs for the two models are very similar - so the MCDS model seems pretty adequate.\n\n\nWhy is this? It is because the MRDS estimate of p(0) for both platforms combined is 0.988 – i.e. the conventional distance sampling assumption that p(0) is 1 is very nearly satisfied.\n\n\nThe full-independence (FI) MRDS analysis is not adequate. The very poor fit to the combined distance data is clear from the plots headed “Detection Probability 1”, “Detection Probability 2” and “Detection Probability 3”, which show the distribution of Obs1, Obs2 and combined Obs detections, with the Obs 1, Obs 2 and combined detection functions overlaid. It can also be clearly seen from the Q-Q plot and the Kolmogorov-Smirnov goodness-of-fit test statistic.\n\n\nThe plot headed “Detection Probability 4” shows the duplicates and the duplicated detection function. The plots headed “Detection Probability 5” and “Detection Probability 6” are the conditional detection functions for each observer overlaid on the respective duplicate proportions.\n\n\nNotice that the conditional detection function fits are pretty good. So the model seems adequate for modelling the conditional probability of one observer detecting a group, given the other observer detected it, but not for the unconditional probability of detecting a group (which is what we want to estimate). This implies that there is something about detected groups that tends to make them more detectable than other groups (i.e., some unmodelled heterogeneity). So treating the conditional detection functions as if they applied to undetected groups will lead to positive bias in estimating their detection probability and negative bias in estimating abundance.\n\n\nThe severe negative bias in the abundance estimate is apparent from a comparison of the FI and PI estimates: the former is 2,509 with CI (2,070; 3,041), which is substantially lower than even the MCDS estimate, while the latter is 3,969 with CI (3,274; 4,812).\n\n\nNote that PI estimators cannot be lower than the corresponding CDS or MCDS estimators.\n\n\nOne final note: FI abundance estimates will not in general be lower than MCDS estimates, even when the FI assumption fails, as it has here. In particular, when p(0) is low, the FI estimator is likely to be less biased than the MCDS estimator. In this example, p(0) is very close to 1, so the MCDS estimator has small bias.\n\nDistance in R\nFitting a simple MRDS model (i.e. DS half-normal key with MR model distance only) gives an\nMRDS estimate of p(0) for both platforms combined of 0.988. The \\(p(0)\\) for each observer team was 0.89. Note that the estimate is the same for each team because ‘observer’ was not included in the MR model.\nCrabeater seals with MCDS\nThe detection function model with the lowest AIC includes side of plane and visibility – this is the distance sampling model used in (Borchers et al., 2006) and (Southwell et al., 2007).\n\n\n\nFormula\nAIC\n\n\n\n\nNo covars\n22304.01\n\n\nside\n22304.74\n\n\nvis\n22311.34\n\n\nside + vis\n22300.13\n\n\n\nFrom the simple MRDS analyses, we see that the conventional distance sampling assumption, that p(0) is 1, is very nearly satisfied – and so in this case an MCDS analysis may have been adequate. However, a double platform survey and analysis were required to establish this.\nReferences\nBuckland ST, Anderson DR, Burnham KP, Laake JL, Borchers DL and Thomas L (2004) Advanced Distance Sampling. Oxford University Press, UK\nBorchers, D.L., Laake, J.L., Southwell, C. and Paxton, C.G.M. (2006) Accommodating unmodeled heterogeneity in double-observer distance sampling surveys. Biometrics 62: 372-378.\nSouthwell, C., Borchers, D.L., Paxton, C.G.M., Burt, M.L., de la Mare, W. (2007) Estimation of detection probability in aerial surveys of Antarctic pack-ice seals. Journal of Agricultural, Biological & Environmental Statistics 12: 41-54."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#footnotes",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#footnotes",
    "title": "Analysis of double platform data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExcept for the model FI – MR dist fitted in R. The 95% CI are (478 – 736).↩︎"
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html",
    "href": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html",
    "title": "Analysis of double platform data",
    "section": "",
    "text": "Analysis of double platform data\nThis version of the practical is for those who would like to conduct the analysis in Distance (Thomas et al., 2010). There is a separate version for conducting the analysis in R.\nThe first part of this practical involves initial analysis of a survey of a known number of golf tees. This is intended mainly to familiarise you with the analysis features in Distance. We will do this during a short in-class break on the first day of class.\nThe second part of the practical involves more detailed analysis of the golf tee data, and an exploration of the double-platform data structure and project setup.\nThe third part of the practical involves analysis of the pack-ice seal survey data of Borchers et al. (2006) and Southwell et al. (2007)."
  },
  {
    "objectID": "11-mrds/mrdslanding.html",
    "href": "11-mrds/mrdslanding.html",
    "title": "Analysis of double platform data",
    "section": "",
    "text": "Text needed to describe double platform data and analysis."
  },
  {
    "objectID": "11-mrds/mrdslanding.html#analysis-of-point-transect-data",
    "href": "11-mrds/mrdslanding.html#analysis-of-point-transect-data",
    "title": "Analysis of point transect data",
    "section": "",
    "text": "Having mastered analysis of line transect data, we move on to analysis of point transect data. These data are more difficult to model because the region of the curve where we wish to be most precise is the region where data are most scarce.\nAssessing fit to point transect data also represents a challenge. Consequently, we use plots of the probability density function to gain perspective regarding the influence of regions of the probability density function upon lack of fit.\nTwo data sets are to be analysed: the first is a simulated data set in which both the true shape of the detection function as well as true animal density is known. Fit various detection functions to these data, also examining the effect of truncation (truncation for points is often more severe than for lines) upon estimates. Look for congruence in density estimates–as you did with a similar exercise performed on simulated line transect data in Practical 3.\nFinally, there are two optional data sets of winter wrens collected by Prof. Buckland. Same species and study area, but two different field protocols: one protocol used traditional 5-minute counts while the other protocol employed the “snapshot” method."
  },
  {
    "objectID": "11-mrds/mrdslanding.html#lecture-materials",
    "href": "11-mrds/mrdslanding.html#lecture-materials",
    "title": "Analysis of double platform data",
    "section": "Lecture materials",
    "text": "Lecture materials\n\nLecture discussion\n\nSlides Placeholder\n\n\nVideo"
  },
  {
    "objectID": "11-mrds/mrdslanding.html#exercise-materials",
    "href": "11-mrds/mrdslanding.html#exercise-materials",
    "title": "Analysis of double platform data",
    "section": "Exercise materials",
    "text": "Exercise materials\n\n\n\nUsing R package\n\nVideo introduction\n\n\nInstructions\n\n\nSolution and discussion\n\n\nVideo summary\n\n\n\n\nUsing Distance for Windows\n\nVideo introduction\n\n\nInstructions\n\n\nSolution and discussion\n\n\nVideo summary"
  },
  {
    "objectID": "11-mrds/mrdslanding.html#supplemental-materials",
    "href": "11-mrds/mrdslanding.html#supplemental-materials",
    "title": "Analysis of double platform data",
    "section": "Supplemental materials",
    "text": "Supplemental materials\n\nNo supplements\n\nNo supplemental material"
  },
  {
    "objectID": "11-mrds/mrdslanding.html#analysis-of-double-platform-data",
    "href": "11-mrds/mrdslanding.html#analysis-of-double-platform-data",
    "title": "Analysis of double platform data",
    "section": "",
    "text": "Text needed to describe double platform data and analysis."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introductory distance sampling training materials",
    "section": "",
    "text": "This is the landing page for the distance sampling training materials website.\n\nDescribe philosophy of lecture/exercise pairing.\ndifferentiate the two exercise pathways\ndiscuss role of video introduction/summary\nif there are self-assessed tutorials, describe them\n\n\n\n\nOther sundries\n\nmention distancesampling.org\nmention “other workshops” if they exist"
  },
  {
    "objectID": "06-design/R-prac/Pr6-solution.html",
    "href": "06-design/R-prac/Pr6-solution.html",
    "title": "Distance sampling survey design solution",
    "section": "",
    "text": "Solution\n\n\n\nDistance sampling survey design\nlibrary(dssd)\nlibrary(sf)\n\nLinking to GEOS 3.11.2, GDAL 3.7.2, PROJ 9.3.0; sf_use_s2() is TRUE"
  },
  {
    "objectID": "06-design/R-prac/Pr6-solution.html#systematic-parallel-line-design",
    "href": "06-design/R-prac/Pr6-solution.html#systematic-parallel-line-design",
    "title": "Distance sampling survey design solution",
    "section": "Systematic Parallel Line Design",
    "text": "Systematic Parallel Line Design\n\n\n\n\n\n\nAnswers\n\n\n\nWhat spacing would you select for this design? What is the maximum trackline length for the design you have selected? What on-effort line length are we likely to achieve?\n\nThe spacing chosen by dssd of 4937.5m to generate a line length of 200km resulted in a maximum trackline length of around 261km (each exact answer will vary due to the random generate of surveys). If we choose this design then it is possible that when we randomly generate our survey we may not be able to complete it with the effort we have available.\nWe should therefore increase the spacing between the transects and re-run the coverage simulations. A spacing of 5000m gave a maximum trackline length of around 249km (see summary table of Trackline length in the output below) so we can be fairly confident that we will be able to complete any survey which we randomly generate from this design. This spacing should allow us to achieve an on-effort line length of 199km (see Line length section of design summary below). The minimum line length we would expect to achieve is 184km and the maximum is 206km. [Note your values might differ to those below]\n\n\n\n\nshapefile.name &lt;- system.file(\"extdata\", \"StAndrew.shp\", package = \"dssd\")\nregion.sab &lt;- make.region(region.name = \"St Andrews Bay\",\n                      units = \"m\",\n                      shape = shapefile.name)\ncover.sabay &lt;- make.coverage(region.sab, n.grid.points = 5000)\ndesign.spacing5km &lt;- make.design(region = region.sab,\n                      transect.type = \"line\",\n                      design = \"systematic\",\n                      spacing = 5000,\n                      design.angle = 90,\n                      edge.protocol = \"minus\",\n                      truncation = 2000,\n                      coverage.grid = cover.sabay)\n\n\ndesign.spacing5km &lt;- run.coverage(design.spacing5km, reps = 250, quiet=TRUE)\nplot(design.spacing5km)\n\n\n\n\nCoverage grid plot for parallel design of St Andrews Bay.\n\n\n\n\n\nprint(design.spacing5km)\n\n\n   Strata St Andrews Bay:\n   _______________________\nDesign:  systematically spaced transects\nSpacing:  5000\nNumber of samplers:  NA\nLine length: NA\nDesign angle:  90\nEdge protocol:  minus\n\nStrata areas:  987500079\nRegion and effort units:  m\nCoverage Simulation repetitions:  250\n\n    Number of samplers:\n    \n        St Andrews Bay Total\nMinimum            7.0   7.0\nMean               7.9   7.9\nMedian             8.0   8.0\nMaximum            8.0   8.0\nsd                 0.3   0.3\n\n    Covered area:\n    \n        St Andrews Bay     Total\nMinimum      725982044 725982044\nMean         759231567 759231567\nMedian       764780347 764780347\nMaximum      778546882 778546882\nsd            16170884  16170884\n\n    % of region covered:\n    \n        St Andrews Bay Total\nMinimum          73.52 73.52\nMean             76.88 76.88\nMedian           77.45 77.45\nMaximum          78.84 78.84\nsd                1.64  1.64\n\n    Line length:\n    \n        St Andrews Bay     Total\nMinimum      184431.70 184431.70\nMean         196795.32 196795.32\nMedian       198623.58 198623.58\nMaximum      205775.31 205775.31\nsd             6086.97   6086.97\n\n    Trackline length:\n    \n        St Andrews Bay     Total\nMinimum      220527.75 220527.75\nMean         241232.76 241232.76\nMedian       246034.37 246034.37\nMaximum      248799.88 248799.88\nsd             8746.43   8746.43\n\n    Cyclic trackline length:\n    \n        St Andrews Bay     Total\nMinimum      251938.09 251938.09\nMean         277825.47 277825.47\nMedian       283385.93 283385.93\nMaximum      285986.27 285986.27\nsd            10318.27  10318.27\n\n    Coverage Score Summary:\n    \n        St Andrews Bay     Total\nMinimum      0.2840000 0.2840000\nMean         0.7688187 0.7688187\nMedian       0.7840000 0.7840000\nMaximum      0.8920000 0.8920000\nsd           0.1018173 0.1018173"
  },
  {
    "objectID": "06-design/R-prac/Pr6-solution.html#equal-spaced-zigzag-design",
    "href": "06-design/R-prac/Pr6-solution.html#equal-spaced-zigzag-design",
    "title": "Distance sampling survey design solution",
    "section": "Equal Spaced Zigzag Design",
    "text": "Equal Spaced Zigzag Design\n\n\n\n\n\n\nAnswers\n\n\n\nDoes this design meet our survey effort constraint? What is the maximum total trackline length for this design? What line length are we likely to achieve with this design? Is this higher or lower than the systematic parallel design?\n\nYou were asked to then run a coverage simulation and check if the trackline length was within our effort constraints. I found the maximum trackline length to be 242km (see Trackline length summary table in the output below) so within our constraint of 250km. I then got a mean line length of 221km and minimum and maximum line lengths of 212km and 227km, respectively (see Line length summary table in the output below). We can therefore expect to achieve just over 20km more on-effort survey line length with the zigzag design than the systematic parallel line design - 10% gain. [Note your values may differ]\n\n\n\n\ndesign.zz.4500 &lt;- make.design(region = region.sab,\n                      transect.type = \"line\",\n                      design = \"eszigzag\",\n                      spacing = 4500,\n                      design.angle = 0,\n                      edge.protocol = \"minus\",\n                      bounding.shape = \"convex.hull\",\n                      truncation = 2000,\n                      coverage.grid = cover.sabay)\n\n\ndesign.zz.4500 &lt;- run.coverage(design.zz.4500, reps = 250, quiet=TRUE)\nplot(design.zz.4500)\n\n\n\n\nCoverage grid plot for zigzag design of St Andrews Bay.\n\n\n\n\n\n\n\n\n\n\nAnswers\n\n\n\nDo you think the coverage scores look uniform across the study region? Where are they higher/lower? Why do you think this is?\n\nYou were finally asked to look at the coverage scores across the survey region to see if this design has even coverage. There are some points with lower coverage around the survey region boundary. This is actually down to the fact we are using a minus sampling strategy. If we plotted coverage scores from a systematic parallel design we would see a similar pattern.\nUsually edge effects from minus sampling are minor unless we have a very long survey region boundary containing a small study area. If using a zigzag design was causing us issues with coverage we would expect to see higher coverage at the very top or very bottom of the survey region (as our design angle is 0). We do not see this. The survey region boundaries at the top and bottom are both quite wide and perpendicular to the design angle, in this situation zigzag designs perform well with regard to even coverage."
  },
  {
    "objectID": "06-design/R-prac/Pr6-solution.html#coverage",
    "href": "06-design/R-prac/Pr6-solution.html#coverage",
    "title": "Distance sampling survey design solution",
    "section": "Coverage",
    "text": "Coverage\nOrganise the study area shape file.\n\nshapefile.name &lt;- system.file(\"extdata\", \"TentsmuirUnproj.shp\", \n                              package = \"dssd\")\nsf.shape &lt;- read_sf(shapefile.name)\nst_crs(sf.shape)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\nproj4string &lt;- \"+proj=aea +lat_1=56 +lat_2=62 +lat_0=50 +lon_0=-3 +x_0=0 \n                +y_0=0 +ellps=intl +units=m\"\nprojected.shape &lt;- st_transform(sf.shape, crs = proj4string)\nregion.tm &lt;- make.region(region.name = \"Tentsmuir\",\n                         strata.name = c(\"Main Area\", \"Morton Lochs\"),\n                         shape = projected.shape)\n\nCreate the coverage grid.\n\ncover.tm &lt;- make.coverage(region.tm, n.grid.points = 5000)\ndesign.tm &lt;- make.design(region = region.tm,\n                         transect.type = \"point\",\n                         design = \"systematic\",\n                         samplers = c(25,15),\n                         design.angle = 0,\n                         edge.protocol = \"minus\",\n                         truncation = 100,\n                         coverage.grid = cover.tm)\nsurvey.tentsmuir &lt;- generate.transects(design.tm)\n\n\nprint(survey.tentsmuir)\n\n\n   Strata Main Area:\n   __________________\nDesign:  systematically spaced transects\nSpacing:  751.2295\nNumber of samplers:  25\nDesign angle:  0\nEdge protocol:  minus\nCovered area:  770153.4\nStrata coverage: 5.46%\nStrata area:  14108643\n\n   Strata Morton Lochs:\n   _____________________\nDesign:  systematically spaced transects\nSpacing:  218.3674\nNumber of samplers:  15\nDesign angle:  0\nEdge protocol:  minus\nCovered area:  400055.4\nStrata coverage: 55.93%\nStrata area:  715264.9\n\n   Study Area Totals:\n   _________________\nNumber of samplers:  40\nCovered area:  1170209\nAverage coverage: 7.89%\n\n\n\n\n\n\n\n\nAnswers\n\n\n\nWhat spacing was used in each strata to try and achieve the desired number of samplers? Did your survey achieve exactly the number of samplers you requested? How much does coverage differ between the two strata for this realisation?\n\nA spacing of 751m was used in the main stratum and 218m in the Morton Lochs stratum - these values are calculated based on the stratum areas and should not vary between surveys generated from the same design. You may or may not have achieved the number of transects you requested, this will depend on the random start point calculated for your particular survey. There will also be some variability in coverage, my survey achieved a coverage of 5.7% in the main strata and 64.8% in the Morton Loch strata.\n\n\n\n\ncoverage.tentsmuir &lt;- run.coverage(design.tm, reps=250, quiet=TRUE)\nprint(coverage.tentsmuir)\n\n\n   Strata Main Area:\n   __________________\nDesign:  systematically spaced transects\nSpacing:  NA\nNumber of samplers:  25\nDesign angle:  0\nEdge protocol:  minus\n\n   Strata Morton Lochs:\n   _____________________\nDesign:  systematically spaced transects\nSpacing:  NA\nNumber of samplers:  15\nDesign angle:  0\nEdge protocol:  minus\n\nStrata areas:  14108643, 715265\nRegion units:  m\nCoverage Simulation repetitions:  250\n\n    Number of samplers:\n    \n        Main Area Morton Lochs Total\nMinimum      22.0         12.0  36.0\nMean         25.1         15.1  40.1\nMedian       25.0         15.0  40.0\nMaximum      27.0         18.0  44.0\nsd            1.0          1.2   1.5\n\n    Covered area:\n    \n        Main Area Morton Lochs      Total\nMinimum 681409.55    349298.47 1072694.57\nMean    767315.09    417165.15 1184480.24\nMedian  771079.37    416627.95 1187341.50\nMaximum 821793.16    467418.16 1273216.18\nsd       28279.26     26120.83   37387.98\n\n    % of region covered:\n    \n        Main Area Morton Lochs Total\nMinimum      4.83        48.83  7.24\nMean         5.44        58.32  7.99\nMedian       5.47        58.25  8.01\nMaximum      5.82        65.35  8.59\nsd           0.20         3.65  0.25\n\n    Coverage Score Summary:\n    \n         Main Area Morton Lochs      Total\nMinimum 0.00800000    0.2400000 0.00800000\nMean    0.05436402    0.5864333 0.07991357\nMedian  0.05200000    0.6320000 0.05600000\nMaximum 0.10000000    0.7080000 0.70800000\nsd      0.01286584    0.1101823 0.11697079\n\n\n\n\n\n\n\n\nAnswers\n\n\n\nView the design statistics. What is the minimum number of samplers you will achieve in each strata? Is this sufficient to complete separate analyses in each stratum?\n\nMy design statistics indicated I should achieve between 22 and 27 transects in the main stratum and between 12 and 18 in the Morton Lochs stratum. I might be a bit concerned about the possibility of only achieving 12 transects in the Morton Lochs stratum (remember I cannot just discard a survey due to the number of transects and generate another as it will affect my coverage properties).\nWhether this is sufficient will depend on a number of things such as a) objectives of the study, b) number of detections per transect etc. Information from a pilot study would be useful to help decide how many transects are required as a minimum.\n\n\n\n\nplot(coverage.tentsmuir, strata=1)\nplot(coverage.tentsmuir, strata=2)\n\n\n\n\n\n\nCoverage scores main stratum Tentsmuir Forest.\n\n\n\n\n\n\n\nCoverage scores Morton Lochs stratum Tentsmuir Forest.\n\n\n\n\n\n\n\n\n\n\n\n\nAnswers\n\n\n\nDoes it appear that you that there is even coverage within strata?\n\nThe main strata looks to have fairly uniform coverage. The values appear to have such small levels of variability that the variability that is seen will be down to stochasticity as it is seen across the entire strata. The Morton Lochs strata we can see has areas of lower coverage around the edge of the study region. This grid is a bit too coarse to allow us to properly judge how much of an issue edge effects will be in this strata. It may be wise to re-run the coverage simulation with a finer coverage grid and more repetitions too. Edge effects could potentially be problematic in such small areas."
  },
  {
    "objectID": "06-design/designlanding.html",
    "href": "06-design/designlanding.html",
    "title": "Design of distance sampling surveys",
    "section": "",
    "text": "Fundamental to safely making inference from transects you surveyed to the entire study area is a sound survey design that includes random allocation of survey effort.\nIt is actually difficult for humans to do things that are actually random. Computerised methods make the process reasonably straightforward. Employing a randomised sampling design derived with our software, means there is one less threat to the validity of your survey.\nYou have the opportunity to use shape files from two locations near St Andrews, one marine and one terrestrial, to design surveys. The marine study will use aircraft so considerations such as fuel load add “incentives” to produce the optimal survey design while allowing the aircraft to return safely to land. The terrestrial study deploys point transects into strata of a natural area."
  },
  {
    "objectID": "06-design/designlanding.html#distance-sampling-survey-design",
    "href": "06-design/designlanding.html#distance-sampling-survey-design",
    "title": "Design of distance sampling surveys",
    "section": "",
    "text": "Fundamental to safely making inference from transects you surveyed to the entire study area is a sound survey design that includes random allocation of survey effort.\nIt is actually difficult for humans to do things that are actually random. Computerised methods make the process reasonably straightforward. Employing a randomised sampling design derived with our software, means there is one less threat to the validity of your survey.\nYou have the opportunity to use shape files from two locations near St Andrews, one marine and one terrestrial, to design surveys. The marine study will use aircraft so considerations such as fuel load add “incentives” to produce the optimal survey design while allowing the aircraft to return safely to land. The terrestrial study deploys point transects into strata of a natural area."
  },
  {
    "objectID": "06-design/designlanding.html#lecture-materials",
    "href": "06-design/designlanding.html#lecture-materials",
    "title": "Design of distance sampling surveys",
    "section": "Lecture materials",
    "text": "Lecture materials\n\nLecture discussion\n\nSlides\n\n\nVideo"
  },
  {
    "objectID": "06-design/designlanding.html#exercise-materials",
    "href": "06-design/designlanding.html#exercise-materials",
    "title": "Design of distance sampling surveys",
    "section": "Exercise materials",
    "text": "Exercise materials\n\n\n\nUsing R package\n\nVideo introduction\n\n\nInstructions\n\n\nSolution and discussion\n\n\nVideo summary\n\n\n\n\nUsing Distance for Windows\n\nVideo introduction\n\n\nInstructions\n\n\nSolution and discussion\n\n\nVideo summary"
  },
  {
    "objectID": "06-design/designlanding.html#supplemental-materials",
    "href": "06-design/designlanding.html#supplemental-materials",
    "title": "Design of distance sampling surveys",
    "section": "Supplemental materials",
    "text": "Supplemental materials\n\nNo supplements\n\nNo supplemental material"
  },
  {
    "objectID": "06-design/R-prac/Prac6_solution.html",
    "href": "06-design/R-prac/Prac6_solution.html",
    "title": "Distance sampling survey design solution",
    "section": "",
    "text": "Solution\n\n\n\nDistance sampling survey design\nlibrary(dssd)\nlibrary(sf)\n\nLinking to GEOS 3.11.2, GDAL 3.7.2, PROJ 9.3.0; sf_use_s2() is TRUE"
  },
  {
    "objectID": "06-design/R-prac/Prac6_solution.html#systematic-parallel-line-design",
    "href": "06-design/R-prac/Prac6_solution.html#systematic-parallel-line-design",
    "title": "Distance sampling survey design solution",
    "section": "Systematic Parallel Line Design",
    "text": "Systematic Parallel Line Design\n\n\n\n\n\n\nAnswers\n\n\n\nWhat spacing would you select for this design? What is the maximum trackline length for the design you have selected? What on-effort line length are we likely to achieve?\n\nThe spacing chosen by dssd of 4937.5m to generate a line length of 200km resulted in a maximum trackline length of around 261km (each exact answer will vary due to the random generate of surveys). If we choose this design then it is possible that when we randomly generate our survey we may not be able to complete it with the effort we have available.\nWe should therefore increase the spacing between the transects and re-run the coverage simulations. A spacing of 5000m gave a maximum trackline length of around 249km (see summary table of Trackline length in the output below) so we can be fairly confident that we will be able to complete any survey which we randomly generate from this design. This spacing should allow us to achieve an on-effort line length of 199km (see Line length section of design summary below). The minimum line length we would expect to achieve is 184km and the maximum is 206km. [Note your values might differ to those below]\n\n\n\n\nshapefile.name &lt;- system.file(\"extdata\", \"StAndrew.shp\", package = \"dssd\")\nregion.sab &lt;- make.region(region.name = \"St Andrews Bay\",\n                      units = \"m\",\n                      shape = shapefile.name)\ncover.sabay &lt;- make.coverage(region.sab, n.grid.points = 5000)\ndesign.spacing5km &lt;- make.design(region = region.sab,\n                      transect.type = \"line\",\n                      design = \"systematic\",\n                      spacing = 5000,\n                      design.angle = 90,\n                      edge.protocol = \"minus\",\n                      truncation = 2000,\n                      coverage.grid = cover.sabay)\n\n\ndesign.spacing5km &lt;- run.coverage(design.spacing5km, reps = 250, quiet=TRUE)\nplot(design.spacing5km)\n\n\n\n\nCoverage grid plot for parallel design of St Andrews Bay.\n\n\n\n\n\nprint(design.spacing5km)\n\n\n   Strata St Andrews Bay:\n   _______________________\nDesign:  systematically spaced transects\nSpacing:  5000\nNumber of samplers:  NA\nLine length: NA\nDesign angle:  90\nEdge protocol:  minus\n\nStrata areas:  987500079\nRegion and effort units:  m\nCoverage Simulation repetitions:  250\n\n    Number of samplers:\n    \n        St Andrews Bay Total\nMinimum            7.0   7.0\nMean               7.9   7.9\nMedian             8.0   8.0\nMaximum            8.0   8.0\nsd                 0.3   0.3\n\n    Covered area:\n    \n        St Andrews Bay     Total\nMinimum      726125908 726125908\nMean         761432936 761432936\nMedian       766769291 766769291\nMaximum      778631483 778631483\nsd            15505089  15505089\n\n    % of region covered:\n    \n        St Andrews Bay Total\nMinimum          73.53 73.53\nMean             77.11 77.11\nMedian           77.65 77.65\nMaximum          78.85 78.85\nsd                1.57  1.57\n\n    Line length:\n    \n        St Andrews Bay     Total\nMinimum      184453.01 184453.01\nMean         197574.82 197574.82\nMedian       198871.13 198871.13\nMaximum      205759.53 205759.53\nsd             5930.42   5930.42\n\n    Trackline length:\n    \n        St Andrews Bay     Total\nMinimum      220537.18 220537.18\nMean         242674.25 242674.25\nMedian       246252.64 246252.64\nMaximum      248796.41 248796.41\nsd             8043.62   8043.62\n\n    Cyclic trackline length:\n    \n        St Andrews Bay     Total\nMinimum      251955.22 251955.22\nMean         279459.39 279459.39\nMedian       283736.35 283736.35\nMaximum      285982.81 285982.81\nsd             9424.41   9424.41\n\n    Coverage Score Summary:\n    \n        St Andrews Bay      Total\nMinimum     0.37600000 0.37600000\nMean        0.77097239 0.77097239\nMedian      0.80000000 0.80000000\nMaximum     0.84000000 0.84000000\nsd          0.08634565 0.08634565"
  },
  {
    "objectID": "06-design/R-prac/Prac6_solution.html#equal-spaced-zigzag-design",
    "href": "06-design/R-prac/Prac6_solution.html#equal-spaced-zigzag-design",
    "title": "Distance sampling survey design solution",
    "section": "Equal Spaced Zigzag Design",
    "text": "Equal Spaced Zigzag Design\n\n\n\n\n\n\nAnswers\n\n\n\nDoes this design meet our survey effort constraint? What is the maximum total trackline length for this design? What line length are we likely to achieve with this design? Is this higher or lower than the systematic parallel design?\n\nYou were asked to then run a coverage simulation and check if the trackline length was within our effort constraints. I found the maximum trackline length to be 242km (see Trackline length summary table in the output below) so within our constraint of 250km. I then got a mean line length of 221km and minimum and maximum line lengths of 212km and 227km, respectively (see Line length summary table in the output below). We can therefore expect to achieve just over 20km more on-effort survey line length with the zigzag design than the systematic parallel line design - 10% gain. [Note your values may differ]\n\n\n\n\ndesign.zz.4500 &lt;- make.design(region = region.sab,\n                      transect.type = \"line\",\n                      design = \"eszigzag\",\n                      spacing = 4500,\n                      design.angle = 0,\n                      edge.protocol = \"minus\",\n                      bounding.shape = \"convex.hull\",\n                      truncation = 2000,\n                      coverage.grid = cover.sabay)\n\n\ndesign.zz.4500 &lt;- run.coverage(design.zz.4500, reps = 250, quiet=TRUE)\nplot(design.zz.4500)\n\n\n\n\nCoverage grid plot for zigzag design of St Andrews Bay.\n\n\n\n\n\n\n\n\n\n\nAnswers\n\n\n\nDo you think the coverage scores look uniform across the study region? Where are they higher/lower? Why do you think this is?\n\nYou were finally asked to look at the coverage scores across the survey region to see if this design has even coverage. There are some points with lower coverage around the survey region boundary. This is actually down to the fact we are using a minus sampling strategy. If we plotted coverage scores from a systematic parallel design we would see a similar pattern.\nUsually edge effects from minus sampling are minor unless we have a very long survey region boundary containing a small study area. If using a zigzag design was causing us issues with coverage we would expect to see higher coverage at the very top or very bottom of the survey region (as our design angle is 0). We do not see this. The survey region boundaries at the top and bottom are both quite wide and perpendicular to the design angle, in this situation zigzag designs perform well with regard to even coverage."
  },
  {
    "objectID": "06-design/R-prac/Prac6_solution.html#coverage",
    "href": "06-design/R-prac/Prac6_solution.html#coverage",
    "title": "Distance sampling survey design solution",
    "section": "Coverage",
    "text": "Coverage\nOrganise the study area shape file.\n\nshapefile.name &lt;- system.file(\"extdata\", \"TentsmuirUnproj.shp\", \n                              package = \"dssd\")\nsf.shape &lt;- read_sf(shapefile.name)\nst_crs(sf.shape)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\nproj4string &lt;- \"+proj=aea +lat_1=56 +lat_2=62 +lat_0=50 +lon_0=-3 +x_0=0 \n                +y_0=0 +ellps=intl +units=m\"\nprojected.shape &lt;- st_transform(sf.shape, crs = proj4string)\nregion.tm &lt;- make.region(region.name = \"Tentsmuir\",\n                         strata.name = c(\"Main Area\", \"Morton Lochs\"),\n                         shape = projected.shape)\n\nCreate the coverage grid.\n\ncover.tm &lt;- make.coverage(region.tm, n.grid.points = 5000)\ndesign.tm &lt;- make.design(region = region.tm,\n                         transect.type = \"point\",\n                         design = \"systematic\",\n                         samplers = c(25,15),\n                         design.angle = 0,\n                         edge.protocol = \"minus\",\n                         truncation = 100,\n                         coverage.grid = cover.tm)\nsurvey.tentsmuir &lt;- generate.transects(design.tm)\n\n\nprint(survey.tentsmuir)\n\n\n   Strata Main Area:\n   __________________\nDesign:  systematically spaced transects\nSpacing:  751.2295\nNumber of samplers:  23\nDesign angle:  0\nEdge protocol:  minus\nCovered area:  722236.2\nStrata coverage: 5.12%\nStrata area:  14108643\n\n   Strata Morton Lochs:\n   _____________________\nDesign:  systematically spaced transects\nSpacing:  218.3674\nNumber of samplers:  16\nDesign angle:  0\nEdge protocol:  minus\nCovered area:  459910\nStrata coverage: 64.3%\nStrata area:  715264.9\n\n   Study Area Totals:\n   _________________\nNumber of samplers:  39\nCovered area:  1182146\nAverage coverage: 7.97%\n\n\n\n\n\n\n\n\nAnswers\n\n\n\nWhat spacing was used in each strata to try and achieve the desired number of samplers? Did your survey achieve exactly the number of samplers you requested? How much does coverage differ between the two strata for this realisation?\n\nA spacing of 751m was used in the main stratum and 218m in the Morton Lochs stratum - these values are calculated based on the stratum areas and should not vary between surveys generated from the same design. You may or may not have achieved the number of transects you requested, this will depend on the random start point calculated for your particular survey. There will also be some variability in coverage, my survey achieved a coverage of 5.7% in the main strata and 64.8% in the Morton Loch strata.\n\n\n\n\ncoverage.tentsmuir &lt;- run.coverage(design.tm, reps=250, quiet=TRUE)\nprint(coverage.tentsmuir)\n\n\n   Strata Main Area:\n   __________________\nDesign:  systematically spaced transects\nSpacing:  NA\nNumber of samplers:  25\nDesign angle:  0\nEdge protocol:  minus\n\n   Strata Morton Lochs:\n   _____________________\nDesign:  systematically spaced transects\nSpacing:  NA\nNumber of samplers:  15\nDesign angle:  0\nEdge protocol:  minus\n\nStrata areas:  14108643, 715265\nRegion units:  m\nCoverage Simulation repetitions:  250\n\n    Number of samplers:\n    \n        Main Area Morton Lochs Total\nMinimum      23.0         12.0  36.0\nMean         25.2         14.9  40.1\nMedian       25.0         15.0  40.0\nMaximum      27.0         18.0  44.0\nsd            1.0          1.1   1.5\n\n    Covered area:\n    \n        Main Area Morton Lochs     Total\nMinimum 689091.57    347637.32 1053462.8\nMean    770183.06    412775.77 1182958.8\nMedian  774499.08    411380.70 1186411.4\nMaximum 820781.44    468079.63 1272770.3\nsd       28098.82     24703.41   39292.3\n\n    % of region covered:\n    \n        Main Area Morton Lochs Total\nMinimum      4.88        48.60  7.11\nMean         5.46        57.71  7.98\nMedian       5.49        57.51  8.00\nMaximum      5.82        65.44  8.59\nsd           0.20         3.45  0.27\n\n    Coverage Score Summary:\n    \n         Main Area Morton Lochs      Total\nMinimum 0.00000000    0.2160000 0.00000000\nMean    0.05463220    0.5793000 0.07982633\nMedian  0.05400000    0.6280000 0.05600000\nMaximum 0.10800000    0.7080000 0.70800000\nsd      0.01876262    0.1150379 0.11642338\n\n\n\n\n\n\n\n\nAnswers\n\n\n\nView the design statistics. What is the minimum number of samplers you will achieve in each strata? Is this sufficient to complete separate analyses in each stratum?\n\nMy design statistics indicated I should achieve between 22 and 27 transects in the main stratum and between 12 and 18 in the Morton Lochs stratum. I might be a bit concerned about the possibility of only achieving 12 transects in the Morton Lochs stratum (remember I cannot just discard a survey due to the number of transects and generate another as it will affect my coverage properties).\nWhether this is sufficient will depend on a number of things such as a) objectives of the study, b) number of detections per transect etc. Information from a pilot study would be useful to help decide how many transects are required as a minimum.\n\n\n\n\nplot(coverage.tentsmuir, strata=1)\nplot(coverage.tentsmuir, strata=2)\n\n\n\n\n\n\nCoverage scores main stratum Tentsmuir Forest.\n\n\n\n\n\n\n\nCoverage scores Morton Lochs stratum Tentsmuir Forest.\n\n\n\n\n\n\n\n\n\n\n\n\nAnswers\n\n\n\nDoes it appear that you that there is even coverage within strata?\n\nThe main strata looks to have fairly uniform coverage. The values appear to have such small levels of variability that the variability that is seen will be down to stochasticity as it is seen across the entire strata. The Morton Lochs strata we can see has areas of lower coverage around the edge of the study region. This grid is a bit too coarse to allow us to properly judge how much of an issue edge effects will be in this strata. It may be wise to re-run the coverage simulation with a finer coverage grid and more repetitions too. Edge effects could potentially be problematic in such small areas."
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html",
    "title": "Design of distance sampling surveys",
    "section": "",
    "text": "Design of distance sampling surveys"
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#reviewing-the-data",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#reviewing-the-data",
    "title": "Design of distance sampling surveys",
    "section": "Reviewing the data",
    "text": "Reviewing the data\n Open the project archived in StAndrews.zip. This project contains the survey region for an aerial survey of porpoise, common dolphins and seals in and around St Andrews bay. (For locals: the nearer St Andrews bay region has been extended in an easterly direction out past Bell Rock, as there are some pockets of deeper water out there that are of interest with regard to the distribution of cetaceans. The survey region has a chunk missing due to a no-fly zone around Buddo Ness, just below Carnoustie). To take a look at the survey region create a new map in the Maps tab and add the layer StAndrews to the map.\nThe small survey plane permits a total flight time of approximately 250 km (excluding the flight time to and from the landing strip in Fife Ness, just down the coast). A systematic line sampling design is going to be used. The design should maximise the amount of on effort surveying time whilst ensuring that the constraint of 250 km total effort (including off effort transit time between sampler lines) is achieved. The aim of this exercise, therefore, is to decide on a systematic line spacing that gives about 200 km on-effort trackline with the total trackline length constrained to 250 km. To do this create a number of systematic line sampling designs with different line spacings, generate the design statistics for these designs and then the statistics for the total trackline length to the on-effort trackline length for different designs.\nBefore proceeding to the design stage you need to generate a coverage grid layer, as this will be needed to generate design statistics."
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#generate-a-coverage-grid-layer",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#generate-a-coverage-grid-layer",
    "title": "Design of distance sampling surveys",
    "section": "Generate a coverage grid layer",
    "text": "Generate a coverage grid layer\nTo generate a coverage grid layer click on the Data tab of the Project Browser and then the Create New Data Layer button (5th from left). Enter “Grid5” as your Layer Name and set the Parent Layer to “StAndrews” and the Layer Type to “Coverage”. You should now be able to click on the Properties… button. In the Grid Properties that pops up set the “Distance between grid points” to 5 and the “Units of distance” to “Kilometre”. (This is too far apart for estimating probabiltiy of coverage, but we know coverage is even for this design, so choosing a wide spacing makes the simulations run faster.) Once you press OK you should proceed to add the grid points to the layer. This may take a few moments.\nNow create and generate a couple of designs with a spacing of your choice (some suggested spacings include 4.5, 5, 5.5 and 6 km)"
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#creating-a-new-design",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#creating-a-new-design",
    "title": "Design of distance sampling surveys",
    "section": "Creating a new design",
    "text": "Creating a new design\nClick on the Designs tab of the Project Browser and then the New Design button. Rename your “New Design” something like “systematic line test” and then click the Show Details button to open the Design Details window. Select the “Line” sampler and set the design class to “Systematic Random Sampling”. Click the Properties button to set the following properties for this design:\n\nOn the General Properties tab under Stratum layer, the StAndrews stratum layer should be selected. Under Design coordinate system, the design coordinate system should be “Non-earth referenced”. (The data have already been projected from the OSGB 1936 geo-coordinate system using the transverse mercator projection)\nIn the Effort Allocation tab, under Edge Sampling select the “Minus” option. In the “Allocation by stratum” section set the Line length units to be Kilometres. Make sure the “Update effort in real time” check box is ticked. As there is only one survey stratum it does not matter whether the “Same effort for all strata” check box is ticked or not. Click the “Systematic line spacing” radio button and enter the line spacing in the “Spacing” column of the table. When you enter a 5 km spacing for instance the “Length” column should then read 226.203 and the “Samplers” column 8. The accuracy of this approximation of on-effort line length and total number of line samplers depends on the shape of the survey region, but should at least give you some indication of what to expect.\nIn the Sampler tab, select Kilometre for the line sampler width units. Set the truncation width to 2 km.\nLastly, in the Coverage Probability tab, click on “Estimate by simulation” and enter 100 as the number of simulations. This is too few to give accurate coverage probabilities, but sufficient for the on-effort and total trackline length statistics. Under grid layer, choose previously created “Grid 5”. Make sure the Grid field name is the same as your design name.\n\nClick OK to close the Design Properties window and return to the design details."
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#design-statistics",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#design-statistics",
    "title": "Design of distance sampling surveys",
    "section": "Design statistics",
    "text": "Design statistics\nFor each design run Distance generates multiple simulated surveys and uses these to work out the statistics for on-effort and total trackline length. Run your designs and in the Design Details Results tab that opens review the statistics to decide on suitable systematic line spacing."
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#automated-generation-of-new-surveys",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#automated-generation-of-new-surveys",
    "title": "Design of distance sampling surveys",
    "section": "Automated generation of new surveys",
    "text": "Automated generation of new surveys\nTo see an example survey, go back to the Design Details window for your selected design click Run again this time choosing the “Generate a new Survey” option. The second page of the survey results displays a map of the survey region with the systematic lines superimposed. You can add this map to the Map browser and manipulate it there by clicking on the 6th button on the Survey map results page."
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-solution-DistWin.html",
    "href": "06-design/DistWin-prac/Pr6-solution-DistWin.html",
    "title": "Design of distance sampling surveys",
    "section": "",
    "text": "Design of distance sampling surveys"
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-solution-DistWin.html#systematic-parallel-line-aerial-survey-of-marine-mammals-in-st-andrews-bay",
    "href": "06-design/DistWin-prac/Pr6-solution-DistWin.html#systematic-parallel-line-aerial-survey-of-marine-mammals-in-st-andrews-bay",
    "title": "Design of distance sampling surveys",
    "section": "Systematic parallel line aerial survey of marine mammals in St Andrews bay",
    "text": "Systematic parallel line aerial survey of marine mammals in St Andrews bay\nI derived the following results (yours will be slightly different because the survey locations in each simulation are selected at random). See also the project archived in StAndrewsSolutions.zip\n\n\n\n\n\n\n\n\n\n\n\n\nTrackline spacing\nOn effort trackline length (min)\nmax\nmean\nTotal trackline length (min)\nmax\nmean\n\n\n\n\n4.5\n206.6\n228.8\n219.6\n249.3\n275.3\n264.7\n\n\n5.0\n184.4\n205.6\n198.2\n220.5\n248.8\n242.5\n\n\n5.5\n169.7\n189.5\n178.9\n217.1\n245.3\n224.7\n\n\n6.0\n152.8\n176.1\n162.1\n183.7\n220.7\n206.1\n\n\n\nBased on these, the 5.0km spacing seems to get us closest to our goal of 200km on effort for 250km total trackline length. The maximum total trackline length did not exceed 250km which is re-assuring if this is an absolute upper limit.\nI generated one realization of this 5km design, which we will use as the survey plan. It gave me a total trackline of 226.2km, with 184.6km on effort (see StAndrewsSolutions.zip project file). While this is rather less than I wanted, I can not validly throw this one away and generate another as we could no longer validly claim to have a random start point (I would effectively only be choosing start points that lead to the amount of trackline length I want) and so would no longer have even coverage probability.\nAs an aside, it is also interesting to look at the proportion of the total survey time spent on effort – reported in Distance as the proportion on effort/total effort:\n\n\n\nTrackline spacing\nMean on effort / total effort\n\n\n\n\n4.5\n0.83\n\n\n5.0\n0.82\n\n\n5.5\n0.80\n\n\n6.0\n0.78\n\n\n\nNot surprisingly, the greater the spacing between tracklines, the smaller the proportion of time we spend on effort as we have to spend time flying between the transect lines."
  },
  {
    "objectID": "07-stratify/DistWin-prac/Pr7-instructions-DistWin.html",
    "href": "07-stratify/DistWin-prac/Pr7-instructions-DistWin.html",
    "title": "Analysis of stratified data",
    "section": "",
    "text": "Analysis of stratified data"
  },
  {
    "objectID": "07-stratify/DistWin-prac/Pr7-instructions-DistWin.html#the-data",
    "href": "07-stratify/DistWin-prac/Pr7-instructions-DistWin.html#the-data",
    "title": "Analysis of stratified data",
    "section": "The Data",
    "text": "The Data\nThe Distance project Stratify exercise.zip contains data from a stratified survey of Antarctic minke whales. The data are “exact” insofar as they are calculated directly from the estimates of radial distance and angle recorded by the observers. While angle boards and reticle binoculars were used for estimation of angles and distances when possible, the transitory nature of cues (usually blows) and the pitch and roll of the vessel, among other things, leads to in errors in estimating angles and distances. Angular errors are typically of the order of a degree or two; the coefficient of variation of distance estimation errors is typically of the order of 10%.\nThe two strata were surveyed by different vessels at the same time. Because the whales tend to be found in high densities against the ice edge, where they feed, densities in southern strata are typically higher than those in northern strata. In fact this is the primary reason for using a stratified survey design. It is also the reason for covering the southern strata more intensely; in this survey the transect length per unit area in the southern stratum, is more than 2.5 times that in the northern stratum.\nHere are pictures of the sort of design used and a typical density gradient. The irregular bottom border is the ice-edge; the “steps” define the boundary between southern and northern strata; dotted lines are transects; solid dots are detections."
  },
  {
    "objectID": "07-stratify/DistWin-prac/Pr7-instructions-DistWin.html#analysis-exercises",
    "href": "07-stratify/DistWin-prac/Pr7-instructions-DistWin.html#analysis-exercises",
    "title": "Analysis of stratified data",
    "section": "Analysis Exercises",
    "text": "Analysis Exercises\nOpen the project from its archive Stratify exercise.zip. The project contains one analysis specification, called Full geog stratification. This is a fully stratified analysis of the data. Seven equal perpendicular distance intervals, truncation at 1.5 nautical miles (nm), and a hazard rate detection function form with no adjustment terms are used to estimate the detection function. As the focus of these exercises is stratification, do not investigate other perpendicular distance intervals and detection function forms; the given models are adequate. Use the Analysis browser to familiarise yourself with the details of this analysis specification.\n\nHaving done that, run the analysis Full geog stratification. Look at the results, and note the AIC statistics from each detection function fit.\nTo stratify \\(f(0)\\) or not: Create a new analysis identical to Full geog stratification by clicking the New Analysis icon in the Analysis tab of the Project browser after selecting the existing analysis. The new analysis will be a copy of the existing one.\n\nCreate a new model definition for this new analysis by going to the Inputs tab and highlighting the “haz rate+no adj full strat” model, then clicking the New tab. This will copy the existing model definition – modify the new model definition so that f(0) is to be estimated from the pooled strata (click the Detection function x Global cell of the table on the Estimate tab of the Model Definition Properties window you get after clicking New). Give this new model definition the name Pooled detection fn and then click OK.\nRun the new analysis and look at the output. By comparing the AIC from this analysis with the sum of the AICs from the analysis Full geog stratification, and considering the fits of each detection function, decide whether or not to pool strata for estimation of f(0).\n\n\n\n\n\n\nIf you have time, here’s a more difficult question.\n\n\n\n\n\nCreate an analysis without any stratification (No stratification) and estimate density using it. Why is the density estimate so much higher than those from Full geog stratification and Pooled detection fn above?"
  },
  {
    "objectID": "07-stratify/DistWin-prac/Pr7-solution-DistWin.html",
    "href": "07-stratify/DistWin-prac/Pr7-solution-DistWin.html",
    "title": "Analysis of stratified data",
    "section": "",
    "text": "Analysis of stratified data\nOutline Solutions\nExample analyses, which were used in getting these solutions, and which are referred to below, are in the project file Stratify solutions.zip."
  },
  {
    "objectID": "07-stratify/DistWin-prac/Pr7-solution-DistWin.html#relevant-results-are-in-analysis-full-geog-stratification",
    "href": "07-stratify/DistWin-prac/Pr7-solution-DistWin.html#relevant-results-are-in-analysis-full-geog-stratification",
    "title": "Analysis of stratified data",
    "section": "Relevant results are in Analysis Full geog stratification",
    "text": "Relevant results are in Analysis Full geog stratification\nThe AICs are 127.90 for the southern stratum and 187.90 for the northern stratum. Detection function model fits are adequate visually and by goodness-of-fit test. Sample sizes are relatively small but not alarmingly so. The southern stratum appears to have a much narrower effective strip width."
  },
  {
    "objectID": "07-stratify/DistWin-prac/Pr7-solution-DistWin.html#relevant-results-are-in-analysis-pooled-f0",
    "href": "07-stratify/DistWin-prac/Pr7-solution-DistWin.html#relevant-results-are-in-analysis-pooled-f0",
    "title": "Analysis of stratified data",
    "section": "Relevant results are in Analysis Pooled f(0)",
    "text": "Relevant results are in Analysis Pooled f(0)\nThe AIC for the pooled detection function fit is 318.72. The detection function model fit is adequate visually and by goodness-of-fit test. Because\n\\[318.72 &gt; (127.9+187.9=315.8)\\]\nestimation of separate detection function in each stratum is preferable."
  },
  {
    "objectID": "07-stratify/DistWin-prac/Pr7-solution-DistWin.html#relevant-results-are-in-analysis-no-stratification.",
    "href": "07-stratify/DistWin-prac/Pr7-solution-DistWin.html#relevant-results-are-in-analysis-no-stratification.",
    "title": "Analysis of stratified data",
    "section": "Relevant results are in Analysis “No stratification”.",
    "text": "Relevant results are in Analysis “No stratification”.\nThe whale density estimate from the unstratified analysis is 15-25% larger than the corresponding estimates from Full geog stratification and Pooled f(0) above. See table of study area abundance estimates below. The reason is that the survey design was geographically stratified, with less survey effort in the north stratum, and this is being ignored in the unstratified analysis.\n\n\n\n\n\n\n\n\n\n\nModel\nNum parameters\nN\nN LCL\nN UCL\n\n\n\n\nFull geog stratification\n4\n14954\n8420\n26559\n\n\nPooled f(0)\n2\n16333\n8619\n30949\n\n\nNo stratification\n2\n18868\n11164\n31888\n\n\n\n\n\n\n\n\n\nCluster size differences between strata\n\n\n\n\n\nWhat is not included in this project are cluster sizes of the observed minke whale groups (we didn’t want to clutter the analysis with that detail). However, there is a bit of a story in geographic variation in cluster sizes. Cluster densities are higher in the southern stratum, but transects from both strata are being treated as if they are representative of the whole survey region. This results in a positively biased cluster density for the region as a whole. In addition, cluster sizes are higher in the South stratum. The estimate of E(s) from the unstratified analysis is a positively biased estimate of E(s) for the North stratum and a negatively biased estimate of E(s) for the South stratum. When it is applied to both strata, it results in a positively biased estimate of whale abundance because the North stratum is much larger and contains roughly twice as many whales as the south stratum.\n\n\n\n\n\n\n\n\n\nMoral\n\n\n\n\n\nDo not perform analyses without taking the survey design into account."
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#projecting-your-study-region",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#projecting-your-study-region",
    "title": "Design of distance sampling surveys",
    "section": "Projecting your Study Region",
    "text": "Projecting your Study Region\nThis exercise demonstrates how to deal with unprojected shapefiles. Study areas should always be projected onto a flat plane before you use them to design your survey. This is because in most parts of the world one degree latitude is not the same in distance as one degree longitude. If we didn’t project, our study region and any surveys generated in it, would be distorted possibly leading to non-uniform coverage.\nLoad the study region and project it onto a flat plane using an Albers Equal Area Conical projection. As we have to project the shapefile we load the shape object separately instead of directly into a region object.\n\n#Load the unprojected shapefile\nshapefile.name &lt;- system.file(\"extdata\", \"TentsmuirUnproj.shp\", package = \"dssd\")\nsf.shape &lt;- read_sf(shapefile.name)\n# Check current coordinate reference system\nst_crs(sf.shape)\n# Define a European Albers Equal Area projection\nproj4string &lt;- \"+proj=aea +lat_1=56 +lat_2=62 +lat_0=50 +lon_0=-3 +x_0=0 \n                +y_0=0 +ellps=intl +units=m\"\n# Project the study area on to a flat plane\nprojected.shape &lt;- st_transform(sf.shape, crs = proj4string)\n\nPlot it to check what it looks like."
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#coverage",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#coverage",
    "title": "Design of distance sampling surveys",
    "section": "Coverage",
    "text": "Coverage\nSet up a coverage grid. A coverage grid is a grid of regularly spaced points and is used to assess whether each point in the survey region is equally likely to sampled. The coverage grid needs to be created before the coverage can be evaluated\nTo generate a coverage grid layer click on the Data tab of the Project Browser and then the Create New Data Layer button (5th from left). Enter “coverage” as your Layer Name and set the Parent Layer to “Study Area” and the Layer Type to “Coverage”. You should now be able to click on the Properties… button. In the Grid Properties specify the approximate number of grid points to be 1000 Once you press OK you should proceed to add the grid points to the layer. This may take a few moments."
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#design",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#design",
    "title": "Design of distance sampling surveys",
    "section": "Design",
    "text": "Design\nSet up a systematic point transect design. We will assume that we have sufficient resources to survey 40 point transects. As the Morton Lochs stratum is of special interest we will give it higher coverage. We will therefore explicitly allocate 25 samplers to the main stratum and 15 to the Morton Lochs stratum (note that the area of the Morton Lochs stratum is much small than the main stratum). If we wanted to allocate the same effort to both stratum we could provide the samplers argument with the single value of 40 and it would divide the effort equally between the strata. We will leave the design angle as 0 and set the truncation distance to 100 m. We will use minus sampling at the edges.\nClick on the Designs tab of the Project Browser and then the New Design button. Rename your “New Design” something like “systematic line test” and then click the Show Details button to open the Design Details window. Select the “Point” sampler and set the design class to “Systematic Grid Sampling”. Click the Properties button to set the following properties for this design:\n\nOn the General Properties tab under Stratum layer, the Region stratum layer should be selected. Under Design coordinate system, you will see the study area has been projected using Albers Equal Angle projection.\nIn the Effort Allocation tab, under Edge Sampling select the “Minus” option. In the “Allocation by stratum”, you will specify your unequal coverage design, which will produce a greater proportional coverage of the Morton Lochs stratum compared to the Main Stratum.\n\nEnsure the “Same effort for all strata” is not checked\nRequest 25 of the 40 point transects be placed in the “Main” stratum and the remaining 15 transects in the relatively small (but important) Morton Lochs stratum.\n\nIn the “Sampler” tab, specify a detection radius of 100 in units of Meter\nMove to “Coverage Probability” tab and specify that coverage probability is to be “estimated by simulation”. Specify 1000 replicates of the survey design for the purpose of assessing coverage probabilities.\nThat concludes specification of the design. Press the “Run” button to generate the coverage probability statistics.\n\n\n\n\n\n\n\nQuestion:\n\n\n\n\nWhat are the analysis implications of a design with unequal coverage?"
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#generate-a-survey",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#generate-a-survey",
    "title": "Design of distance sampling surveys",
    "section": "Generate a Survey",
    "text": "Generate a Survey\n Having completed your assessment of coverage properties of your design and determining the coverage is suitable for your study objectives, generate a single survey from this design and plot it inside the survey region to check what it looks like.\nReturn to the design you generated, and again press the “Run” button. However, this time when presented with the dialogue box at right, choose the second option “Create new Survey and generate a new sample data layer”\nExamine the survey information, viewing the green tab.\nFor both strata Main and Morton Lochs you will see the number of point transects placed, the vertical and horizontal spacing between points and the proportion of the strata receiving sampling effort (based upon 100m truncation distance at each point).\nThe final two pages of output show the placement of point transects for the given survey realisation in map form and also the coordinates (in degrees latitude/longitude) of the point stations. These values can be downloaded into handheld GPS units for the field crew to navigate to each station.\n\n\n\n\n\n\nQuestions:\n\n\n\n\nWhat spacing was used in each strata to try and achieve the desired number of samplers?\nDid your survey achieve exactly the number of samplers you requested?\nHow much does coverage differ between the two strata for this realisation?"
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#assessing-coverage-and-design-statistics",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#assessing-coverage-and-design-statistics",
    "title": "Design of distance sampling surveys",
    "section": "Assessing Coverage and Design Statistics",
    "text": "Assessing Coverage and Design Statistics\nExamining the output from the coverage simulation you just created, assess how - variable the number of samplers and average coverage between replicate surveys and - coverage varies spatially to assess the magnitude of edge effects.\n\n\n\n\n\n\nQuestions:\n\n\n\n\nWhat is the minimum number of samplers you will achieve in each strata?\nIs this sufficient to complete separate analyses in each stratum?\n\n\n\n\n\n\n\n\n\nQuestions:\n\n\n\n\nDoes it appear that there is even coverage within each strata?\n\nAs there is such a difference in the range of coverage scores between strata you may need to plot each strata individually."
  },
  {
    "objectID": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#the-distance-for-windows-project",
    "href": "06-design/DistWin-prac/Pr6-instructions-DistWin.html#the-distance-for-windows-project",
    "title": "Design of distance sampling surveys",
    "section": "The Distance for Windows project",
    "text": "The Distance for Windows project\nA shapefile of the study area has been inserted into the project Tentsmuir.zip. Your task is to design a survey that places point transect effort into the two strata. Download and open the project and create a map of the study area using the Maps tab adding the Region layer; see if you can locate the boundary between the strata."
  },
  {
    "objectID": "08-covariates/sparrow-supplement.html",
    "href": "08-covariates/sparrow-supplement.html",
    "title": "Supplement, covariate coefficient interpretation",
    "section": "",
    "text": "Covariate analysis of point transects: Savannah sparrow\n\n\n\n\n\n\nFurther investigation of a single covariate (pasture) upon detectability of the Savannah Sparrow data set. The analysis is done in R, but the understanding of the covariates is relevant whatever software is used.\n\n\n\n\nRecall, these are data from Colorado, described by Knopf et al. (1988). The question here was whether to include pasture as a covariate in the detection function. The biological question being, “does detectability of Savannah sparrows differ between the pastures in which the survey was conducted.”\n\nlibrary(Distance)\ndata(Savannah_sparrow_1980)\nhead(Savannah_sparrow_1980, n=3)\n\n  Region.Label Area Sample.Label Effort object distance Study.Area\n1    PASTURE 1    1    POINT   1      1     NA       NA  SASP 1980\n2    PASTURE 1    1    POINT   2      1     NA       NA  SASP 1980\n3    PASTURE 1    1    POINT   3      1     NA       NA  SASP 1980\n\nhist(Savannah_sparrow_1980$distance, \n     nclass=20, xlab=\"Distance (m)\",\n     main=\"Savannah sparrow radial distances '80\")\n\n\n\nconversion.factor &lt;- convert_units(\"meter\", NULL, \"hectare\")\n\nA truncation distance of 55m was chosen. The half normal and hazard rate functions were tried in turn, allowing AIC selection of cosine adjustment terms, then pasture was included as a covariate in the detection function.\n\nSavannah_sparrow_1980.hn &lt;- ds(data=Savannah_sparrow_1980, key=\"hn\",\n                               adjustment=\"cos\", truncation=55,\n                               transect=\"point\", \n                               convert_units=conversion.factor)\nSavannah_sparrow_1980.hr &lt;- ds(data=Savannah_sparrow_1980, key=\"hr\",\n                               adjustment=\"cos\", truncation=55,\n                               transect=\"point\", \n                               convert_units=conversion.factor)\nSavannah_sparrow_1980.hn.region &lt;- ds(data=Savannah_sparrow_1980, key=\"hn\",\n                                      truncation=55,\n                                      transect=\"point\",\n                                      convert_units=conversion.factor,\n                                      formula=~Region.Label)\nSavannah_sparrow_1980.hr.region &lt;- ds(data=Savannah_sparrow_1980, key=\"hr\", truncation=55,\n                                      transect=\"point\", convert_units=conversion.factor,\n                                      formula=~Region.Label)\nAIC(Savannah_sparrow_1980.hn, Savannah_sparrow_1980.hr, \n    Savannah_sparrow_1980.hn.region, Savannah_sparrow_1980.hr.region)\n\n                                df      AIC\nSavannah_sparrow_1980.hn         2 2126.228\nSavannah_sparrow_1980.hr         3 2127.883\nSavannah_sparrow_1980.hn.region  3 2125.033\nSavannah_sparrow_1980.hr.region  4 2130.447\n\n\nThe half normal model with pasture as a covariate had a marginally smaller AIC than the half normal model without pasture. The plots and estimates are shown below.\n\nplot(Savannah_sparrow_1980.hn.region, pch=\".\", pdf=TRUE)\n\n\n\n\nNote different PDF shapes caused by the pasture covariate.\n\n\n\n\n\nsummary(Savannah_sparrow_1980.hn.region)\n\n\nSummary for distance analysis \nNumber of observations :  271 \nDistance range         :  0  -  55 \n\nModel       : Half-normal key function \nAIC         :  2125.033 \nOptimisation:  mrds (nlminb) \n\nDetection function parameters\nScale coefficient(s):  \n                         estimate         se\n(Intercept)            3.17237666 0.09850468\nRegion.LabelPASTURE 2 -0.20459862 0.11098924\nRegion.LabelPASTURE 3 -0.03286901 0.12333031\n\n                       Estimate          SE         CV\nAverage p             0.2896553  0.01973518 0.06813332\nN in covered region 935.5946771 79.89055349 0.08539013\n\nSummary statistics:\n     Region Area CoveredArea Effort   n   k        ER      se.ER      cv.ER\n1 PASTURE 1    1    117.8411    124  59 124 0.4758065 0.07009015 0.14730811\n2 PASTURE 2    1    119.7418    126 121 126 0.9603175 0.09521957 0.09915427\n3 PASTURE 3    1    116.8908    123  91 123 0.7398374 0.07467322 0.10093193\n4     Total    3    354.4738    373 271 373 0.7253204 0.04661364 0.06426628\n\nAbundance:\n      Label Estimate        se         cv       lcl      ucl       df\n1 PASTURE 1 1.430170 0.3084008 0.21563923 0.9403572 2.175117 353.1228\n2 PASTURE 2 4.116182 0.5642114 0.13707154 3.1472623 5.383394 329.1061\n3 PASTURE 3 2.345631 0.3717609 0.15849077 1.7208931 3.197169 374.9983\n4     Total 7.891983 0.7427326 0.09411229 6.5625680 9.490706 537.6070\n\nDensity:\n      Label Estimate        se         cv       lcl      ucl       df\n1 PASTURE 1 1.430170 0.3084008 0.21563923 0.9403572 2.175117 353.1228\n2 PASTURE 2 4.116182 0.5642114 0.13707154 3.1472623 5.383394 329.1061\n3 PASTURE 3 2.345631 0.3717609 0.15849077 1.7208931 3.197169 374.9983\n4     Total 2.630661 0.2475775 0.09411229 2.1875227 3.163569 537.6070\n\n\nA similar process was conducted for the 1981 data: a truncation distance of 55m was again used.\n\ndata(Savannah_sparrow_1981)\nconversion.factor &lt;- convert_units(\"meter\", NULL, \"hectare\")\n\n\nSavannah_sparrow_1981.hn &lt;- ds(data=Savannah_sparrow_1981, key=\"hn\", \n                               adjustment=\"cos\", truncation=55,\n                               transect=\"point\", convert_units=conversion.factor)\nSavannah_sparrow_1981.hr &lt;- ds(data=Savannah_sparrow_1981, key=\"hr\", \n                               adjustment=\"cos\", truncation=55,\n                               transect=\"point\", convert_units=conversion.factor)\nSavannah_sparrow_1981.hn.region &lt;- ds(data=Savannah_sparrow_1981, \n                                      key=\"hn\", truncation=55, transect=\"point\",\n                                      convert_units=conversion.factor,\n                                      formula=~Region.Label)\nSavannah_sparrow_1981.hr.region &lt;- ds(data=Savannah_sparrow_1981, key=\"hr\", \n                                      truncation=55, transect=\"point\",\n                                      convert_units=conversion.factor,\n                                      formula=~Region.Label)\nAIC(Savannah_sparrow_1981.hn, Savannah_sparrow_1981.hr, \n    Savannah_sparrow_1981.hn.region, Savannah_sparrow_1981.hr.region)\n\n                                df      AIC\nSavannah_sparrow_1981.hn         1 1266.358\nSavannah_sparrow_1981.hr         2 1267.335\nSavannah_sparrow_1981.hn.region  4 1261.684\nSavannah_sparrow_1981.hr.region  5 1260.638\n\n\nFor 1981, there was a clear preference for including pasture as a covariate in the detection function but little to choose from between the half normal and hazard rate key function. For comparability with 1980, the plots and results below are for the half normal model although AIC showed a slight preference for the hazard rate model. The differences in detection between pastures can easily be seen and this is reflected in the estimated densities (birds per hectare).\n\npastures &lt;- unique(Savannah_sparrow_1981$Region.Label)\nplot(Savannah_sparrow_1981.hn.region, showpoints=FALSE, \n     main=\"Savannah sparrows with pasture covariate\", pdf=TRUE)\nk &lt;- 1\nfor (i in pastures) {\n  k &lt;- k+1\n  add_df_covar_line(Savannah_sparrow_1981.hn.region, \n                    data=data.frame(Region.Label=as.character(i)),\n                    lty=1, col=k, lwd=3, pdf=TRUE)\n}\nlegend(\"topright\", legend=tolower(as.character(pastures)), \n       col=2:k, lwd=2, title = \"Pastures\")\ntext(-2,0.038, cex=0.9, pos=4,\n     expression(widehat(sigma[p])==plain(exp)(widehat(beta[0]) + widehat(beta[1]) * p[1] + widehat(beta[2]) * p[2] + widehat(beta[3]) * p[3])))\nlibrary(plotrix)\nparms &lt;- data.frame(est=c(2.944, 0.736, 0.166, 0.271),\n                    se=c(0.111, 0.373, 0.153, 0.179))\nrownames(parms) &lt;- c(\"b0\", \"b1\", \"b2\", \"b3\")\naddtable2plot(2, 0.027, parms, bty=\"o\",\n              display.rownames=TRUE,hlines=TRUE, cex=0.8,\n              xpad=0.4, vlines=FALSE,title=\"Parameter estimates\")\n\n\n\n\nStronger influence of pasture covariate seen here.\n\n\n\n\n\nsummary(Savannah_sparrow_1981.hn.region)\n\n\nSummary for distance analysis \nNumber of observations :  162 \nDistance range         :  0  -  55 \n\nModel       : Half-normal key function \nAIC         :  1261.684 \nOptimisation:  mrds (nlminb) \n\nDetection function parameters\nScale coefficient(s):  \n                       estimate        se\n(Intercept)           2.9440471 0.1110272\nRegion.LabelPASTURE 1 0.7362681 0.3726357\nRegion.LabelPASTURE 2 0.1660949 0.1524426\nRegion.LabelPASTURE 3 0.2703034 0.1790810\n\n                       Estimate          SE        CV\nAverage p             0.3435487  0.03715842 0.1081606\nN in covered region 471.5489313 59.62606186 0.1264472\n\nSummary statistics:\n     Region Area CoveredArea Effort   n   k    ER      se.ER      cv.ER\n1 PASTURE 0    1    95.03318    100  31 100 0.310 0.05448566 0.17576019\n2 PASTURE 1    1    95.03318    100  32 100 0.320 0.06175874 0.19299605\n3 PASTURE 2    1    95.03318    100  51 100 0.510 0.08225975 0.16129363\n4 PASTURE 3    1    95.03318    100  48 100 0.480 0.07174590 0.14947063\n5     Total    4   380.13271    400 162 400 0.405 0.03418422 0.08440547\n\nAbundance:\n      Label  Estimate        se        cv       lcl      ucl       df\n1 PASTURE 0 1.3887466 0.3779428 0.2721467 0.8203808 2.350880 255.9017\n2 PASTURE 1 0.5241867 0.1817587 0.3467442 0.2699503 1.017861 250.9726\n3 PASTURE 2 1.6980708 0.4057104 0.2389243 1.0676527 2.700732 251.7139\n4 PASTURE 3 1.3509360 0.3544528 0.2623757 0.8127396 2.245526 253.0658\n5     Total 4.9619401 0.6827259 0.1375925 3.7903971 6.495586 357.0057\n\nDensity:\n      Label  Estimate        se        cv       lcl      ucl       df\n1 PASTURE 0 1.3887466 0.3779428 0.2721467 0.8203808 2.350880 255.9017\n2 PASTURE 1 0.5241867 0.1817587 0.3467442 0.2699503 1.017861 250.9726\n3 PASTURE 2 1.6980708 0.4057104 0.2389243 1.0676527 2.700732 251.7139\n4 PASTURE 3 1.3509360 0.3544528 0.2623757 0.8127396 2.245526 253.0658\n5     Total 1.2404850 0.1706815 0.1375925 0.9475993 1.623896 357.0057\n\n\nIn these models, the detection functions have been fitted to all the detections within the study region (for each year). An alternative would be to fit separate detection functions within each pasture (specified in Region.Label), provided there are enough detections. This would allow different shape detection functions to be fitted in each pasture (providing this is a reasonable thing to do).\n\n\n\n\nReferences\n\nKnopf, F. L., Sedgwick, J. A., & Cannon, R. W. (1988). Guild structure of a riparian avifauna relative to seasonal cattle grazing. The Journal of Wildlife Management, 52(2), 280–290. https://doi.org/10.2307/3801235"
  },
  {
    "objectID": "08-covariates/R-prac/Prac8_solution.html",
    "href": "08-covariates/R-prac/Prac8_solution.html",
    "title": "Covariates in the detection function solution",
    "section": "",
    "text": "Solution\n\n\n\nCovariates in the detection function"
  },
  {
    "objectID": "08-covariates/R-prac/Prac8_solution.html#colourful-plot-noting-effect-of-cue-type",
    "href": "08-covariates/R-prac/Prac8_solution.html#colourful-plot-noting-effect-of-cue-type",
    "title": "Covariates in the detection function solution",
    "section": "Colourful plot noting effect of cue type",
    "text": "Colourful plot noting effect of cue type\nJust an example of using the function add_df_covar_line to visually explore consequences of covariates on the detection function. A regular call to plot() is first used to produce the histogram and average detection function line; subsequent calls to the new function with different values of the covariate of interest completes the plot.\n\nplot(etp.hr.cue, main=\"ETP dolphin survey\", showpoints=FALSE)\nadd_df_covar_line(etp.hr.cue, data = data.frame(Cue.type=1), \n                  col='red', lwd=2, lty=1)\nadd_df_covar_line(etp.hr.cue, data = data.frame(Cue.type=2), \n                  col='blue', lwd=2, lty=1)\nadd_df_covar_line(etp.hr.cue, data = data.frame(Cue.type=3), \n                  col='green', lwd=2, lty=1)\nadd_df_covar_line(etp.hr.cue, data = data.frame(Cue.type=4), \n                  col='purple', lwd=2, lty=1)\nlegend(\"topright\", \n       legend=c(\"Birds\",\"Splashes\",\"Unspecified\",\"Floating objects\"),\n       col=c(\"red\", \"blue\", \"green\", \"purple\"), lwd=2, title = \"Cue type\")\n\n\n\n\nDetection function with cue type as covariate."
  },
  {
    "objectID": "08-covariates/covariateslanding.html",
    "href": "08-covariates/covariateslanding.html",
    "title": "Including covariates in detection function modelling",
    "section": "",
    "text": "It is not just distance from the transect that influences the detectability of animals. In most situations, inference regarding animal density is not hindered if additional causes of variation in detectability are unaccounted.\nThere are some situations in which covariates in addition to distance can be added to models of the detection function. One example of this is animal group size. It is commonly the case that small groups at large distances are not detected and do not enter our sample that is used to estimate the average group size in the population. By failing to have the small groups in our sample, the sample is biased; we estimate that the average group size in the field is larger than it really is; producing biased estimates of population size. The use of group size as a covariate is the recommended way to remove that bias.\nThis exercise presents three sets of data: Hawaiian amakihi point transect data collected by multiple observers at varying times during the morning. Eastern Tropical Pacific dolphin surveys where there were different types of vessels, sea state and widely varying dolphin school sizes. Finally, additional bird point transect data from Colorado where the study area was divided into geographic strata–we examine whether the geographic stratum effect can be modelled as a covariate."
  },
  {
    "objectID": "08-covariates/covariateslanding.html#including-covariates-in-detection-function-modelling",
    "href": "08-covariates/covariateslanding.html#including-covariates-in-detection-function-modelling",
    "title": "Including covariates in detection function modelling",
    "section": "",
    "text": "It is not just distance from the transect that influences the detectability of animals. In most situations, inference regarding animal density is not hindered if additional causes of variation in detectability are unaccounted.\nThere are some situations in which covariates in addition to distance can be added to models of the detection function. One example of this is animal group size. It is commonly the case that small groups at large distances are not detected and do not enter our sample that is used to estimate the average group size in the population. By failing to have the small groups in our sample, the sample is biased; we estimate that the average group size in the field is larger than it really is; producing biased estimates of population size. The use of group size as a covariate is the recommended way to remove that bias.\nThis exercise presents three sets of data: Hawaiian amakihi point transect data collected by multiple observers at varying times during the morning. Eastern Tropical Pacific dolphin surveys where there were different types of vessels, sea state and widely varying dolphin school sizes. Finally, additional bird point transect data from Colorado where the study area was divided into geographic strata–we examine whether the geographic stratum effect can be modelled as a covariate."
  },
  {
    "objectID": "08-covariates/covariateslanding.html#lecture-materials",
    "href": "08-covariates/covariateslanding.html#lecture-materials",
    "title": "Including covariates in detection function modelling",
    "section": "Lecture materials",
    "text": "Lecture materials\n\nLecture discussion\n\nSlides\n\n\nVideo"
  },
  {
    "objectID": "08-covariates/covariateslanding.html#exercise-materials",
    "href": "08-covariates/covariateslanding.html#exercise-materials",
    "title": "Including covariates in detection function modelling",
    "section": "Exercise materials",
    "text": "Exercise materials\n\n\n\nUsing R package\n\nVideo introduction\n\n\nInstructions\n\n\nSolution and discussion\n\n\nVideo summary\n\n\n\n\nUsing Distance for Windows\n\nVideo introduction\n\n\nInstructions\n\n\nSolution and discussion\n\n\nVideo summary"
  },
  {
    "objectID": "08-covariates/covariateslanding.html#supplemental-materials",
    "href": "08-covariates/covariateslanding.html#supplemental-materials",
    "title": "Including covariates in detection function modelling",
    "section": "Supplemental materials",
    "text": "Supplemental materials\n\nInterpreting covariate coefficient estimates\n\nPasture type as covariate in detection function"
  },
  {
    "objectID": "08-covariates/DistWin-prac/Pr8-instructions-DistWin.html",
    "href": "08-covariates/DistWin-prac/Pr8-instructions-DistWin.html",
    "title": "Covariates in the detection function",
    "section": "",
    "text": "Covariates in the detection function\nThis exercise consists of two datasets of increasing difficulty. They take you deeper into the heart of understanding multiple covariates. Feel free to complete as many as you like."
  },
  {
    "objectID": "08-covariates/DistWin-prac/Pr8-instructions-DistWin.html#passerine-data-from-marques2007",
    "href": "08-covariates/DistWin-prac/Pr8-instructions-DistWin.html#passerine-data-from-marques2007",
    "title": "Covariates in the detection function",
    "section": "Passerine data from T. A. Marques et al. (2007)",
    "text": "Passerine data from T. A. Marques et al. (2007)\nThe data from the Auk paper by (T. A. Marques et al., 2007) is also available. It is zipped as the project fTAMAUK07.zip.\nThe survey information in this project is from seven surveys carried out in Hawaii 1992-1995 of the Hawaiʻi ʻamakihi (Chlorodrepanis virens). In addition to standard distance sampling information, the project contains four observation-level covariates:\n\ninitials of the observation making the detection (factor),\nhours after sunrise (continuous) and\nminutes after sunrise (continuous).\n\nThere is no area measure associated with the surveys so abundance estimates will not be produced. Construct models with the covariates to build the best model for these data."
  },
  {
    "objectID": "08-covariates/DistWin-prac/Pr8-instructions-DistWin.html#dolphin-sightings-data",
    "href": "08-covariates/DistWin-prac/Pr8-instructions-DistWin.html#dolphin-sightings-data",
    "title": "Covariates in the detection function",
    "section": "Dolphin Sightings Data",
    "text": "Dolphin Sightings Data\nIn this exercise there are several potential covariates and no ‘right’ answers. Begin your investigation by downloading the archived Distance for Windows project Dolphin.zip and opening it using the Distance for Windows software.\n\nReviewing the data\nIn this example we have a sample of eastern tropical Pacific (ETP) offshore spotted dolphin sightings data, collected by observers placed on board tuna vessels (the data were kindly made available to us by the Inter-American Tropical Tuna Commission – IATTC). A full description of the analysis of these data can be found in F. F. C. Marques & Buckland (2003). In the ETP, schools of yellow fin tuna commonly associate with schools of certain species of dolphins, and so vessels fishing for tuna often search for dolphins in the hopes of also locating tuna. For each school detected by the tuna vessels, the observer records the species, sighting angle and distance (later converted to perpendicular distance and truncated at 5 nautical miles), school size, and a number of covariates associated with each detected school. Many of these covariates potentially affect the detection function, as they reflect how the search was being carried out.\nA variety of search methods are used to find the dolphins, but currently the most commonly used are 20x binoculars from the crow’s nest, 20x binoculars from another location on the vessel, from a helicopter, or through “bird radar” (high power radars which are able to detect seabirds flying above the dolphin schools). In the example dataset these are coded as 0, 2, 3, and 5, respectively. Some of these methods may have a wider range of search than the others, and so it is possible that the effective strip width varies according to the method being used.\nFor each sighting the initial cue type is recorded. This may be birds flying above the school, splashes on the water, floating objects such as logs, or some other unspecified cue. In the example they have been coded as 1, 2, 4 and 3, respectively.\nAnother covariate that potentially affects the detection function is sea state, as measured by Beaufort. In rougher conditions (i.e. higher Beaufort levels), visibility and/or detectability may be reduced. For this example, Beaufort levels are grouped into two categories, the first including Beaufort values ranging from 0 to 2 (coded as 1) and the second containing values from 3 to 5 (coded as 2).\nThe sample data encompasses sightings made over a three month period: June, July and August (months 6, 7 and 8, respectively).\nBegin by extracting and opening the project from the archive Dolphin.zip. Once it is open, you will see the Project Browser, from which you can have a look at the data (Data tab).\n\n\nAnalysis of Dolphin Sightings data\n The data in the project is only a portion of the data for the survey; for example there is only a single transect depicted and it is of unknown length. Nor is the size of the study area provided. Because of this, estimates of abundance and density will not be meaningful. The focus of the exercise is upon exploring covariates in the detection function. Consequently, it might be simplest to specify that estimates of density and abundance are not of interest; this is done using the configuration of Model Definition Properties shown in the screen shot at right.\nStart by running a set of conventional distance analyses. Are there any problems in the data and if so how might you mitigate them? (Hint – check out the q-q plot, and also try dividing the data into a large number of intervals in the Model Definition | Detection Function | Diagnostics.)\nBecause of a surplus of detections at perpendicular distance 0, it is best to convert the distances to binned distances, using say, 15 equal width bins before fitting models to the data.\nAs there are a number of potential covariates to be used in this example, try fitting models with different covariates and combinations of the covariates. All of the covariates in this example are factor covariates except cluster size. We suggest that you not explore detection functions with cluster size, simply because we will revisit this data set again in the module where we discuss cluster size.\nKeep in mind that this is a large dataset (&gt; 1000 observations), and hence estimation may take a while, particularly if you are allowing several adjustment terms to be fitted. It will be generally more efficient to start fitting models without any adjustment terms, and then adding one at a time if appropriate. Consider also whether to standardize by w or by σ (or try both).\nYou will likely end up with quite a few models, so think about how you are going to name and organize them in the Project Browser (for analyses) and Analysis Components window (for model definitions).\n\n\n\n\n\n\nCaution regarding the hazard rate key function with covariates for these data)\n\n\n\n\n\n\nModel convergence problems arise when using the hazard rate model particularly in association with the sea state covariate, month covariate and the cue type covariate.\nRun some of these models and see if you can diagnose the source of these problems.\nTo circumvent the problems, perhaps restrict your candidate model set to the half normal key function along with covariates."
  },
  {
    "objectID": "08-covariates/DistWin-prac/Pr8-solution-DistWin.html",
    "href": "08-covariates/DistWin-prac/Pr8-solution-DistWin.html",
    "title": "Covariates in the detection function",
    "section": "",
    "text": "Covariates in the detection function"
  },
  {
    "objectID": "08-covariates/DistWin-prac/Pr8-solution-DistWin.html#hawaiian-amakihi",
    "href": "08-covariates/DistWin-prac/Pr8-solution-DistWin.html#hawaiian-amakihi",
    "title": "Covariates in the detection function",
    "section": "Hawaiian Amakihi",
    "text": "Hawaiian Amakihi\nHere is the Results Browser table of the models described in Marques et al. (2007), with strata (“strat”) representing the repeated surveys performed. The project containing these results can be found in fTAMAUK07.zip.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\n# params\nDelta AIC\nAIC\nESW/EDR\nD\nD LCL\nD UCL\nD CV\n\n\n\n\ng7 - HR OBS MAS w82.5\n5\n0\n10777.72\n45.54432\n7.172463\n\n\n\n\n\nh8 - HR OBS w82.5\n4\n1.730469\n10779.45\n45.30368\n7.229559\n\n\n\n\n\nk11 - HRpol OBS HAS w82.5\n9\n5.620117\n10783.34\n46.01192\n7.025928\n\n\n\n\n\nl12 - HN OBS w82.5\n6\n7.120117\n10784.84\n41.97314\n8.493949\n\n\n\n\n\nd4 - Unicos by strat w82.5\n12\n13.5\n10791.22\n\n7.334418\n6.801114\n7.90954\n0.03848917\n\n\ni9 - HN Obs HAS by strat 82.5m\n9\n14.18066\n10791.9\n43.4998\n7.922717\n\n\n\n\n\nj10 - HN OBS MAS w82.5\n5\n15.52051\n10793.24\n43.38829\n7.97246\n\n\n\n\n\ne5 - HR by strat w82.5\n14\n18.58984\n10796.31\n\n6.821746\n5.990242\n7.768671\n0.06631405\n\n\na1 - HN by strat f0 pooled w82.5\n5\n21.40039\n10799.12\n43.85356\n7.824244\n6.029662\n10.15294\n0.1333881\n\n\ng6 - HN by strat w82.5\n15\n22.87012\n10800.59\n\n7.998222\n6.889873\n9.284867\n0.07605652\n\n\nb2 - Unicos by strat f0 pooled w82.5\n2\n25.11035\n10802.83\n44.30367\n7.666068\n7.002776\n8.392186\n0.04615532\n\n\no15 - HR MAS w82.5\n3\n29.18066\n10806.9\n47.91844\n6.575671\n\n\n\n\n\nc3 - HR by strat f0 pooled w82.5\n2\n29.90039\n10807.62\n47.27633\n6.732318\n5.960572\n7.603986\n0.06212176\n\n\np16 - HRpol HAS w82.5\n7\n31.62012\n10809.34\n47.79588\n6.599619\n\n\n\n\n\nn14 - HN HAS by strat 82.5m\n7\n34.73047\n10812.45\n43.3067\n8.042932\n\n\n\n\n\nm13 - HN MAS w82.5\n3\n35.36035\n10813.08\n43.28159\n8.061954\n\n\n\n\n\n\n\nYou will note there are no measures of precision associated with the density estimates when a single detection function (across strata) is used to estimate density. Do you understand why this is the case? If not, carefully read the message included in the Distance for Windows output for one of these models."
  },
  {
    "objectID": "08-covariates/DistWin-prac/Pr8-solution-DistWin.html#analysis-of-dolphin-sightings-data",
    "href": "08-covariates/DistWin-prac/Pr8-solution-DistWin.html#analysis-of-dolphin-sightings-data",
    "title": "Covariates in the detection function",
    "section": "Analysis of dolphin sightings data",
    "text": "Analysis of dolphin sightings data\nTo obtain an overall impression of the data it is useful to fit a detection function histogram with many intervals (you may have problems fitting to the maximum number of 30, but 25 intervals should be OK). The spikes in the histogram suggest that the data has been rounded to zero and possibly other values. The q-q plot also indicates problems with the model at zero distances. To mitigate these problems, use the Intervals tab in the Data Filter to pool the data into a few intervals – 10 to 15 intervals work. For reasons described in the instructions (lacking information regarding effort and study area size), we restrict our interest in the analysis to the fitting of the detection function, measured in the table below by effective strip width (ESW).\nFor the MCDS analysis, cluster size was fitted as a continuous variable, whereas, month, Beaufort, cue and search position were fitted as factor variables. Table 1 summarises the results.\nTable 1. Effective strip width estimates for the different models. | Name | # params | Delta AIC | AIC | ESW/EDR | ESW/EDR CV | |————————— |———- |———– |———- |———- |———— | | interval hn search method | 4 | 0 | 5743.476 | 3.388467 | 0.01766289 | | interval hn log cluster | 2 | 11.13477 | 5754.611 | 3.423404 | 0.01740193 | | interval hn cos | 2 | 16.72412 | 5760.2 | 3.024034 | 0.04587239 | | interval hn cluster | 2 | 17.22998 | 5760.706 | 3.506682 | 0.01725098 | | interval hn month | 3 | 22.125 | 5765.601 | 3.44452 | 0.0171129 | | interval hn sea state | 2 | 26.37891 | 5769.855 | 3.454254 | 0.01689994 | | interval hn cue type | 4 | 27.23877 | 5770.715 | 3.449551 | 0.01703152 |\n\nBased on the AIC, it seems as though the model including search method is best, however, there were warning messages about the detection function fitting and cluster size estimation. Before going on and looking at models which include two covariates, it is worth looking at the search model in more detail. The detection functions have very different scale parameters, for example, the detection function for search method 3 (using a helicopter) has a very wide shoulder and so the scale parameter is very large. See figure at right.\nThis suggests that the observers were seeing everything out to 5 nm and so detection does not decrease with distance as it does with the other methods. One assumption of MCDS is that the perpendicular distance distributions of the covariate factor levels have the same shape. It may be worth refitting the model ignoring the observations made by the helicopter. Data can easily be selected/ignored using the Data filter | Data selection tab. The selection criteria will be of the form ‘[Search method] IN (0,2,5)’"
  },
  {
    "objectID": "10-multipliers/R-prac/Pr10-instructions.html",
    "href": "10-multipliers/R-prac/Pr10-instructions.html",
    "title": "Analysis using multipliers",
    "section": "",
    "text": "We consider indirect methods to estimate abundance and hence include multipliers in the abundance calculations. The first problem uses data from a dung survey of deer and there are two levels of multipliers that need to be accounted for (dung production rate and dung decay rate). The songbird data set deals with instantaneous cues and so only cue rate needs to be taken into account."
  },
  {
    "objectID": "10-multipliers/R-prac/Pr10-instructions.html#getting-started",
    "href": "10-multipliers/R-prac/Pr10-instructions.html#getting-started",
    "title": "Analysis using multipliers",
    "section": "Getting started",
    "text": "Getting started\nThese data (called sikadeer) are available in the Distance package. As in previous exercises the conversion units are calculated. What are the measurement units for these data?\n\nlibrary(Distance)\ndata(sikadeer)\nconversion.factor &lt;- convert_units(\"centimeter\", \"kilometer\", \"square kilometer\")"
  },
  {
    "objectID": "10-multipliers/R-prac/Pr10-instructions.html#fit-detection-function-to-dung-pellets",
    "href": "10-multipliers/R-prac/Pr10-instructions.html#fit-detection-function-to-dung-pellets",
    "title": "Analysis using multipliers",
    "section": "Fit detection function to dung pellets",
    "text": "Fit detection function to dung pellets\nFit the usual series of models (i.e. half normal, hazard rate, uniform) models to the distances to pellet groups and decide on a detection function (don’t spend too long on this). Call your model deer.df. This detection function will be used to obtain \\(\\hat D_{\\textrm{pellet groups}}\\).\nHave a look at the Summary statistics for this model - what do you notice about the allocation of search effort in each woodland?"
  },
  {
    "objectID": "10-multipliers/R-prac/Pr10-instructions.html#multipliers",
    "href": "10-multipliers/R-prac/Pr10-instructions.html#multipliers",
    "title": "Analysis using multipliers",
    "section": "Multipliers",
    "text": "Multipliers\nThe next step is to create an object which contains the multipliers we wish to use. We already have estimates of dung production rates but need similar information on dung decay (or persistence) rate.\nData to calculate this has been collected in the file IntroDS_9.1.csv that can be read from the Github internet repository. Following code comes from Meredith (2017).\n\nMIKE.persistence &lt;- function(DATA) {\n  \n#  Purpose: calculate mean persistence time (mean time to decay) for dung/nest data \n#  Input: data frame with at least two columns:\n#         DAYS - calendar day on which dung status was observed\n#         STATE - dung status: 1-intact, 0-decayed\n#  Output: point estimate, standard error and CV of mean persistence time\n#\n#  Attribution: code from Mike Meredith website: \n#      http://www.mikemeredith.net/blog/2017/Sign_persistence.htm \n#        (site no longer maintained)\n#   Citing: CITES elephant protocol\n#      https://cites.org/sites/default/files/common/prog/mike/survey/dung_standards.pdf\n  \n  ##   Fit logistic regression model to STATE on DAYS, extract coefficients\n  dung.glm &lt;- glm(STATE ~ DAYS, data=DATA, family=binomial(link = \"logit\"))\n  betas &lt;- coefficients(dung.glm)\n  ##   Calculate mean persistence time\n  mean.decay &lt;- -(1+exp(-betas[1])) * log(1+exp(betas[1])) / betas[2]\n  ## Calculate the variance of the estimate\n  vcovar &lt;- vcov(dung.glm)\n  var0 &lt;- vcovar[1,1]  # variance of beta0\n  var1 &lt;- vcovar[2,2]  # variance of beta1\n  covar &lt;- vcovar[2,1] # covariance\n  deriv0 &lt;- -(1-exp(-betas[1]) * log(1+exp(betas[1])))/betas[2]\n  deriv1 &lt;- -mean.decay/betas[2]\n  var.mean &lt;- var0*deriv0^2 + 2*covar*deriv0*deriv1 + var1*deriv1^2\n  ## Calculate the SE and CV and return\n  se.mean &lt;- sqrt(var.mean)\n  cv.mean &lt;- se.mean/mean.decay\n  out &lt;- c(mean.decay, se.mean, 100*cv.mean)\n  names(out) &lt;- c(\"Mean persistence time\", \"SE\", \"%CV\")\n  plot(decay$DAYS, jitter(decay$STATE, amount=0.10), xlab=\"Days since initiation\",\n       ylab=\"Dung persists (yes=1)\",\n       main=\"Eight dung piles revisited over time\")\n  curve(predict(dung.glm, data.frame(DAYS=x), type=\"resp\"), add=TRUE)\n  abline(v=mean.decay, lwd=2, lty=3)\n  return(out)\n}\ngithub &lt;- \"https://raw.githubusercontent.com/\"\nrepo &lt;- \"distanceworkshops/async2024-2/main/\"\nfilename &lt;- \"10-multipliers/R-prac/IntroDS_9.1.csv\"\ndecay &lt;- read.csv(paste0(github, repo, filename))\npersistence.time &lt;- MIKE.persistence(decay)\nprint(persistence.time)\n\nRunning the above command should have produced a plot of dung persistence versus days since produced and fitted a logistic regression (this is like a simple linear regression but restricts the response to taking values between 0 and 1). Note the points can in reality only take values between 0 and 1 but for the purposes of plotting have been ‘jittered’ to avoid over-plotting.\nAn estimate of mean persistence time and measure of variability are also provided - make a note of these as they will be required below.\nAs stated above, we want an object which contains information on the dung production rate (and standard error) and dung decay rate (and standard error). The following command creates a list containing two data frames:\n\ncreation contains estimates of the dung production rate and associated standard error\ndecay contains the dung decay rate and associated standard error where XX and YY are the estimates you obtained from the dung decay rate analysis.\n\n\n# Create list of multipliers\nmult &lt;- list(creation = data.frame(rate=25, SE=0),\n#             decay    = data.frame(rate=XX, SE=YY))\nprint(mult)\n\nThe final step is to use these multipliers to convert \\(\\hat D_{\\textrm{pellet groups}}\\) to \\(\\hat D_{\\textrm{deer}}\\) (as in the equations above) - for this we need to employ the dht2 function. In the command below the multipliers= argument allows us to specify the rates and standard errors. There are a couple of other function arguments that need some explanation:\n\nstrat_formula=~Region.Label is specified to take into account the design (i.e. different woodlands or blocks).\nstratification=\"effort_sum\" is specified because we want to produce an overall estimate density that is the mean of the woodland specific densities weighted by effort allocated within each block.\ndeer.df is the detection function you have fitted.\n\n\n# Weight by effort because we have repeats\ndeer.ests &lt;- dht2(deer.df, flatfile=sikadeer, strat_formula=~Region.Label,\n                 convert_units=conversion.factor, multipliers=mult, \n                 stratification=\"effort_sum\", total_area=13.9)\nprint(deer.ests)\n\nThe function dht2 also provides information on the components of variance. Make a note of the these (contribution of detection function, encounter rate, decay rate and what happened to production rate component?) in each strata."
  },
  {
    "objectID": "05-points/R-prac/Pr5-instructions.html",
    "href": "05-points/R-prac/Pr5-instructions.html",
    "title": "Point transect sampling",
    "section": "",
    "text": "The purpose of this exercise is to analyse point transect survey data: it can sometimes be more difficult than line transect data. In the first problem, the data are simulated and so the true density is known. In the second problem, two different data collection methods were used to survey song birds."
  },
  {
    "objectID": "05-points/R-prac/Pr5-instructions.html#probability-density-function",
    "href": "05-points/R-prac/Pr5-instructions.html#probability-density-function",
    "title": "Point transect sampling",
    "section": "Probability density function",
    "text": "Probability density function\nTo plot the more informative probability density function (pdf), an additional argument is required in the plot() function:\n\nplot(ptdat.hn, pdf=TRUE)"
  },
  {
    "objectID": "05-points/R-prac/Pr5-instructions.html#analyse-both-conventional-and-snapshot-data-sets",
    "href": "05-points/R-prac/Pr5-instructions.html#analyse-both-conventional-and-snapshot-data-sets",
    "title": "Point transect sampling",
    "section": "Analyse both conventional and snapshot data sets",
    "text": "Analyse both conventional and snapshot data sets\nWhat to do:\n\nSelect a simple model for exploratory data analysis. Experiment with different truncation distances, \\(w\\), and select a suitable value for each method. Are there any potential problems with any of the data sets?\nTry other models and model options. Use plots, AIC values and goodness-of-fit test statistics to determine an adequate model.\nRecord your estimates of density and corresponding confidence interval for each method."
  },
  {
    "objectID": "10-multipliers/R-prac/Prac10_solution.html",
    "href": "10-multipliers/R-prac/Prac10_solution.html",
    "title": "Analysis with multipliers solution",
    "section": "",
    "text": "Solution\n\n\n\nAnalysis with multipliers\n\n\n\nDung survey of deer\nReturning to the data described in Marques et al. (2001), the following code loads the relevant packages and data. The perpendicular distances are measured in centimetres, effort along the transects measured in kilometres and areas in square kilometres.\n\nlibrary(Distance)\ndata(sikadeer)\nconversion.factor &lt;- convert_units(\"centimeter\", \"kilometer\", \n                                   \"square kilometer\")\n\nHere we did not perform a comprehensive examination of fitting a detection function to the detected pellet groups, however, as a general guideline, we truncated the longest 10% perpendicular distances.\n\ndeer.df &lt;- ds(sikadeer, key=\"hn\", truncation=\"10%\", convert_units = conversion.factor)\nplot(deer.df)\n\n\n\nprint(deer.df$dht$individuals$summary)\n\n  Region Area CoveredArea Effort    n  k        ER      se.ER     cv.ER\n1      A 13.9    0.005950   1.70 1217 13 715.88234 119.918872 0.1675120\n2      B 10.3    0.003850   1.10  396 10 359.99999  86.859289 0.2412758\n3      C  8.6    0.001575   0.45   17  3  37.77778   8.521202 0.2255612\n4      E  8.0    0.002975   0.85   30  5  35.29412  16.568939 0.4694533\n5      F 14.0    0.000700   0.20   29  1 145.00000   0.000000 0.0000000\n6      G 15.2    0.001400   0.40   32  3  80.00000  39.686269 0.4960784\n7      H 11.3    0.000700   0.20    3  1  15.00000   0.000000 0.0000000\n8      J  9.6    0.000350   0.10    7  1  70.00000   0.000000 0.0000000\n9  Total 90.9    0.017500   5.00 1731 37 201.90876   0.000000 0.0000000\n\n\nThe summary above shows that in blocks F, H and J there was only one transect and, as a consequence, it is not possible to calculate a variance empirically for the encounter rate in those blocks.\n\n\nEstimating decay rate from data\nA paper by Laing et al. (2003) describes field protocol for collecting data to estimate the mean persistence time of dung or nests to be used as multipliers. The code segment shown earlier analyses a file of such data via logistic regression to produce an estimate of mean persistence time and its associated uncertainty.\n\n\n\n\n\nMean persistence time                    SE                   %CV \n           163.396748             14.226998              8.707026 \n\n\nUsing the output from calling the MIKE.persistence function, the multipliers can be specified:\n\n# Create list of multipliers\nmult &lt;- list(creation = data.frame(rate=25, SE=0),\n             decay    = data.frame(rate=163, SE=14))\nprint(mult)\n\n$creation\n  rate SE\n1   25  0\n\n$decay\n  rate SE\n1  163 14\n\ndeer_ests &lt;- dht2(deer.df, flatfile=sikadeer, strat_formula=~Region.Label,\n                  convert_units=conversion.factor, multipliers=mult, \n                  stratification=\"effort_sum\", total_area = 100)\nprint(deer_ests, report=\"abundance\")\n\nAbundance estimates from distance sampling\nStratification : effort_sum \nVariance       : R2, n/L \nMultipliers    : creation, decay \nSample fraction : 1 \n\n\nSummary statistics:\n Region.Label  Area CoveredArea Effort    n  k      ER   se.ER cv.ER\n            A  13.9    0.005950   1.70 1217 13 715.882 119.919 0.168\n            B  10.3    0.003850   1.10  396 10 360.000  86.859 0.241\n            C   8.6    0.001575   0.45   17  3  37.778   8.521 0.226\n            E   8.0    0.002975   0.85   30  5  35.294  16.569 0.469\n            F  14.0    0.000700   0.20   29  1 145.000   0.000 0.000\n            G  15.2    0.001400   0.40   32  3  80.000  39.686 0.496\n            H  11.3    0.000700   0.20    3  1  15.000   0.000 0.000\n            J   9.6    0.000350   0.10    7  1  70.000   0.000 0.000\n        Total 100.0    0.017500   5.00 1731 37 346.200  45.234 0.131\n\nAbundance estimates:\n Region.Label Estimate      se    cv  LCI  UCI        df\n            A     1027 197.474 0.192  691 1527    20.797\n            B      383  99.171 0.259  220  667    11.955\n            C       34   8.200 0.244   15   75     2.759\n            E       29  13.959 0.479    9   99     4.329\n            F      210  19.752 0.094  174  252 60314.199\n            G      126  63.399 0.505   18  858     2.147\n            H       18   1.649 0.094   15   21 60314.199\n            J       69   6.539 0.094   58   83 60314.199\n        Total     3575 575.860 0.161 2560 4990    20.215\n\nComponent percentages of variance:\n Region.Label Detection    ER Multipliers\n            A      4.07 75.96       19.97\n            B      2.24 86.76       10.99\n            C      2.52 85.14       12.34\n            E      0.66 96.13        3.22\n            F     16.93  0.00       83.07\n            G      0.59 96.52        2.89\n            H     16.93  0.00       83.07\n            J     16.93  0.00       83.07\n        Total      8.09 91.91        0.00\n\n\nThere are a few things to notice:\n\noverall estimate of density\n\nmost effort took place in woodland A where deer density was high. Therefore, the overall estimate is between the estimated density in woodland A and the lower densities in the other woodlands.\n\ncomponents of variance\n\nwe now have uncertainty associated with the encounter rate, detection function and decay rate (note there was no uncertainty associated with the production rate) and so the components of variation for all three components are provided.\n\n\nIn woodland A, there were 13 transects on which over 1,200 pellet groups were detected: uncertainty in the estimated density was 19% and the variance components were apportioned as detection probability 4%, encounter rate 76% and multipliers 20%.\nIn woodland E, there were 5 transects and 30 pellet groups resulting in a coefficient of variation (CV) of 48%: the variance components were apportioned as detection probability 0.7%, encounter rate 96% and multipliers 3%.\nIn woodland F only a single transect was placed and the CV of density of 9% was apportioned as detection probability 17% and multipliers 83%. Do you trust this assessment of uncertainty in the density of deer in this woodland? We are missing a component of variation because we were negligent in placing only a single transect in this woodland and so are left to ‘assume’ there is no variability in encounter rate in this woodland.\nBy the same token, we are left to assume there is no variability in production rates between deer because we have not included a measure of uncertainty in this facet of our analysis.\n\n\nCue counting survey of songbirds\nAnalysis of the cue count data of winter wrens described by Buckland (2006).\n\ndata(wren_cuecount)\ncuerate &lt;- unique(wren_cuecount[ , c(\"Cue.rate\",\"Cue.rate.SE\")])\nnames(cuerate) &lt;- c(\"rate\", \"SE\")\nmult &lt;- list(creation=cuerate)\nprint(mult)\n\n$creation\n    rate     SE\n1 1.4558 0.2428\n\n# Search time is the effort - this is 2 * 5min visits\nwren_cuecount$Effort &lt;- wren_cuecount$Search.time\nw3.hr &lt;- ds(wren_cuecount, transect=\"point\", key=\"hr\", adjustment=NULL, truncation=92.5)\n\nThe sampling fraction for these data will be 1 because the full circle around the observer was searched.\n\nconversion.factor &lt;- convert_units(\"meter\", NULL, \"hectare\")\nw3.est &lt;- dht2(w3.hr, flatfile=wren_cuecount, strat_formula=~1,\n               multipliers=mult, convert_units=conversion.factor)\n# NB \"Effort\" here is sum(Search.time) in minutes\n# NB \"CoveredArea\" here is pi * w^2 * sum(Search.time)\nprint(w3.est, report=\"density\")\n\nDensity estimates from distance sampling\nStratification : geographical \nVariance       : P2, n/L \nMultipliers    : creation \nSample fraction : 1 \n\n\nSummary statistics:\n .Label Area CoveredArea Effort   n  k    ER se.ER cv.ER\n  Total 33.2    860.1681    320 765 32 2.391 0.236 0.099\n\nDensity estimates:\n .Label Estimate    se  cv    LCI    UCI      df\n  Total   1.2092 0.242 0.2 0.8195 1.7843 522.541\n\nComponent percentages of variance:\n .Label Detection    ER Multipliers\n  Total      6.14 24.33       69.54\n\n\nNote the large proportion of the uncertainty in winter wren density stems from variability in cue (song) rate. Analyses of the cue count data are necessarily rather subjective as the data show substantial over-dispersion (a single bird may give many song bursts all from the same location during a five minute count). In this circumstance, goodness-of-fit tests are misleading and care must be taken not to over-fit the data (i.e. fit a complicated detection function).\n\nplot(w3.hr, pdf=TRUE, main=\"Cue distances of winter wren.\")\ngof_ds(w3.hr)\n\n\n\n\n\n\n\n\n\n\n\n\nGoodness of fit results for ddf object\n\nDistance sampling Cramer-von Mises test (unweighted)\nTest statistic = 1.70062 p-value = 6.04794e-05\n\n\n\n\n\n\n\n\n\nReferences\n\nBuckland, S. T. (2006). Point-transect surveys for songbirds: Robust methodologies. The Auk, 123(2), 345–357. https://doi.org/10.1642/0004-8038(2006)123[345:PSFSRM]2.0.CO;2\n\n\nLaing, S. E., Buckland, S. T., Burn, R. W., Lambie, D., & Amphlett, A. (2003). Dung and nest surveys: Estimating decay rate. Journal of Applied Ecology, 40, 1102–1111. https://doi.org/10.1111/j.1365-2664.2003.00861.x\n\n\nMarques, F. F. C., Buckland, S. T., Goffin, D., Dixon, C. E., Borchers, D. L., Mayle, B. A., & Peace, A. J. (2001). Estimating deer abundance from line transect surveys of dung: sika deer in southern Scotland. Journal of Applied Ecology, 38(2), 349–363. https://doi.org/10.1046/j.1365-2664.2001.00584.x"
  },
  {
    "objectID": "10-multipliers/DistWin-prac/Pr10-instruction-DistWin.html",
    "href": "10-multipliers/DistWin-prac/Pr10-instruction-DistWin.html",
    "title": "Analysis with the use of multipliers",
    "section": "",
    "text": "Analysis with the use of multipliers"
  },
  {
    "objectID": "10-multipliers/DistWin-prac/Pr10-instruction-DistWin.html#the-problem",
    "href": "10-multipliers/DistWin-prac/Pr10-instruction-DistWin.html#the-problem",
    "title": "Analysis with the use of multipliers",
    "section": "The Problem",
    "text": "The Problem\nThe question is how to estimate of the density of sika deer in a number of woodlands in the Scottish Borders. These animals are quite shy and often will be alert to the presence of an observer before the observer detects them, making surveys of the deer challenging. As a consequence, indirect estimation methods have been applied to this problem. In this manner, an estimate of density is produced for some sign generated by deer (faecal pellets) and this estimate is transformed to density of deer by\n\\[\\hat{D}_{\\text{deer}} = \\frac{\\frac{\\hat{D}_{{\\text{pellet group}}}}{\\text{mean time to decay}}}{\\text{dung production rate (per animal)}} = \\frac{\\text{dung deposited daily}}{\\text{dung production rate}}\\]\nWe will produce a pellet group density estimate, then adjust it accordingly to account for the deposition and decay processes operating during the time the data are being acquired. We will also take uncertainty in the production and decay rates into account in our final estimate of deer density. The complete study is described in Marques et al. (2001).\nThe Data\n Data from 9 woodlands were collected and reside in the Distance for Windows project Deer pellets.zip The design of the survey is shown at right (note differing amounts of effort in different woodlands based on information derived from pilot surveys).\nIn addition to these data, we also require estimates of the defecation rate. From a consultation with the literature, we learn that sika deer deposit 25 pellet groups daily. The literature source did not provide a measure of variability of this estimate. During the course of our surveys we also followed the fate of some marked pellet groups to estimate the disappearance (decay) rates of a group. A thorough discussion of methods useful for estimating decay rates and associated measures of precision can be found in Laing et al. (2003).\nThere are many factors that might influence both deposition and decay rates, and for purposes of this exercise we will make the simplifying assumption that decay rate is homogeneous across these woodlands; with their mean time to decay of 163 days and a standard error of 13 days. However if you were to conduct a survey such as this, you would want to investigate this assumption more thoroughly."
  },
  {
    "objectID": "10-multipliers/DistWin-prac/Pr10-instruction-DistWin.html#analysis-exercises",
    "href": "10-multipliers/DistWin-prac/Pr10-instruction-DistWin.html#analysis-exercises",
    "title": "Analysis with the use of multipliers",
    "section": "Analysis Exercises",
    "text": "Analysis Exercises\nUse the Distance project Deer pellets.zip for the following analyses.\n\nAdjust the multipliers in the project (replacing the place-holders in the project, with values provided in the previous section of this exercise).\nFit the usual series of models (uniform, half normal, and hazard rate) models to the data.\nSelect the Multipliers button in the Model Definition Properties to specify the layer and the field in the project database for the multipliers you wish to employ (along with their measure of precision).\nProduce estimates using the woodland as strata, pooling data across strata for fitting the detection function, but using woodland-specific encounter rate to produce woodland-specific estimates of density.\nProduce an overall estimate of density as mean of woodland-specific densities weighted by the effort allocated within each woodlot.\nMake special note of the components of variance (contribution of detection function, encounter rate, decay rate, and what happened to defecation rate component?) in each of the strata."
  },
  {
    "objectID": "10-multipliers/DistWin-prac/Pr10-instruction-DistWin.html#the-data",
    "href": "10-multipliers/DistWin-prac/Pr10-instruction-DistWin.html#the-data",
    "title": "Analysis with the use of multipliers",
    "section": "The Data",
    "text": "The Data\n Data from 9 woodlands were collected and reside in the Distance for Windows project Deer pellets.zip The design of the survey is shown at right (note differing amounts of effort in different woodlands based on information derived from pilot surveys).\nIn addition to these data, we also require estimates of the defecation rate. From a consultation with the literature, we learn that sika deer deposit 25 pellet groups daily. The literature source did not provide a measure of variability of this estimate. During the course of our surveys we also followed the fate of some marked pellet groups to estimate the disappearance (decay) rates of a group. A thorough discussion of methods useful for estimating decay rates and associated measures of precision can be found in Laing et al. (2003).\nThere are many factors that might influence both deposition and decay rates, and for purposes of this exercise we will make the simplifying assumption that decay rate is homogeneous across these woodlands; with their mean time to decay of 163 days and a standard error of 13 days. However if you were to conduct a survey such as this, you would want to investigate this assumption more thoroughly."
  },
  {
    "objectID": "10-multipliers/DistWin-prac/Pr10-solution-DistWin.html",
    "href": "10-multipliers/DistWin-prac/Pr10-solution-DistWin.html",
    "title": "Analysis with the use of multipliers",
    "section": "",
    "text": "Analysis with the use of multipliers"
  },
  {
    "objectID": "10-multipliers/DistWin-prac/Pr10-solution-DistWin.html#component-percentages-of-vard",
    "href": "10-multipliers/DistWin-prac/Pr10-solution-DistWin.html#component-percentages-of-vard",
    "title": "Analysis with the use of multipliers",
    "section": "Component Percentages of Var(D)",
    "text": "Component Percentages of Var(D)\n\n\n\nDetection probability\nEncounter rate\nDecay rate\n\n\n\n\n4.0\n79.1\n16.9\n\n\n\nwhereas woodlot E had 5 transects, but only 30 detections overall (resulting in a CV of 48%)\n\n\n\nDetection probability\nEncounter rate\nDecay rate\n\n\n\n\n0.6\n96.9\n2.5\n\n\n\nIn woodlot F, were only a single transect was placed, the CV of density was 8.9% with the allocation being\n\n\n\nDetection probability\nEncounter rate\nDecay rate\n\n\n\n\n19.1\n0.0\n80.9\n\n\n\nDo you trust this assessment of uncertainty in the density of deer in this woodlot? We are missing a component of variation because we were negligent in placing only a single transect in this woodlot, and so are left to assume there is no variability in encounter rate in this woodlot.\nBy the same token, we are left to assume there is no variability in defecation rates between deer because we have no measure of uncertainty in this facet of our assessment of deer densities."
  },
  {
    "objectID": "10-multipliers/DistWin-prac/Pr10-solution-DistWin.html#results",
    "href": "10-multipliers/DistWin-prac/Pr10-solution-DistWin.html#results",
    "title": "Analysis with the use of multipliers",
    "section": "Results",
    "text": "Results\nProduce an overall estimate of density as mean of woodland-specific densities weighted by the effort allocated within each woodlot.\n\nWith considerable effort allocated in woodlot A, where deer density is high, the overall estimate of density is between the estimated density in woodlot A of 74 deer per km-2 and the lower densities in the remaining woodlots.\n\nMake special note of the components of variance (contribution of detection function, encounter rate, decay rate, and what happened to defecation rate component?) in each of the strata.\n\nBecause we now have uncertainty associated not only with the detection function and encounter rate, but also decay rate we are presented with these component of variability for each of the strata for which we requested estimates of density.\n\nIn woodlot A, there were 13 transects on which over 1200 pellet groups were detected; uncertainty in the estimated density was 19.0% and the variance components were apportioned as\nComponent Percentages of Var(D)\n\n\n\nDetection probability\nEncounter rate\nDecay rate\n\n\n\n\n4.0\n79.1\n16.9\n\n\n\nwhereas woodlot E had 5 transects, but only 30 detections overall (resulting in a CV of 48%)\n\n\n\nDetection probability\nEncounter rate\nDecay rate\n\n\n\n\n0.6\n96.9\n2.5\n\n\n\nIn woodlot F, were only a single transect was placed, the CV of density was 8.9% with the allocation being\n\n\n\nDetection probability\nEncounter rate\nDecay rate\n\n\n\n\n19.1\n0.0\n80.9\n\n\n\nDo you trust this assessment of uncertainty in the density of deer in this woodlot? We are missing a component of variation because we were negligent in placing only a single transect in this woodlot, and so are left to assume there is no variability in encounter rate in this woodlot.\nBy the same token, we are left to assume there is no variability in defecation rates between deer because we have no measure of uncertainty in this facet of our assessment of deer densities."
  },
  {
    "objectID": "11-mrds/R-prac/Pr11-instructions-R.html",
    "href": "11-mrds/R-prac/Pr11-instructions-R.html",
    "title": "Analysis of double-platform data",
    "section": "",
    "text": "Analysis of double-platform data\nThis version of the practical is for those who would like to conduct the analysis in R using the package mrds (Laake et al., 2023). There is a separate version for conducting the analysis in Distance for Windows (Thomas et al., 2010).\nThe first part of this practical involves initial analysis of a survey of a known number of golf tees. This is intended mainly to familiarise you with the mrds function.\nThe second part of the practical involves more detailed analysis of the golf tee data, and an exploration of the double-platform data structure.\nThe third part of the practical involves analysis of the pack-ice seal survey data of Borchers et al. (2006) and Southwell et al. (2007).\nTo help understand the terminology used in MRDS and the output produced by mrds, there is a guide available ‘Interpreting MRDS output’."
  },
  {
    "objectID": "11-mrds/R-prac/Pr11-instructions-R.html#golf-tee-survey",
    "href": "11-mrds/R-prac/Pr11-instructions-R.html#golf-tee-survey",
    "title": "Analysis of double-platform data",
    "section": "Golf tee survey",
    "text": "Golf tee survey\nThese data come from a survey of golf tees which conducted by statistics students at the University of St Andrews. The data were collected along transect lines, 210 metres in total. A distance of 4 metres out from the centre line was searched and, for the purposes of this exercise, we assume that this comprised the total study area, which was divided into two strata. There were 250 clusters of tees in total and 760 individual tees in total.\nThe population was independently surveyed by two observer teams. The following data were recorded for each detected group: perpendicular distance, cluster size, observer (team 1 or 2), ‘sex’ (males are yellow and females are green and golf tees occur in single-sex clusters) and ‘exposure’. Exposure was a subjective judgment of whether the cluster was substantially obscured by grass (exposure=0) or not (exposure=1). The lengths of grass varied along the transect line and the grass was slightly more yellow along one part of the line compared to the rest.\nThe golf tee dataset is provided as part of the mrds package.\nOpen R and load the mrds package and golf tee dataset (called book.tee.data). The elements required for an MRDS analysis are contained within the object dataset. These data are in a hierarchical structure (rather than in a ‘flat file’ format) so that there are separate elements for observations, samples and regions. In the code below, each of these tables is extracted to avoid typing long names.\n\n# Load libraries\nlibrary(knitr) #Used to knit this markdown document together\nlibrary(mrds)\n#Note - the Distance package is also used in the Crabeater seal example, to access\n# the checkdata function, and to do an MCDS analysis.\n\n# Access the golf tee data\ndata(book.tee.data)\n\n# Extract the list elements from the dataset into easy-to-access objects\ndetections &lt;- book.tee.data$book.tee.dataframe # detection information\nregion &lt;- book.tee.data$book.tee.region # region info\nsamples &lt;- book.tee.data$book.tee.samples # transect info\nobs &lt;- book.tee.data$book.tee.obs # links detections to transects and regions\n\n# In the detections data frame, define sex and exposure as factor variables \ndetections$sex &lt;- as.factor(detections$sex)\ndetections$exposure &lt;- as.factor(detections$exposure)"
  },
  {
    "objectID": "11-mrds/R-prac/Pr11-instructions-R.html#golf-tee-survey-analyses",
    "href": "11-mrds/R-prac/Pr11-instructions-R.html#golf-tee-survey-analyses",
    "title": "Analysis of double-platform data",
    "section": "Golf tee survey analyses",
    "text": "Golf tee survey analyses\n\nEstimation of p: distance only\nWe will start by analysing these data assuming that Observer 2 was generating trials for Observer 1 but not vice versa, i.e. trial configuration where Observer 1 is the primary and Observer 2 is the tracker. (The data could also be analysed in independent observer configuration - you are welcome to try this for yourself). We begin by assuming full independence (i.e. detections between observers are independent at all distances): this requires only a mark-recapture (MR) model and, to start with, perpendicular distance will be included as the only covariate.\nRemember that ? or help can be used to find out more about any of the functions used – e.g., ?ddf will tell you more about the ddf function.\n\n# Fit trial configuration with full independence model\nfi.mr.dist &lt;- ddf(method='trial.fi', mrmodel=~glm(link='logit',formula=~distance),\n                  data=detections, meta.data=list(width=4))\n\n\nExamining mrds output\nHaving fitted the model, we can create tables summarizing the detection data. In the commands below, the tables are created using the det.tables function and saved to detection.tables.\n\n# Create a set of tables summarizing the double observer data \ndetection.tables &lt;- det.tables(fi.mr.dist)\n# Print these detection tables\ndetection.tables\n\n\nObserver 1 detections\n           Detected\n            Missed Detected\n  [0,0.4]        1       25\n  (0.4,0.8]      2       16\n  (0.8,1.2]      2       16\n  (1.2,1.6]      6       22\n  (1.6,2]        5        9\n  (2,2.4]        2       10\n  (2.4,2.8]      6       12\n  (2.8,3.2]      6        9\n  (3.2,3.6]      2        3\n  (3.6,4]        6        2\n\nObserver 2 detections\n           Detected\n            Missed Detected\n  [0,0.4]        4       22\n  (0.4,0.8]      1       17\n  (0.8,1.2]      0       18\n  (1.2,1.6]      2       26\n  (1.6,2]        1       13\n  (2,2.4]        2       10\n  (2.4,2.8]      3       15\n  (2.8,3.2]      4       11\n  (3.2,3.6]      2        3\n  (3.6,4]        1        7\n\nDuplicate detections\n\n  [0,0.4] (0.4,0.8] (0.8,1.2] (1.2,1.6]   (1.6,2]   (2,2.4] (2.4,2.8] (2.8,3.2] \n       21        15        16        20         8         8         9         5 \n(3.2,3.6]   (3.6,4] \n        1         1 \n\nObserver 1 detections of those seen by Observer 2\n          Missed Detected Prop. detected\n[0,0.4]        1       21      0.9545455\n(0.4,0.8]      2       15      0.8823529\n(0.8,1.2]      2       16      0.8888889\n(1.2,1.6]      6       20      0.7692308\n(1.6,2]        5        8      0.6153846\n(2,2.4]        2        8      0.8000000\n(2.4,2.8]      6        9      0.6000000\n(2.8,3.2]      6        5      0.4545455\n(3.2,3.6]      2        1      0.3333333\n(3.6,4]        6        1      0.1428571\n\n\nThe information in detection summary tables can be plotted, but, in the interest of space, only one (out of six possible plots) is shown below.\n\n# Plot detection information, change number to see other plots\nplot(detection.tables, which=1)\n\n\n\n\nThe plot numbers are:\n\nHistograms of distances for detections by either, or both, observers. The shaded regions show the number for observer 1.\nHistograms of distances for detections by either, or both, observers. The shaded regions show the number for observer 2.\nHistograms of distances for duplicates (detected by both observers).\nHistogram of distances for detections by either, or both, observers. Not shown for trial configuration.\nHistograms of distances for observer 2. The shaded regions indicate the number of duplicates - for example, the shaded region is the number of clusters in each distance bin that were detected by Observer 1 given that they were also detected by Observer 2 (the “|” symbol in the plot legend means “given that”).\nHistograms of distances for observer 1. The shaded regions indicate the number of duplicates as for plot 5. Not shown for trial configuration.\n\nNote that if an independent observer configuration had been chosen, all plots would be available.\nA summary of the detection function model is available using the summary function. The Q-Q plot has the same interpretation as a Q-Q plot in a conventional, single platform analysis.\n\n# Produce a summary of the fitted detection function object\nsummary(fi.mr.dist)\n\n\nSummary for trial.fi object \nNumber of observations               :  162 \nNumber seen by primary               :  124 \nNumber seen by secondary (trials)    :  142 \nNumber seen by both (detected trials):  104 \nAIC                                  :  452.8094 \n\n\nConditional detection function parameters:\n             estimate        se\n(Intercept)  2.900233 0.4876238\ndistance    -1.058677 0.2235722\n\n                        Estimate          SE         CV\nAverage p              0.6423252  0.04069410 0.06335435\nAverage primary p(0)   0.9478579  0.06109656 0.06445750\nN in covered region  193.0486185 15.84826582 0.08209469\n\n# Produce goodness of fit statistics and a qq plot\ngof.result &lt;- ddf.gof(fi.mr.dist, \n                      main=\"Full independence, trial configuration\\ngoodness of fit Golf tee data\")\n\n\n\ngof.result\n\n\nGoodness of fit results for ddf object\n\nChi-square tests\n\nDistance sampling component:\n          [0,0.4] (0.4,0.8] (0.8,1.2] (1.2,1.6] (1.6,2] (2,2.4] (2.4,2.8]\nObserved   25.000    16.000    16.000    22.000   9.000  10.000    12.000\nExpected   18.068    17.479    16.650    15.527  14.079  12.327    10.361\nChisquare   2.659     0.125     0.025     2.698   1.833   0.439     0.259\n          (2.8,3.2] (3.2,3.6] (3.6,4]   Total\nObserved      9.000     3.000   2.000 124.000\nExpected      8.335     6.419   4.753 124.000\nChisquare     0.053     1.821   1.595  11.508\n\nNo degrees of freedom for test\n\nMark-recapture component:\nCapture History 01\n          [0,0.4] (0.4,0.8] (0.8,1.2] (1.2,1.6] (1.6,2] (2,2.4] (2.4,2.8]\nObserved        1         2         2         6       5       2         6\nExpected        1         2         3         5       4       4         7\nChisquare       0         0         0         0       1       1         0\n          (2.8,3.2] (3.2,3.6] (3.6,4] Total\nObserved          6         2       6    38\nExpected          6         2       5    38\nChisquare         0         0       0     2\nCapture History 11\n          [0,0.4] (0.4,0.8] (0.8,1.2] (1.2,1.6] (1.6,2] (2,2.4] (2.4,2.8]\nObserved       21        15        16        20       8       8         9\nExpected       21        15        15        21       9       6         8\nChisquare       0         0         0         0       0       0         0\n          (2.8,3.2] (3.2,3.6] (3.6,4] Total\nObserved          5         1       1   104\nExpected          5         1       2   104\nChisquare         0         0       0     1\n\n\nTotal chi-square = 14.888  P = 0.60351 with 17 degrees of freedom\n\nDistance sampling Cramer-von Mises test (unweighted)\nTest statistic = 0.294564 p-value = 0.140034\n\n# Extract chi-square statistics for reporting in the text below (see Markdown file for how this is done).\nchi.distance &lt;- gof.result$chisquare$chi1$chisq\nchi.markrecap &lt;- gof.result$chisquare$chi2$chisq\nchi.total &lt;- gof.result$chisquare$pooled.chi\n\nThe \\(\\chi^2\\) goodness-of-fit assessment shows the \\(\\chi^2\\) contribution from the distance sampling component to be 11.5 and the \\(\\chi^2\\) contribution from the mark-recapture component to be 3.4. The combination of these elements produces a total \\(\\chi^2\\) of 14.9 with 17 degrees of freedom, resulting in a \\(p\\)-value of 0.604\nThe mark-recapture model detection function can be plotted with the following code:\n\n# Divide the plot region into 2 columns\npar(mfrow=c(1,2))\n# Plot detection functions\nplot(fi.mr.dist)\n\n\n\n\n\nThe plot headed\n\n“Conditional detection probability” (the right hand plot) shows the proportion of Obs 2’s detections that were detected by Obs 1 (also see the detection tables). The fitted line is the estimated detection probability function for Obs 1 (given detection by Obs 2) - this is the MR model. Dots are estimated detection probabilities for each Obs 1 detection.\n“Observer=1 detections” (left hand plot) shows a histogram of Observer 1 detections with the estimated Observer 1 detection function (from the MR model) overlaid on it and adjusted for the estimated p(0). The dots show the estimated detection probability for all Observer 1 detections. Note that the MR model was not fitted to these data – it is the conditional data (right hand plot) that was used to fit the model. This plot is just shown to help you diagnose any issues in the fit – if there is dependency between observer detections then we’d expect the detection function to decrease slower than the histograms.\n\nIs there evidence of unmodelled heterogeneity? What do these results tell you about the estimates of p (average detection probability) and p(0) (detection probability at 0 distance)?\n\n\n\nEstimating abundance\nAbundance is estimated using the dht function. In this function, we need to supply information about the transects and survey regions.\n\n# Calculate density estimates using the dht function\ntee.abund &lt;- dht(model=fi.mr.dist, region.table=region, sample.table=samples, \n                 obs.table=obs)\n\n# Print out results in a nice format\nknitr::kable(tee.abund$individuals$summary, digits=2, \n      caption=\"Survey summary statistics for golftees\")\n\n\nSurvey summary statistics for golftees\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegion\nArea\nCoveredArea\nEffort\nn\nk\nER\nse.ER\ncv.ER\nmean.size\nse.mean\n\n\n\n\n1\n1040\n1040\n130\n229\n6\n1.76\n0.12\n0.07\n3.18\n0.21\n\n\n2\n640\n640\n80\n152\n5\n1.90\n0.33\n0.18\n2.92\n0.23\n\n\nTotal\n1680\n1680\n210\n381\n11\n1.81\n0.15\n0.08\n3.07\n0.15\n\n\n\n\nknitr::kable(tee.abund$individuals$N, digits=2, \n      caption=\"Abundance estimates for golftee population with two strata\")\n\n\nAbundance estimates for golftee population with two strata\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\n1\n356.52\n32.35\n0.09\n294.54\n431.53\n17.13\n\n\n2\n236.64\n44.14\n0.19\n147.33\n380.09\n5.06\n\n\nTotal\n593.16\n60.38\n0.10\n478.32\n735.57\n16.06\n\n\n\n\n\n\n\n\nEstimation of p: distance and other explanatory variables\nBelow is a model that includes size, sex and exposure covariates. Please spend a bit of time examining the model coefficients, goodness of fit, plots of the fitted detection functions, etc (you’ll need to write your own code for this).\n\n# Example of adding covariates to MR detection function\nfi.mr.dist.size.sex.exposure &lt;- ddf(method='trial.fi', \n                      mrmodel=~glm(link='logit',formula=~distance+size+sex+exposure),\n                      data=detections, meta.data=list(width=4))\n\nWe can use AIC to compare this with the previous model that just had distance as a covariate. The function AIC works on these objects:\n\nAIC(fi.mr.dist, fi.mr.dist.size.sex.exposure)\n\n                             df      AIC\nfi.mr.dist                    2 452.8094\nfi.mr.dist.size.sex.exposure  5 407.3974"
  },
  {
    "objectID": "11-mrds/R-prac/Pr11-instructions-R.html#further-analyses-of-golf-tee-data",
    "href": "11-mrds/R-prac/Pr11-instructions-R.html#further-analyses-of-golf-tee-data",
    "title": "Analysis of double-platform data",
    "section": "Further analyses of golf tee data",
    "text": "Further analyses of golf tee data\n\nEstimation of p: distance and other explanatory variables\nThe size covariate is the least significant of the covariates in the model fi.mr.dist.size.sex.exposure – its estimate is 0.078 with SE 0.183. So try creating a new model definition and analysis without this covariate. Does it have a lower AIC?\nYou can also try some models with interaction terms - you can specify these in the usual way in the model foruma with a * symbol. Don’t spend too long on full independence models, but move on to the next section.\n\n\nPoint independence\nA less restrictive assumption than full independence is point independence, which assumes that detections are only independent on the transect centre line i.e. at perpendicular distance zero.\nLet’s start by seeing if a simple point independence model is better than a simple full independence one. This requires that a distance sampling (DS) model is specified as well a MR model. Here we try a half-normal key function for the DS model.\n\n# Fit trial configuration with point independence model\npi.mr.dist &lt;- ddf(method='trial', \n                  mrmodel=~glm(link='logit', formula=~distance),\n                  dsmodel=~cds(key='hn'), \n                  data=detections, meta.data=list(width=4))\n\n# Summary pf the model \nsummary(pi.mr.dist)\n\n\nSummary for trial.fi object \nNumber of observations               :  162 \nNumber seen by primary               :  124 \nNumber seen by secondary (trials)    :  142 \nNumber seen by both (detected trials):  104 \nAIC                                  :  140.8887 \n\n\nConditional detection function parameters:\n             estimate        se\n(Intercept)  2.900233 0.4876238\ndistance    -1.058677 0.2235722\n\n                      Estimate         SE         CV\nAverage primary p(0) 0.9478579 0.02409996 0.02542571\n\n\n\nSummary for ds object\nNumber of observations :  124 \nDistance range         :  0  -  4 \nAIC                    :  311.1385 \nOptimisation           :  mrds (nlminb) \n\nDetection function:\n Half-normal key function \n\nDetection function parameters \nScale coefficient(s): \n             estimate         se\n(Intercept) 0.6632435 0.09981249\n\n           Estimate         SE         CV\nAverage p 0.5842744 0.04637627 0.07937412\n\n\nSummary for trial object\n\nTotal AIC value =  452.0272 \n                       Estimate          SE         CV\nAverage p             0.5538091  0.04615832 0.08334697\nN in covered region 223.9038534 22.99246338 0.10268900\n\n# Produce goodness of fit statistics and a qq plot\ngof.results &lt;- ddf.gof(pi.mr.dist, main=\"Point independence, trial configuration\\n goodness of fit Golftee data\")\n\n\n\n\nCompare the results with the corresponding full independence model. Which has the lower AIC? Which has an estimate closer to known true abundance.\n\nCovariates in the DS model\nTo include covariates in the DS detection function, we need to specify an MCDS model as follows:\n\n# Fit the PI-trial model - DS sex and MR distance \npi.mr.dist.ds.sex &lt;- ddf(method='trial', \n                         mrmodel=~glm(link='logit',formula=~distance),\n                         dsmodel=~mcds(key='hn',formula=~sex), \n                         data=detections, meta.data=list(width=4))\n\nUse the summary or AIC function to check the AIC and decide if you are going to include any additional covariates in the detection function.\nNow try a point independence model that has the preferred MR model from your full independence analyses. Which has the lower AIC and bias?\nFeel free to experiment some more with different models. What is your final best model? What is the estimate of p and p(0) for this model? Was all this modelling necessary in this instance, given the value of p(0)? How else could you have obtained a robust estimate of abundance?"
  },
  {
    "objectID": "11-mrds/R-prac/Pr11-instructions-R.html#data-structure",
    "href": "11-mrds/R-prac/Pr11-instructions-R.html#data-structure",
    "title": "Analysis of double-platform data",
    "section": "Data structure",
    "text": "Data structure\nBefore moving on to the second dataset, let’s have a look at the columns in the detections data because, for all mrds analyses, it needs to have a particular structure.\n\n# Check detections\nhead(detections)\n\n   object observer detected distance size sex exposure\n1       1        1        1     2.68    2   1        1\n21      1        2        0     2.68    2   1        1\n2       2        1        1     3.33    2   1        0\n22      2        2        0     3.33    2   1        0\n3       3        1        1     0.34    1   0        0\n23      3        2        0     0.34    1   0        0\n\n\nThe structure of the detection is as follows:\n\neach detected object (in this case the object was a group or cluster of golf tees) is given a unique number in the object column,\neach object occurs twice - once for observer 1 and once for observer 2,\nthe detected column indicates whether the object was seen (detected=1) or not seen (detected=0) by the observer,\nperpendicular distance is in the distance column and cluster size is in the size column (the same default names as for the ds function).\n\nTo ensure that the variables sex and exposure are treated correctly, we defined them as factor variables."
  },
  {
    "objectID": "11-mrds/R-prac/Pr11-instructions-R.html#crabeater-seal-data",
    "href": "11-mrds/R-prac/Pr11-instructions-R.html#crabeater-seal-data",
    "title": "Analysis of double-platform data",
    "section": "Crabeater seal data",
    "text": "Crabeater seal data\nThis analysis is described in Borchers et al. (2006) and Southwell et al. (2007). These data come from a helicopter survey of crabeater seals conducted by the Australian Antarctic Division within the pack-ice seals programme. The helicopter could only operate within a relatively short distance from the ice-breaker ship which acted as its base. The ice-breaker could only go where the pack ice was thin enough and so the aerial transects could not be located at random. This means that design-based estimation was not a valid option and so, in the published analysis, abundance was estimated using density surface modelling. For the purposes of this exercise, we concentrate on detection function estimation and create an artificial region as a device to produce abundance estimates.\nThere were four independent observers in the helicopter, two on each side (front and back). The front observers were considered to be one ‘team’ and the back observers were considered to be the other ‘team’. Various environmental factors were recorded. In addition to perpendicular distance, observer (1=front or 2=back) and cluster size, the following explanatory variables are available:\n\nside – the side of the helicopter from which seal were seen (L and R)\nexp – the experience (in survey hours) of the observer\nfatigue – the number of minutes the observer had been on duty on the current flight\ngscat – group size category (1, 2 and greater than or equal to 3)\nvis – visibility category (Poor, Good and Excellent)\nglare – whether there was glare (Yes or No)\nssmi – a measure of ice cover\naltitude – the height of the aircraft in metres\nobsname – unique identifier of observer\n\nThe data from the survey has been saved in a .csv file. This file is read into R using read.csv.\n\ncrabseal &lt;- read.csv(\"crabbieMRDS.csv\")\nstr(crabseal)\n\n'data.frame':   3480 obs. of  20 variables:\n $ Study.area  : chr  \"Nominal_area\" \"Nominal_area\" \"Nominal_area\" \"Nominal_area\" ...\n $ Region.Label: int  1 1 1 1 1 1 1 1 1 1 ...\n $ Area        : int  1000000 1000000 1000000 1000000 1000000 1000000 1000000 1000000 1000000 1000000 ...\n $ Sample.Label: chr  \"99A21\" \"99A21\" \"99A21\" \"99A21\" ...\n $ Effort      : num  59.7 59.7 59.7 59.7 59.7 ...\n $ distance    : num  144 144 125 125 421 ...\n $ size        : num  1 1 1 1 1 1 1 1 1 1 ...\n $ object      : int  54464 54464 54465 54465 54466 54466 54467 54467 54468 54468 ...\n $ observer    : int  1 2 1 2 1 2 1 2 1 2 ...\n $ detected    : int  1 1 1 1 0 1 1 1 1 1 ...\n $ side        : chr  \"R\" \"R\" \"L\" \"L\" ...\n $ exp         : num  0 178 212 0 212 ...\n $ fatigue     : num  61.9 61.9 62.6 62.6 62.9 ...\n $ gscat       : int  1 1 1 1 1 1 1 1 1 1 ...\n $ vis         : chr  \"G\" \"G\" \"G\" \"G\" ...\n $ glare       : chr  \"N\" \"N\" \"N\" \"N\" ...\n $ ssmi        : int  79 79 79 79 79 79 79 79 79 79 ...\n $ altitude    : num  43.1 43.1 43.1 43.1 43.1 ...\n $ obsname     : chr  \"YH\" \"HZ\" \"MF\" \"MH\" ...\n $ fold        : int  1 1 2 2 3 3 4 4 5 5 ...\n\n\nIf you’ve used Distance for Windows you might recognize some of the column names from that - indeed the dataset has been exported from Distance for Windows into the .csv file. The first column can be ignored. Region.Label and Area relate to the strata (their names and area - there’s only one in this dataset). Sample.Label and Effort relate to the transects. The columns distance onwards relate to the observations. You can see there are columns for each explanatory variable above, plus one additional one called fold that will enable use to pick a subset of the data (see later on).\nConvert the explanatory variables that should be fitted as factor variables into factors.\n\ncrabseal$side &lt;- as.factor(crabseal$side)\ncrabseal$vis &lt;- as.factor(crabseal$vis)\ncrabseal$glare &lt;- as.factor(crabseal$glare)\ncrabseal$observer &lt;- as.factor(crabseal$observer)\ncrabseal$obsname &lt;- as.factor(crabseal$obsname)"
  },
  {
    "objectID": "11-mrds/R-prac/Pr11-instructions-R.html#crabeater-seal-analyses",
    "href": "11-mrds/R-prac/Pr11-instructions-R.html#crabeater-seal-analyses",
    "title": "Analysis of double-platform data",
    "section": "Crabeater seal analyses",
    "text": "Crabeater seal analyses\nThe observer teams acted independently and so an ‘independent observer’ (IO) configuration can be specified. The code below fits simple models (i.e. distance only) with the full independence assumption and the point independence assumption. For each model, make a note of the estimated values for \\(p(0)\\) for each observer and the observers combined. Check goodness-of-fit and plot the detection function.\nFit an IO configuration assuming full independence:\n\n# IO configuration - full independence\n# MR model - distance only\n# Truncation 700m\nfi.mr.dist &lt;- ddf(method=\"io.fi\", mrmodel=~glm(link=\"logit\", formula=~distance),\n                 data=crabseal, meta.data=list(width=700))\nsummary(fi.mr.dist)\n\n\nSummary for io.fi object \nNumber of observations   :  1740 \nNumber seen by primary   :  1394 \nNumber seen by secondary :  1471 \nNumber seen by both      :  1125 \nAIC                      :  25681.52 \n\n\nConditional detection function parameters:\n                estimate           se\n(Intercept)  2.107762345 0.0994391199\ndistance    -0.003087713 0.0003159216\n\n                           Estimate           SE          CV\nAverage p                 0.9071952  0.009684936 0.010675692\nAverage primary p(0)      0.8916554  0.007472286 0.008380240\nAverage secondary p(0)    0.8916554  0.007472286 0.008380240\nAverage combined p(0)     0.9882614  0.004402403 0.004454695\nN in covered region    1917.9995344 24.808749358 0.012934700\n\n\nNext fit IO configuration assuming point independence. Specify a half-normal key function for the DS model; again only include perpendicular distance in the MR model.\n\n# IO configuration - point independence\n# MR model - distance only\n# DS model - half normal detection function, no additional covars\n# Truncation at 700m\npi.mr.dist.ds.hn &lt;- ddf(method=\"io\", dsmodel=~cds(key=\"hn\"),\n                 mrmodel=~glm(link=\"logit\", formula=~distance),\n                 data=crabseal, meta.data=list(width=700))\nsummary(pi.mr.dist.ds.hn)\n\n\nSummary for io.fi object \nNumber of observations   :  1740 \nNumber seen by primary   :  1394 \nNumber seen by secondary :  1471 \nNumber seen by both      :  1125 \nAIC                      :  3011.463 \n\n\nConditional detection function parameters:\n                estimate           se\n(Intercept)  2.107762345 0.0994391199\ndistance    -0.003087713 0.0003159216\n\n                        Estimate          SE          CV\nAverage primary p(0)   0.8916554 0.009606424 0.010773696\nAverage secondary p(0) 0.8916554 0.009606424 0.010773696\nAverage combined p(0)  0.9882614 0.002081609 0.002106335\n\n\nSummary for ds object\nNumber of observations :  1740 \nDistance range         :  0  -  700 \nAIC                    :  22314.4 \nOptimisation           :  mrds (nlminb) \n\nDetection function:\n Half-normal key function \n\nDetection function parameters \nScale coefficient(s): \n            estimate         se\n(Intercept) 5.828703 0.02685781\n\n           Estimate         SE         CV\nAverage p 0.5845871 0.01247826 0.02134542\n\n\nSummary for io object\nTotal AIC value :  25325.86 \n\n                        Estimate          SE         CV\nAverage p              0.5777249  0.01239167 0.02144909\nN in covered region 3011.8139214 79.84149372 0.02650944\n\n\nWhich of these models do you prefer? \nIf you have time, try a few models with covariates. However, this is a large dataset and so fitting models and obtaining model summaries can take a long time with complicated models. Given this and the fact that the exercise is just for practice, you may want to work with just a subset of the data – which is where the fold column in the dataset comes in. With this column, each observation is associated with a number from 1 to 10 (they are assigned systematically in order of the data, so the first observation is given number 1, the second 2, …, the 10th 10, the 11th 1 again, the 12th 2, etc). So, for example, you could pick out just the first and fifth ``fold’’ (i.e., just one fifth of the data) with\n\ncrabseal15 &lt;- crabseal[crabseal$fold %in% c(1, 5), ]\n\nand then use this to investigate covariate selection - for example comparing point independence models where the mr model has just distance in it vs one with distance and observer:\n\npi.mr.dist.ds.hn.fold15 &lt;- ddf(method=\"io\", dsmodel=~cds(key=\"hn\"),\n                 mrmodel=~glm(link=\"logit\", formula=~distance),\n                 data=crabseal15, meta.data=list(width=700))\npi.mr.dist.observer.ds.hn.fold15 &lt;- ddf(method=\"io\", dsmodel=~cds(key=\"hn\"),\n                 mrmodel=~glm(link=\"logit\", formula=~distance+observer),\n                 data=crabseal15, meta.data=list(width=700))\nAIC(pi.mr.dist.ds.hn.fold15, pi.mr.dist.observer.ds.hn.fold15)\n\n                                 df      AIC\npi.mr.dist.ds.hn.fold15           3 5068.746\npi.mr.dist.observer.ds.hn.fold15  4 5065.830\n\n\n\nEstimating abundance\nFollowing model criticism and selection, the abundance can be estimated – below we use the simple point independence model on the full dataset. The estimates of abundance for the study area are arbitrary because inference of the study was restricted to the covered region, hence, the estimates of abundance here are artificial. Nevertheless, we illustrate the method to estimate abundance. We require tables of the region, transects and detections – these can easily be created from the data using the checkdata function in the Distance package (the ::: is shorthand for accessing a function without loading a package). Using these tables, Horvitz-Thompson-like1 estimators can be applied to produce estimates of \\(\\hat{N}\\). The use of convert.units=0.001 adjusts the units of perpendicular distance measurement (m) to units of transect effort (km).\n\n# Create tables for estimating abundance \n# Selecting observer==1 ensures that observations in the obs.table are unique \ntables &lt;- Distance:::checkdata(crabseal[crabseal$observer==1, ])\n\n# Estimate abundance in covered region\npi.abund &lt;- dht(model=pi.mr.dist.ds.hn,\n                region=tables$region.table, \n                sample=tables$sample.table, obs=tables$obs.table,\n                se=TRUE, options=list(convert.units=0.001))\n\n# Pretty tables of data summary\nknitr::kable(pi.abund$individuals$summary, digits=3,\n      caption=\"Summary information from crabeater seal aerial survey.\")\n\n\nSummary information from crabeater seal aerial survey.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegion\nArea\nCoveredArea\nEffort\nn\nk\nER\nse.ER\ncv.ER\nmean.size\nse.mean\n\n\n\n\n1\n1e+06\n8594.082\n6138.63\n2053\n118\n0.334\n0.033\n0.097\n1.18\n0.013\n\n\n\n\n\n\n# Pretty tables of estimates of individual abundance\nknitr::kable(pi.abund$individual$N, digits=3,\n      caption=\"Crabeater seal abundance estimates for study area of arbitrary size.\")\n\n\nCrabeater seal abundance estimates for study area of arbitrary size.\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\nTotal\n413493.2\n41201.47\n0.1\n339670.9\n503359.5\n128.625\n\n\n\n\n\n\n\nCrabeater seals with MCDS (optional)\nWe can also analyse the crabeater seals data as if it were single platform data (i.e. ignoring that \\(p(0)\\) is less than 1). These data are available in crabbieMCDS.csv.\nThis short exercise guides you through the import of these data into R and fits a simple half-normal detection function examining the possible improvement of the model by incorporating side of plane and visibility covariates (using the full dataset).\n\n# Load Distance for MCDS \nlibrary(Distance)\n# Read in data\ncrab.covar &lt;- read.csv(\"crabbieMCDS.csv\")\n# Check data imported OK\nhead(crab.covar, n=3)\n\n    Study.area Region.Label    Area Sample.Label Effort distance size side\n1 Nominal_area            1 1000000        99A21  59.72   144.49    1    R\n2 Nominal_area            1 1000000        99A21  59.72   125.16    1    L\n3 Nominal_area            1 1000000        99A21  59.72   421.40    1    L\n    exp fatigue gscat vis glare ssmi altitude obsname fold\n1   0.0   61.90     1   G     N   79 43.05763      YH    1\n2 211.7   62.61     1   G     N   79 43.05763      MF    2\n3   0.0   62.86     1   G     N   79 43.05763      MH    3\n\n\nAfter checking that the data have been read into R appropriately, we are ready to fit a detection function.\nAs before, side of plane and visibility are assigned characters and so we need to tell R to treat them as factors.\n\n# Define factor variables\ncrab.covar$side &lt;- as.factor(crab.covar$side)\ncrab.covar$vis &lt;- as.factor(crab.covar$vis)\n\nWith two potential explanatory variables, there are a number of possible models. We start by fitting a detection function with side of plane as a covariate using a half-normal key function.\n\n# Fit HN key function with side of plane\nds.side &lt;- ds(crab.covar, key=\"hn\", formula=~side, truncation=700)\n\nModel contains covariate term(s): no adjustment terms will be included.\n\n\nFitting half-normal key function\n\n\nAIC= 22304.742\n\n\nWe would now like to assess the fit of this function to our data. Two visual assessments are provided by the panels below: histogram and fitted function on the left and Q-Q plot on the right.\n\n# Divide plot region\npar(mfrow = c(1, 2))\n# Create a title for the plot\nplot.title &lt;- \"Two sets of points\\none for each 'side' of plane\"\n# Plot model\nplot(ds.side, pch=19, cex=0.5, main=plot.title)\n# Plot qq plot\ngof.result &lt;- gof_ds(ds.side, lwd = 2, lty = 1, pch = \".\", cex = 0.5)\n# Extract gof statistics\nmessage &lt;- paste(\"CVM GOF p-value=\", round(gof.result$dsgof$CvM$p, 4))\n# Add gof stats to plot\ntext(0.6, 0.2, message, cex=0.5)\n\n\n\n\nHistogram and fitted half-normal detection function on left. Q-Q plot of detection function and data on right.\n\n\n\n\nThe code below fits the model without any covariates.\n\n# Fit HN key function with no covars and no adjustments\nds.nocov &lt;- ds(crab.covar, key=\"hn\", adjustment=NULL, truncation=700)\n\nFitting half-normal key function\n\n\nAIC= 22314.398\n\n\nAIC score for model without covariates is 22314.4 and AIC score for model with side as a covariate is 22304.74 so the model with side as a covariate is preferred.\nWe could also fit further detection functions and contrast the resulting models:\n\nwith visibility only\nwith side of plane and visibility (excluding an interaction).\n\nOut of the four possible models which is to be preferred?\nFurther modelling is possible. For example, we typically allow adjustment terms in CDS analyses (i.e., where there are not covariates), and it is also possible to include adjustment terms in MCDS analyses. Below is a model with half-normal key and AIC-based selection of cosine adjustments. How does the AIC of this model compare with those fitted previously?\n\n# Fit HN key function with no covars and no adjustments\nds.nocov.hncos &lt;- ds(crab.covar, key=\"hn\", adjustment=\"cos\", truncation=700)\n\nStarting AIC adjustment term selection.\n\n\nFitting half-normal key function\n\n\nAIC= 22314.398\n\n\nFitting half-normal key function with cosine(2) adjustments\n\n\nAIC= 22308.645\n\n\nFitting half-normal key function with cosine(2,3) adjustments\n\n\nAIC= 22304.015\n\n\nFitting half-normal key function with cosine(2,3,4) adjustments\n\n\nAIC= 22305.943\n\n\n\nHalf-normal key function with cosine(2,3) adjustments selected.\n\n\nWe could go on to produce abundance estimates from our preferred model using the dht function if we had provided information about the size of the crabeater seal study area.\nRather than fitting an MRDS model, as above, would an MCDS analyses have been adequate?"
  },
  {
    "objectID": "11-mrds/R-prac/Pr11-instructions-R.html#footnotes",
    "href": "11-mrds/R-prac/Pr11-instructions-R.html#footnotes",
    "title": "Analysis of double-platform data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\\(\\hat{N} = \\sum_{i=1}^n \\frac{1}{\\pi_i \\hat{p}_i}\\) where \\(n\\) is the number of observations, \\(\\pi_i\\) is the “coverage probability”, i.e., the probability the object is covered by a transect, and \\(\\hat{p}_i\\) is the estimated detection probability, i.e., the probability the object is detected given it is covered by a transect.↩︎"
  },
  {
    "objectID": "11-mrds/DistWin-prac/Supplement-interpretingoutput.html",
    "href": "11-mrds/DistWin-prac/Supplement-interpretingoutput.html",
    "title": "Introductory distance sampling training materials",
    "section": "",
    "text": "Interpreting MRDS output: making sense of all the numbers\nML Burt, CREEM, University of St Andrews (lb9@st-andrews.ac.uk)\nINTRODUCTION\nThe mrds package (Laake et al. 2019) was written to allow the user to estimate abundance from a mark-recapture distance sampling (MRDS) survey (i.e. taking account of imperfect detection both on and away from the transect centreline). On running an analysis lots of output is generated and wading through all the numbers can be a bit daunting for a first-time user. This document aims to help the user understand the output and find key bits of information. Some knowledge of conventional distance sampling (see Buckland et al. 2001) and MRDS is assumed; for details on undertaking a MRDS analysis see Burt et al. (2014).\nThe mrds package can be used in R (R core Team 2019) directly or via program Distance for Windows v7 (Thomas et al. 2010). The same output is available on both software platforms but in Distance for Windows output is generated automatically to a ‘Results’ tab and in R the user is required to do a bit of work to obtain the information (e.g. using the summary and plot commands).\nThe example data used here is taken from a survey of faecal pellets (Jenkins and Manly 2008; Example 1 of Burt et al. 2014). The Distance for Windows project of these data is available to download from http://distancesampling.org/Distance/example-projects (this will likely get moved to https://examples.distancesampling.org/ at some point). The focus of this study was to estimate the probability of detection of pellet groups rather than estimating density or abundance of animals. Output from an analysis of these example data is annotated (in red text) in the following sections but first terms and quantities are defined.\nThis is a work in progress; comments and suggestions to improve the document are welcome.\nGLOSSARY\nCovered region Region covered during the survey i.e. 2wL.\nStudy region Area of interest.\nDetected object This could be a group (cluster) of objects and group size is recorded or individual objects if cluster size is one for all objects.\nObserver One or more people performing the same role or could be an acoustic or digital observer.\nObserver 1 Also known as the Primary observer in a trial configuration setup.\nObserver 2 Also known as the Secondary observer in a trial configuration setup.\nDS model Distance sampling model; fitted assuming g(0)=1 i.e. certain detection on the transect centreline. This could be a conventional distance sampling model (Buckland et al. 2001) or a multiple covariate distance sampling model (Marques and Buckland 2004).\nMR model Mark-recapture model; logistic regression model \\(p_{j|3 - j}\\left( y,\\underline{z} \\right) = \\frac{exp(\\beta_{0} + \\beta_{1}y + \\sum_{k = 1}^{K}{\\beta_{k + 1}z_{k})}}{1 + exp(\\beta_{0} + \\beta_{1}y + \\sum_{k = 1}^{K}{\\beta_{k + 1}z_{k})}}\\)\n\nwhere j (j=1 or 2) is observer, the β’s are model coefficients, y is perpendicular distance and z are covariates.\n\nIO configuration Independent observer configuration; both observers search independently of the other observer. The probability of detection by either, or both, of the observers is of interest.\nTrial configuration One observer (often called the primary) searches independently. A second observer (often called the tracker) searches for animals, beyond the search distance of the primary, and tracks them in order to determine more easily if the primary also detects them. The probability of detection of the primary observer is of interest.\nFull independence Detections between observers are assumed to be independent at all perpendicular distances. This assumption requires only a MR model to be fitted.\nPoint independence Detections between observers are assumed to be independent only at the point where perpendicular distance is zero (i.e. on the transect centreline). This assumption requires both a DS and MR model to be fitted.\nNOTATION\nObserved values\nn1 total number of detected objects seen by observer 1 (also Primary observer)\nn2 total number of detected objects seen by observer 2 (also Secondary observer)\nnD total number of detected objects seen by both observers (Duplicate detections)\nnP = n1+n2-nD total number of detected objects (Pooled detections)\np1|2 = nD/n2 proportion detected by observer 1 of those seen by observer 2\np2|1 = nD/n1 proportion detected by observer 2 of those seen by observer 1\nEstimated values\nThe estimated probabilities are the probabilities of detection for detected objects. The model used to estimate them is given in parentheses.\n\\({\\widehat{p}}_{j}(0)\\) (MR model) Estimate of probability of detection (of objects) on the trackline for observer j (j=1 or 2). If the MR model is of the form \\({\\widehat{p}}_{j|3 - j}(y) = \\frac{exp({\\widehat{\\beta}}_{0} + {\\widehat{\\beta}}_{1}y)}{1 + exp({\\widehat{\\beta}}_{0} + {\\widehat{\\beta}}_{1}y)}\\) i.e. no covariates (except distance) then\n\\({\\widehat{p}}_{j|3 - j}(0) = \\frac{exp({\\widehat{\\beta}}_{0})}{1 + exp({\\widehat{\\beta}}_{0})}\\). Similar calculations hold if observer is included (with the coefficient for observer included) but if other covariates are included, then the function is averaged over all covariates and a more complicated formula is used (see Laake and Borchers 2004).\n\\({\\widehat{p}}_{P}(0)\\) (MR model) Estimate of probability of detection on the trackline (for both observers combined). When the MR model is simple (i.e. only contains covariates for distance (and/or observer in an IO configuration)), then \\({\\widehat{p}}_{P}(0) = {\\widehat{p}}_{1}(0) + {\\widehat{p}}_{2}(0) - {\\widehat{p}}_{1}(0){\\widehat{p}}_{2}(0)\\). This equation does not hold when other covariates are included in the MR model; in this case, the intercept is obtained by averaging over all covariates (see Laake and Borchers 2004).\n\\({\\widehat{p}}_{P.DS}\\) (DS model) Estimate of probability of detection (over all distances) for both observers pooled\n\\({\\widehat{p}}_{1.DS}\\) (DS model) Estimate of probability of detection (over all distances) for observer 1\n\\({\\widehat{p}}_{P}\\) Estimate of probability of detection (over all distances) for both observers pooled taking into account imperfect detection on the trackline. Under the point independence assumption \\({\\widehat{p}}_{P} = \\ {\\widehat{p}}_{P}(0).{\\widehat{p}}_{P.DS}\\)\n\\({\\widehat{p}}_{1}\\) Estimate of probability of detection (over all distances) for observer 1 taking into imperfect account detection on the trackline. Under the point independence assumption \\({\\widehat{p}}_{1} = \\ {\\widehat{p}}_{1}(0){\\widehat{p}}_{1.DS}\\)\n\\({\\widehat{N}}_{cIO} = \\frac{n_{P}}{\\widehat{p}}\\) Estimated number of groups in the covered region for IO configuration\n\\({\\widehat{N}}_{cT} = \\frac{n_{1}}{{\\widehat{p}}_{1}}\\) Estimated number of groups in the covered region for Trial configuration\n\\(\\widehat{N}\\) Estimated number of individuals in the study region\n\\({\\widehat{N}}_{g}\\) Estimated number of groups, or clusters, in the study region\n\\(E\\left\\lbrack \\widehat{s} \\right\\rbrack = \\frac{\\widehat{N}}{{\\widehat{N}}_{g}}\\) Expected group size\nOUTPUT FROM MRDS\nAs mentioned previously, output in Distance for Windows goes to the Results tab. In R, the user needs to request model output using summary and plot commands. The exact information provided in the output will depend on the observer configuration and the independence assumption used. Here, we follow the order of the output used in Distance for Windows results tab.\nSummary of the observations\nThe numbers of detected objects are tabulated and also plotted in histograms. The tabulated data in Distance for Windows is found on the Observation/Summary tab and the histograms are on the Observation/Plot tab. In R use det.tables(ddfmodel) to list these tables (for a fitted MRDS model called ddfmodel) and to plot the histograms use plot(det.tables(ddfmodel)).\nThe tabulated data consist of the numbers of objects detected in each perpendicular distance interval used for the histograms for observer 1, observer 2, pooled and duplicate detections. This information is useful because it illustrates the data that underpin the fitted models. Table 1 shows an example of tabulated data for three distance intervals (there are many more intervals in the actual data) and provides a summary of the key bits of information that can be found in these tables.\nThe data used for the histograms of the number of objects are described in Table 2a.\nDetection function summary\nIn Distance for Windows, the detection function(s) is summarised on the Detection Fct/Summary tab: in R use summary(ddfmodel). The estimated coefficients of the fitted models are listed along with the probabilities of detection. The information included in the output depends on the configuration and independence assumption chosen:\n\nfor an IO point independence model see Figure 1;\nfor an IO full independence model see Figure 2;\nfor a trial point independence model see Figure 3 and\nfor a trial full independence model see Figure 4.\n\nThe detection function plots are described in Table 2b. In R use plot(ddfmodel). The intercepts of the fitted models are also given in Table 2a.\nDensity and abundance estimates\nDensity and abundance estimates (if requested) are found in Distance on the ‘Density Estimates and associated quantities’ tab. In R, data frames containing information on strata (region.data), transects (sample.data) and observations (obs.data) are required as input to obtain density and abundance estimates using the dht function i.e. dht(ddfmodel,region.data,sample.data,obs.data). These data link objects (detections) to transects and transects to survey regions and provide data on search effort and area of survey strata.\nSummary data and estimates (density and abundance) are provided for groups (clusters) and individuals and also expected group size for each strata. In ‘Summary statistics’ (for either clusters or individuals) the number of objects (n) will depended on whether an IO configuration (nP) or a trial configuration (n1) is selected.\nREFERENCES\nBuckland ST, DR Anderson, KP Burnham. JL Laake, DL Borchers and L Thomas (2001) Introduction to Distance Sampling. Oxford University Press, Oxford, UK\nBurt ML, DL Borchers, KJ Jenkins and TA Marques (2014) Using mark-recapture distance sampling methods on line transect surveys. Methods in Ecology and Evolution. doi: 10.1111/2041-210X.12294\nLaake J, DL Borchers, L Thomas, D Miller and J Bishop (2019) mrds: Mark-Recapture Distance Sampling. R package version 2.2.1\nLaake JL and DL Borchers (2004) Methods for incomplere detection at distance zero. Advanced Distance Sampling (eds) ST Buckland DR Anderson, KP Burnham. JL Laake, DL Borchers and L Thomas, Oxford University Press, Oxford, UK\nMarques FFC and ST Buckland (2004) Covariates models for the detection function. Advanced Distance Sampling (eds) ST Buckland DR Anderson, KP Burnham. JL Laake, DL Borchers and L Thomas, Oxford University Press, Oxford, UK\nR Core Team (2016). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.\nThomas L, ST Buckland, EA Rexstad, JL Laake, S Strindberg, SL Hedley, JRB Bishop, TA Marques and KP Burnham (2010) Distance software: design and analysis of distance sampling surveys for estimating population size.  Journal of Applied Ecology 47: 5-14.  DOI: 10.1111/j.1365-2664.2009.01737.x\nTable 1 Observation summary tables: a) key information extracted from b) example output. The symbol ‘:’ indicates that there are more distance intervals in the actual data.\n\nSummary of key information for three distance intervals and on which Results tab the information is found in Distance for Windows.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterval\nn1\nn2\nnD\nnP\np1|2\np2|1\nResults tab\n\n\n\n\n[0, 5.17]\n78\n85\n66\n97\n0.776\n0.846\nObservation/ Summary\n\n\n[5.17, 10.3]\n40\n42\n30\n52\n0.714\n0.750\n\n\n\n[10.3, 15.5]\n41\n40\n30\n51\n0.750\n0.731\n\n\n\n:\n\n\n\n\n\n\n\n\n\nTotal\n1094\n1102\n816\n1380\n0.7401\n0.7451\nDetection Fct/Summary\n\n\n\n1 Not given in Detection function summary – these are Petersen estimates\n\nExample output\n\nObserver 1 detections\nDetected\nMissed Detected (n1)\n[0,5.17] 19 78 (19 + 78 = 97 = np)\n(5.17,10.3] 12 40\n(10.3,15.5] 10 41\n:\nObserver 2 detections\nDetected\nMissed Detected (n2)\n[0,5.17] 12 85 (12 + 85 = 97 = np)\n(5.17,10.3] 10 42\n(10.3,15.5] 11 40\n:\nDuplicate detections (nD)\n[0,5.17] (5.17,10.3] (10.3,15.5] (15.5,20.7] (20.7,25.9] (25.9,31]\n66 30 30 53 35 46\n:\nPooled detections (nP)\n[0,5.17] (5.17,10.3] (10.3,15.5] (15.5,20.7] (20.7,25.9] (25.9,31]\n97 52 51 86 64 64\n:\nObserver 1 detections of those seen by Observer 2\nMissed Detected Prop. Detected (p1|2)\n[0,5.17] 19 66 0.7764706 (66/(19+66) = 66/85 = 0.7764)\n(5.17,10.3] 12 30 0.7142857\n(10.3,15.5] 10 30 0.7500000\n:\nObserver 2 detections of those seen by Observer 1\nMissed Detected Prop. Detected (p2|1)\n[0,5.17] 12 66 0.8461538 (66/(12+66)= 66/78 = 0.8461)\n(5.17,10.3] 10 30 0.7500000\n(10.3,15.5] 11 30 0.7317073\n:\nTable 2 Information plotted for each observer configuration (IO and Trial). A dash indicates that figure is not plotted for that observer configuration.\n\nObservation/Plot tab\n\n\n\n\n\n\n\n\n\n\n\nSummary plot #\n\nHistogram colour\n\nNumbers of objects for who?\n\n\n\n\nIO\nTrial\nBlack\nBlue\n\n\n\n1\n1\nnP\nn1\nPooled and observer 1\n\n\n2\n2\nnP\nn2\nPooled and observer 2\n\n\n3\n3\nnD\n\nDuplicates\n\n\n4\n-\nnP\n\nPooled\n\n\n5\n4\nn2\nnD\nObserver 2 and duplicates\n\n\n6\n-\nn1\nnD\nObserver 1 and duplicates\n\n\n\n\nDetection Function/Plot tab\n\nThe points on the plots are estimated values for individual detections and the line is the average value (taking into account all covariates in the model).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDetection probability\n\n\nplot #\n\n\n\nHistogram\n\n\nWhich model used for independence assumption?\n\n\nIntercept of the line is at?\n\n\n\n\nIO\n\n\nTrial\n\n\nPoint\n\n\nFull\n\n\n\n\n\n\n1\n\n\n1\n\n\nScaled n1\n\n\nDS model\n\n\nMR model\n\n\np̂1(0)\n\n\n\n\n2\n\n\n-\n\n\nScaled n2\n\n\nDS model\n\n\nMR model\n\n\np̂2(0)\n\n\n\n\n3\n\n\n-\n\n\nScaled nP\n\n\nDS model\n\n\nMR model\n\n\np̂P(0)\n\n\n\n\n4\n\n\n-\n\n\nScaled nD\n\n\nDS model\n\n\nMR model\n\n\n?\n\n\n\n\n5\n\n\n2\n\n\np1|2\n\n\nMR model\n\n\nMR model\n\n\np̂1(0)\n\n\n\n\n6\n\n\n-\n\n\np2|1\n\n\nMR model\n\n\nMR model\n\n\np̂2(0)\n\n\n\n\n\nFigure 1 Example detection function summary for an IO point independence model: MR model contains distance and a factor for observer (this is a Petersen model); the DS model uses a hazard rate form with no covariates (apart from distance).\nSummary for io.fi object (MR model)\nNumber of observations : 1380 nP\nNumber seen by primary : 1094 n1\nNumber seen by secondary : 1102 n2\nNumber seen by both : 816 nD\nAIC : 2652.566\nConditional detection function parameters:\nestimate se\n(Intercept) 1.334518220 0.107556941\ndistance -0.004843781 0.001385673\nobserver2 0.028370866 0.084224532\nEstimate SE CV\nAverage primary p(0) 0.7915870 0.017744426 0.02241627 \\({\\widehat{p}}_{1}(0)\\)\nAverage secondary p(0) 0.7962288 0.017526680 0.02201211 \\({\\widehat{p}}_{2}(0)\\)\nAverage combined p(0) 0.9575314 0.006690943 0.00698770 \\({\\widehat{p}}_{P}(0)\\)\nSummary for ds object (DS model)\nNumber of observations : 1380 nP\nDistance range : 0 - 150\nAIC : 13612.95\nDetection function:\nHazard-rate key function\nDetection function parameters\nScale coefficient(s):\nestimate se\n(Intercept) 4.425513 0.05855335\nShape coefficient(s):\nestimate se\n(Intercept) 0.6851006 0.1247415\nEstimate SE CV\nAverage p 0.6924608 0.02190796 0.03163784 \\({\\widehat{p}}_{P.DS}\\)\nSummary for io object (MR + DS model combined)\nTotal AIC value : 16255.2 = 2652.566 + 13612.95\nEstimate SE CV\nAverage p 0.663053 0.02148313 0.03240032 \\({\\widehat{p}}_{P}\\)\nN in covered region 2081.281660 74.86672579 0.03597145 \\({\\widehat{N}}_{cIO}\\)\nFigure 2 Example detection function summary for an IO full independence model: MR model contains covariates distance and observer (as a factor).\nSummary for io.fi object (MR model)\nNumber of observations : 1380 nP\nNumber seen by primary : 1094 n1\nNumber seen by secondary : 1102 n2\nNumber seen by both : 816 nD\nAIC : 16481.92\nConditional detection function parameters:\nestimate se\n(Intercept) 1.334518220 0.107556941\ndistance -0.004843781 0.001385673\nobserver2 0.028370866 0.084224532\nEstimate SE CV\nAverage p 0.9233260 0.007189382 0.007786396 \\({\\widehat{p}}_{P}\\)\nAverage primary p(0) 0.7915870 0.016272902 0.020557313 \\({\\widehat{p}}_{1}(0)\\)\nAverage secondary p(0) 0.7962288 0.016064551 0.020175796 \\({\\widehat{p}}_{2}(0)\\)\nAverage combined p(0) 0.9575314 0.005181690 0.005411509 \\({\\widehat{p}}_{P}(0)\\)\nN in covered region 1494.5966586 16.110394124 0.010779091 \\({\\widehat{N}}_{cIO}\\)\nFigure 3 Example detection function summary for a Trial point independence model: DS model uses a hazard rate form with no covariates in the scale parameter; MR model contains distance only.\nSummary for trial.fi object (MR model)\nNumber of observations : 1380 nP\nNumber seen by primary : 1094 n1\nNumber seen by secondary (trials) : 1102 n2\nNumber seen by both (detected trials): 816 nD\nAIC : 1260.732\nConditional detection function parameters:\nestimate se\n(Intercept) 1.279522703 0.124363484\ndistance -0.003960919 0.001732436\nEstimate SE CV\nAverage primary p(0) 0.7823685 0.02117513 0.02706542 \\({\\widehat{p}}_{1}(0)\\)\nSummary for ds object (DS model)\nNumber of observations : 1094 n1\nDistance range : 0 - 150\nAIC : 10770.29\nDetection function:\nHazard-rate key function\nDetection function parameters\nScale coefficient(s):\nestimate se\n(Intercept) 4.442346 0.05685968\nShape coefficient(s):\nestimate se\n(Intercept) 0.8301251 0.133593\nEstimate SE CV\nAverage p 0.6936849 0.02237827 0.03226 \\({\\widehat{p}}_{1.DS}\\)\nSummary for trial object (MR + DS model combined)\nTotal AIC value = 12031.02 = 10770.29 + 1260.73\nEstimate SE CV\nAverage p 0.5427173 0.02285377 0.04210991 \\({\\widehat{p}}_{1}\\)\nN in covered region 2015.7825642 94.36006632 0.04681064 \\({\\widehat{N}}_{cT}\\)\nFigure 4 Example detection function summary for a Trial full independence model: MR model contains distance only.\nSummary for trial.fi object (MR model)\nNumber of observations : 1380 nP\nNumber seen by primary : 1094 n1\nNumber seen by secondary (trials) : 1102 n2\nNumber seen by both (detected trials): 816 nD\nAIC : 12185.06\nConditional detection function parameters:\nestimate se\n(Intercept) 1.279522703 0.124363484\ndistance -0.003960919 0.001732436\nEstimate SE CV\nAverage p 0.7262759 0.01521478 0.02094904 \\({\\widehat{p}}_{1}\\)\nAverage primary p(0) 0.7823685 0.01621225 0.02072201 \\({\\widehat{p}}_{1}(0)\\)\nN in covered region 1506.3146420 39.23133973 0.02604458 \\({\\widehat{N}}_{cT}\\)"
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#the-golf-tee-data-and-distance-project",
    "href": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#the-golf-tee-data-and-distance-project",
    "title": "Analysis of double platform data",
    "section": "The Golf Tee Data and Distance Project",
    "text": "The Golf Tee Data and Distance Project\nThe data come from a survey of clusters of golf tees in grass, conducted by undergraduate statistics students at the University of St Andrews. For the purposes of this exercise, we will assume that all the data were collected on one 210 metre long transect line out to a width of 4 metres (both sides), and that this comprises the study region. There were 250 clusters of tees in the study region and 760 individual tees in total.\nThe population was independently surveyed by two observer teams. The following data were recorded for each detected group: perpendicular distance, cluster size, observer (team 1 or 2), “sex” (males are yellow, females green and golf tees occur in single-sex clusters), and “exposure”. Exposure was a subjective judgement of whether the cluster was substantially obscured by grass (exposure=0) or not (exposure=1). The lengths of grass varied along the transect line, and the grass was also slightly more yellow along one part of the line compared with the rest.\nThe data are stored in the distance project GolfteesExercise.zip. Open the project within Distance, and click on the Analyses tab. Two Analyses have been set up for you:\n\n“FI – MR dist” is a model with only perpendicular distance as a covariate in the mark recapture detection function model.\n“FI – MR dist + size + sex + exp” is a model with distance, cluster size, sex and exposure as covariates in the mark recapture detection function model.\n\nHave a look at the Properties of the Model Definition for each of these models, and familiarize yourself with the contents of each tab.\n\nBoth specify trial configuration (see the Method button in the Detection Function tab) – team 2 setting up trials for team 1. That’s the configuration we’ll use throughout this exercise, but for this dataset an independent observer configuration would also be fine and you’re welcome to explore that yourself.\nBoth are full independence models (we’ll try point independence models later in the exercise).\nThe difference between the two is that they have different MR (mark recapture) models – see the MR Model button in the Detection Function tab. Notice that the names used in the model formulae are not the same as the field names in the Data tab – for example the “Perp distance” field is called “distance” in the formulae. (Recall from the lecture that some fields get renamed when the data are sent out to R for analysis. You can find out what renaming has been done in the Log tab once you’ve run an analysis – we’ll do this in a second.)"
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#golf-tee-survey-analyses",
    "href": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#golf-tee-survey-analyses",
    "title": "Analysis of double platform data",
    "section": "Golf Tee Survey Analyses",
    "text": "Golf Tee Survey Analyses\n\nEstimation of p: distance only\nRun the “FI - MR dist” analysis. Once it is run, look in the Analysis Details Log tab, and find the part of the log where Distance tells you how it has renamed the fields. It’s useful to know where this is in case you need reminding of what names to use when specifying formulae. Now look in the Results tab. Does the fit of the model look good?\nHere’s what the plots are:\n\nThe plots on the pages headed “Summary 1” and “Summary 2” show the histograms of distances for detections by either, or both, observer. The shaded regions show the number for observer 1 and observer 2, respectively.\nThe plot on the page ‘Summary 3’ shows the histograms of distances for duplicates (detected by both observers).\nThe plot on page headed ‘Summary 4’ shows the histograms of distances for observer 2. The shaded regions indicate the number of duplicates – for example, the shaded region is the number of clusters in each distance bin that were detected by Observer 1 given that they were also detected by Observer 2 (the “|” symbol in the plot legend means “given that”). [Note that if an ‘io’ configuration had been chosen, there would also be a plot showing the duplicates overlaid onto distances detected by Observer 1; in a ‘trial’ configuration we are only interested in Observer 2 setting up trials.]\nQ-Q plot – this has exactly the same interpretation as a Q-Q plot in single platform analyses.\nThe plot on the page headed “Detection probability 1” shows a histogram of Observer 1 detections with the estimated Observer 1 detection function overlaid on it. The dots show the estimated detection probability for all Observer 1 detections.\nThe plot on the page headed “Detection probability 2” shows the proportion of Obs 2’s detections that were detected by Obs 1 (also see the “Summary” page). The fitted line is the estimated detection function for Obs 1 (given detection by Obs 2). Dots are estimated detection probabilities for each Obs 1 detection.\n\nIs there evidence of unmodelled heterogeneity? What do these results tell you about the estimates of p (average detection probability) and p(0) (detection probability at 0 distance)?\n\n\nEstimation of p: distance and other variables\nRun “FI - MR dist+size+sex+exp”. Can you explain the differences between the estimates of p and the abundance estimates between the two models? Which model would you use to estimate abundance? To decide, look at the goodness-of-fit test and AIC values from each model."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#golf-tee-survey-analyses-1",
    "href": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#golf-tee-survey-analyses-1",
    "title": "Analysis of double platform data",
    "section": "Golf Tee Survey Analyses",
    "text": "Golf Tee Survey Analyses\n\nSpecifying new models\nThe size covariate is the least significant of the covariates in the model “FI – MR dist + size + sex + exp” – its estimate is 0.078 with SE 0.183. Create a new model definition and analysis without this covariate. Does it have a lower AIC?\nYou can also try some models with interaction terms. For example, you would specify the interaction between sex and exposure as “sex:exposure”. If you also want both sex and exposure in as main effects (which you usually do) then the notation “sex*exposure” is shorthand for “sex + exposure + sex:exposure”. Don’t try too many of these models – leave time for the next part.\n\n\nPoint independence\nAll the models we have tried so far assume full independence – i.e. that the detections are independent between platforms at all distances. A less restrictive assumption is point independence – that the detections are only independent on the line.\nDetermine whether a simple point independence model is better than a simple full independence one. Set up a new Analysis and Model Definition, and under Detection Function | Method, choose Trial, Point independence. For the MR (mark-recapture) model, specify distance as the only covariate. You now also need to specify a DS (distance sampling) model. Start with a half-normal key function and constant scale parameter (i.e. no covariates).\nRun this model, and compare it with the corresponding full independence model (i.e., the full independence model with the same MR model). Which has the lower AIC? Which has an estimate closer to the known true abundance?\nTry a point independence model that has a MR model the same as the MR model from your full independence analyses. Which has the lower AIC and bias? Finally, try some models where you introduce covariates into the scale parameter of the DS model (for example, try sex as a covariate).\nWhat is your final best model? What is the estimate of p and p(0) for this model? Was all this modelling necessary in this instance, given the value of p(0)? How else could you have obtained a robust estimate of abundance?\n\n\nGolf Tee Survey Data exploration\nIt’s worth having a look at how the data are stored for a double-observer project. Open the project, and click on the Data tab to see how the data are stored. Notice that each detected cluster appears twice in the observation layer – once for observer 1 and once for observer 2. There is a field “object” which gives a unique number to each cluster and another field “detected” which indicates whether the cluster was seen (=1) or missed (=0) by each observer. There are also fields for the other covariates: perpendicular distance, cluster size, sex and exposure. In general, covariates could also be stored in other data layers (e.g., stratum- or transect-level covariates such as habitat).\nNow click on the Survey tab and open the Survey details for “New survey”. Click on Properties to see the survey’s properties. Notice that the observer configuration is set to Double observer. We analysed these data assuming that Observer 2 was generating trials for Observer 1 but not vice versa – i.e., trial configuration, where Observer 1 is the primary and Observer 2 is the tracker. (As noted earlier, the data could also be analyzed in independent observer configuration – you are welcome to try this yourself!) Click on the Data fields tab, and notice that the Object, Observer and Detected roles are all filled by the appropriate fields – this is done by default when you are setting up a new project, if you tell Distance it is a double observer survey in the Setup Project Wizard."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#the-crabeater-seal-data-and-distance-project",
    "href": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#the-crabeater-seal-data-and-distance-project",
    "title": "Analysis of double platform data",
    "section": "The Crabeater Seal Data and Distance Project",
    "text": "The Crabeater Seal Data and Distance Project\nThese data come from a helicopter survey of crabeater seals within pack-ice in the Antarctic conducted by the Australian Antarctic Division as part of their pack-ice seals program. The helicopter can only operate within a relatively short distance from the icebreaker, which acts as its base, and the ice-breaker can only go where the pack-ice is thin enough, the aerial transects cannot be randomly located. This means that design-based abundance estimation was not a valid option – abundance was estimated using density surface modelling. In this exercise, we concentrate on detection function estimation.\nThe data are stored in two distance projects: CrabbieMCDSExercise and CrabbieMRDSExercise. The first contains a multiple-covariate distances analysis of the data (assuming p(0)=1); the second contains mark-recapture distance sampling analyses of the same data.\nIn addition to distance and cluster size, the following explanatory variables are available for modelling detection probability:\n\nside: the side of the helicopter from which the seals were seen\nexp: the experience (in survey hours) of the observer\nfatigue: the number of minutes the observer has been on duty on the current flight\ngscat: group size category (1/2/≥3)\nvis: visibility category (poor/good/excellent)\nglare: Yes or No, depending on whether there was glare or not\nssmi: a measure of ice cover\naltitude: the height of the aircraft in metres\nobsname: individual observer identifier\n\nThe distance projects are set up as if the transects were random and survey area was 1,000,000 hectares. This is just a device to get Distance to produce an abundance estimate, which we can treat as a relative index of abundance."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#the-crabeater-seal-analyses",
    "href": "11-mrds/DistWin-prac/Pr11-instructions-DistWin.html#the-crabeater-seal-analyses",
    "title": "Analysis of double platform data",
    "section": "The Crabeater Seal Analyses",
    "text": "The Crabeater Seal Analyses\nThe analyses described in Borchers et al. (2006) and Southwell et al. (2007) use the point independence method. Use the analyses in the two projects to decide whether:\n\nan MCDS analysis would have been adequate (and if so, why), and\na full-independence MRDS analysis would have been adequate (and if so, why).\n\nThe projects contain the following analyses (which have already been run, since running them takes a while):\n\nMCDS like paper: MCDS model used for the MCDS component of the analysis in the papers. This one is in the CrabbieMCDSExercise project\nPI dist only: Point independence model using only distance. This and the subsequent ones are in the CrabbieMRDSExercise project.\nFI like paper: Full independence model using the MRDS model used in the papers.\nPI as in paper: Point independence model using the same MCDS model and MRDS model as used in the papers.\n\nIf you have time, you might want to try other models and see if you can do better than the model “PI as in paper”. (However, see Tip2, below, for a timesaver.)\nTip1: remember in Distance for Windows you queue up multiple models to run one after the other (by clicking the Run button while another analysis is already running – the new model will get added to the queue), so you could always set up a series of candidate models and let them run while you do something else!\nTip2: Because the dataset is large, analyses with lots of covariates take a long time to run – and so the dataset is not very conducive to rapid learning. Hence we’ve set up a data filter that selects just 1 in 5 of the observations (it’s called “trunc 700 folds 1 and 5” – the folds 1 and 5 comes from the fact that there is a column “fold” in the dataset that divides the data into 10 equal subsets (“folds”), so we can select 1/5th of the data through the Data Selection tab of the Data Filter by selecting “fold IN (1, 5)”). If you look in the analysis set “Folds 1 and 5” you’ll see that we’ve run the three models using this subset of the data. You might want to do your further covariate selection using this subset also, just to speed up the runs. Of course, you might well find a different model is selected by AIC compared to that in the paper, because you are now only working with 1/5th of the data"
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#estimation-of-p-fi---mr-dist-and-fi---mr-distsizesexexp",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#estimation-of-p-fi---mr-dist-and-fi---mr-distsizesexexp",
    "title": "Analysis of double platform data",
    "section": "Estimation of p; FI - MR dist and FI - MR dist+size+sex+exp",
    "text": "Estimation of p; FI - MR dist and FI - MR dist+size+sex+exp\nThe model with more covariates is modelling more of the heterogeneity in detection probability and so should be less biased. This seems to be the case: the estimated N for the model “FI – MR dist + size + sex + exp” is closer to truth than the “FI – MR dist” (recall that there were really 760 individual tees).\nThere is some evidence of unmodelled heterogeneity in both cases (noticeably more so with the ‘FI – MR dist’ in that the fitted detection function for observer 1 declines slower than the histogram as distance increases (Figure 1). This is less the case for the ‘FI – MR dist + size + sex + exp’ model – not surprisingly, because it models the effect of more variables causing the heterogeneity.\nBoth are still somewhat negatively biased, but the 95% confidence intervals do include the true value1. Both models are reasonable fits to the data (non-significant chi-squares, Cramer-von Mises and KS tests) – although the fit is noticeably worse in the case of the ‘FI – MR dist’ model. The ‘dist + size + sex + exp’ model has a much lower AIC and so is to be preferred on that basis."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#specifying-new-models",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#specifying-new-models",
    "title": "Analysis of double platform data",
    "section": "Specifying new models",
    "text": "Specifying new models\nI tried two models with interaction terms (although many other models could have been tried) – one with a sex times exposure interaction (‘FI – MR dist + sex x exp’) and one with a three-way interaction between distance, sex and exposure (‘FI – MR dist x sex x exp’). The former had a slightly lower AIC than the model with the 3-way interaction. The estimated N from this model was also closer to truth (Table 1)."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#point-independence",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#point-independence",
    "title": "Analysis of double platform data",
    "section": "Point independence",
    "text": "Point independence\nThe point independence model with just Distance in the MR model (‘PI – MR dist DS hn’) had a slightly lower AIC than the corresponding full independence model (‘FI – MR dist’), however, the abundance estimate is much closer to truth (Table 1). We can expect the bias to be smaller for the point independence model because the assumption of independence only on the trackline is weaker than assuming independence everywhere.\nComparing the previous best FI model (‘FI – MR dist + sex x exp’) with the equivalent PI model with no covariates in the DS part (‘PI – MR dist + sex x exp DS hn’), the former had a lower AIC, and similarly for a model with no interactions in the MR model (model ‘PI – MR dist + sex + exp DS hn’). The difference in bias between FI and PI models is less for these models with more covariates, as there is less unmodelled heterogeneity that can contribute to non-independence away from the trackline (i.e., violation of the independence assumption of the FI model).\nAdding sex as a covariate into the DS model (‘PI – MR dist + sex + exp DS hn sex’) produced a model with the lowest AIC yet, and also the closest estimate (695) to true N. This model was found to have lowest AIC in a comparison of 40 models in Chapter 6 (Buckland et al., 2004, Table 6.5). The estimate is still less than the true N indicating, perhaps, some unmodelled heterogeneity on the trackline (or perhaps just bad luck – remember that this is only one survey).\nWas this complex modelling worthwhile? In this case, the estimated p(0) for the best model was 0.96. If we ran a conventional distance sampling analysis (i.e. single platform), pooling the data from the two observers, we should get a very robust estimate of N. We did this in the final analysis in the solutions Distance project GolfteeSolutions.zip.\n\nTo do this, we selected only records where Observer = 1 regardless of whether they were seen by that observer or not – i.e. we use data from both observers combined, who will have a higher p(0) than either of them on their own.\n\nThe estimate of N from the CDS analysis is 706 – slightly closer to truth than our best MRDS model. (You can do the same thing in the mrds package in R, by specifying in the ddf function method = “ds”. Once you have a fitted detection function you can then pass this into the dht function to get an abundance estimate. The resulting estimate of abundance of clusters is identical.\n\nassuming you used the same half-normal key function we used in the Distance project; the estimate of abundance of individual is slightly different because Distance for Windows uses cluster size regression by default, while ddf does not.\n\nTable 1 Summary of the fitted models, AIC and estimated individual abundance, N.\n\n\n\nModel name\nAIC\nEstimated N\n\n\n\n\nFI-MR dist\n452.81\n593\n\n\nFI-MR dist + size + sex + exp\n407.40\n642\n\n\nFI-MR dist + sex * exp\n403.80\n682\n\n\nFI-MR dist * sex * exp\n404.46\n679\n\n\nPI-MR dist DS hn\n452.03\n688\n\n\nPI-MR dist + sex * exp DS hn\n406.34\n675\n\n\nPI-MR dist + sex + exp DS hn\n406.04\n666\n\n\nPI-MR dist + sex + exp DS hn sex\n399.26\n695\n\n\n\nFigure 1 Fitted detection function using the models ‘FI-MR dist’ (left plot) and ‘FI-MR dist+size+sex+exp’ (right plot)."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#distance-in-windows",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#distance-in-windows",
    "title": "Analysis of double platform data",
    "section": "Distance in Windows",
    "text": "Distance in Windows\n\nThe MCDS goodness-of-fit statistics all indicate adequate fit (none are significant at the 5% level) and the abundance estimate is not far from that for the PI model used in the paper: 3,820 with CI (3,168; 4,606) vs 3,969 with CI (3,274; 4,812) from the MRDS model. Use of an MCDS model results in an estimate only 4% lower than that from the MRDS model and the CVs for the two models are very similar - so the MCDS model seems pretty adequate.\n\nWhy is this? It is because the MRDS estimate of p(0) for both platforms combined is 0.988 – i.e. the conventional distance sampling assumption that p(0) is 1 is very nearly satisfied.\n\nThe full-independence (FI) MRDS analysis is not adequate. The very poor fit to the combined distance data is clear from the plots headed “Detection Probability 1”, “Detection Probability 2” and “Detection Probability 3”, which show the distribution of Obs1, Obs2 and combined Obs detections, with the Obs 1, Obs 2 and combined detection functions overlaid. It can also be clearly seen from the Q-Q plot and the Kolmogorov-Smirnov goodness-of-fit test statistic.\n\nThe plot headed “Detection Probability 4” shows the duplicates and the duplicated detection function. The plots headed “Detection Probability 5” and “Detection Probability 6” are the conditional detection functions for each observer overlaid on the respective duplicate proportions.\nNotice that the conditional detection function fits are pretty good. So the model seems adequate for modelling the conditional probability of one observer detecting a group, given the other observer detected it, but not for the unconditional probability of detecting a group (which is what we want to estimate). This implies that there is something about detected groups that tends to make them more detectable than other groups (i.e., some unmodelled heterogeneity). So treating the conditional detection functions as if they applied to undetected groups will lead to positive bias in estimating their detection probability and negative bias in estimating abundance.\nThe severe negative bias in the abundance estimate is apparent from a comparison of the FI and PI estimates: the former is 2,509 with CI (2,070; 3,041), which is substantially lower than even the MCDS estimate, while the latter is 3,969 with CI (3,274; 4,812).\nNote that PI estimators cannot be lower than the corresponding CDS or MCDS estimators.\nOne final note: FI abundance estimates will not in general be lower than MCDS estimates, even when the FI assumption fails, as it has here. In particular, when p(0) is low, the FI estimator is likely to be less biased than the MCDS estimator. In this example, p(0) is very close to 1, so the MCDS estimator has small bias."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#distance-in-r",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#distance-in-r",
    "title": "Analysis of double platform data",
    "section": "Distance in R",
    "text": "Distance in R\nFitting a simple MRDS model (i.e. DS half-normal key with MR model distance only) gives an MRDS estimate of p(0) for both platforms combined of 0.988. The \\(p(0)\\) for each observer team was 0.89. Note that the estimate is the same for each team because ‘observer’ was not included in the MR model.\n\nCrabeater seals with MCDS\nThe detection function model with the lowest AIC includes side of plane and visibility – this is the distance sampling model used in Borchers et al. (2006) and Southwell et al. (2007).\n\n\n\nFormula\nAIC\n\n\n\n\nNo covars\n22304.01\n\n\nside\n22304.74\n\n\nvis\n22311.34\n\n\nside + vis\n22300.13\n\n\n\nFrom the simple MRDS analyses, we see that the conventional distance sampling assumption, that p(0) is 1, is very nearly satisfied – and so in this case an MCDS analysis may have been adequate. However, a double platform survey and analysis were required to establish this."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#distance-for-windows",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#distance-for-windows",
    "title": "Analysis of double platform data",
    "section": "Distance for Windows",
    "text": "Distance for Windows\n\nThe MCDS goodness-of-fit statistics all indicate adequate fit (none are significant at the 5% level) and the abundance estimate is not far from that for the PI model used in the paper: 3,820 with CI (3,168; 4,606) vs 3,969 with CI (3,274; 4,812) from the MRDS model. Use of an MCDS model results in an estimate only 4% lower than that from the MRDS model and the CVs for the two models are very similar - so the MCDS model seems pretty adequate.\n\nWhy is this? It is because the MRDS estimate of p(0) for both platforms combined is 0.988 – i.e. the conventional distance sampling assumption that p(0) is 1 is very nearly satisfied.\n\nThe full-independence (FI) MRDS analysis is not adequate. The very poor fit to the combined distance data is clear from the plots headed “Detection Probability 1”, “Detection Probability 2” and “Detection Probability 3”, which show the distribution of Obs1, Obs2 and combined Obs detections, with the Obs 1, Obs 2 and combined detection functions overlaid. It can also be clearly seen from the Q-Q plot and the Kolmogorov-Smirnov goodness-of-fit test statistic.\n\nThe plot headed “Detection Probability 4” shows the duplicates and the duplicated detection function. The plots headed “Detection Probability 5” and “Detection Probability 6” are the conditional detection functions for each observer overlaid on the respective duplicate proportions.\nNotice that the conditional detection function fits are pretty good. So the model seems adequate for modelling the conditional probability of one observer detecting a group, given the other observer detected it, but not for the unconditional probability of detecting a group (which is what we want to estimate). This implies that there is something about detected groups that tends to make them more detectable than other groups (i.e., some unmodelled heterogeneity). So treating the conditional detection functions as if they applied to undetected groups will lead to positive bias in estimating their detection probability and negative bias in estimating abundance.\nThe severe negative bias in the abundance estimate is apparent from a comparison of the FI and PI estimates: the former is 2,509 with CI (2,070; 3,041), which is substantially lower than even the MCDS estimate, while the latter is 3,969 with CI (3,274; 4,812).\nNote that PI estimators cannot be lower than the corresponding CDS or MCDS estimators.\nOne final note: FI abundance estimates will not in general be lower than MCDS estimates, even when the FI assumption fails, as it has here. In particular, when p(0) is low, the FI estimator is likely to be less biased than the MCDS estimator. In this example, p(0) is very close to 1, so the MCDS estimator has small bias."
  },
  {
    "objectID": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#distance-package-in-r",
    "href": "11-mrds/DistWin-prac/Pr11-solution-DistWin.html#distance-package-in-r",
    "title": "Analysis of double platform data",
    "section": "Distance package in R",
    "text": "Distance package in R\nFitting a simple MRDS model (i.e. DS half-normal key with MR model distance only) gives an MRDS estimate of p(0) for both platforms combined of 0.988. The \\(p(0)\\) for each observer team was 0.89. Note that the estimate is the same for each team because observer was not included in the MR model.\n\nCrabeater seals with MCDS\nThe detection function model with the lowest AIC includes side of plane and visibility – this is the distance sampling model used in Borchers et al. (2006) and Southwell et al. (2007).\n\n\n\nFormula\nAIC\n\n\n\n\nNo covars\n22304.01\n\n\nside\n22304.74\n\n\nvis\n22311.34\n\n\nside + vis\n22300.13\n\n\n\nFrom the simple MRDS analyses, we see that the conventional distance sampling assumption, that p(0) is 1, is very nearly satisfied – and so in this case an MCDS analysis may have been adequate. However, a double platform survey and analysis were required to establish this."
  },
  {
    "objectID": "09-clusters/clusterslanding.html",
    "href": "09-clusters/clusterslanding.html",
    "title": "Analysis of animals in groups",
    "section": "",
    "text": "Some species travel in groups. The detection of these species is often made of a group. It is standard practice to record the perpendicular distance to the centre of the group and the number of individuals in the group. Conventional distance sampling could then be applied to produce an estimate of the number of groups in the study area.\nConverting that estimate of group abundance into an estimate of abundance of individuals creates a challenge. Simply multiplying the estimated abundance of groups by the average size of the detected groups produces biased estimates of abundance of individuals. As the following lecture describes, there is a problem of size bias. The average size of the detected groups is a positively biased estimate of the average size of groups in the population, leading to estimates of individual abundance that is too large.\nThe practicals in this model address this situation. You are to analyse data from a survey of Risso’s dolphins (Grampus griseus) in the eastern Atlantic Ocean. Not only will you produce estimates of group abundance, but also estimates of abundance of individuals. To prevent bias in the estimates of abundance of individuals, you will apply methods that avoid the size bias problem.\n\n Photo by Wynand Uys on Unsplash"
  },
  {
    "objectID": "09-clusters/clusterslanding.html#analysis-of-animals-in-groups",
    "href": "09-clusters/clusterslanding.html#analysis-of-animals-in-groups",
    "title": "Analysis of animals in groups",
    "section": "",
    "text": "Some species travel in groups. The detection of these species is often made of a group. It is standard practice to record the perpendicular distance to the centre of the group and the number of individuals in the group. Conventional distance sampling could then be applied to produce an estimate of the number of groups in the study area.\nConverting that estimate of group abundance into an estimate of abundance of individuals creates a challenge. Simply multiplying the estimated abundance of groups by the average size of the detected groups produces biased estimates of abundance of individuals. As the following lecture describes, there is a problem of size bias. The average size of the detected groups is a positively biased estimate of the average size of groups in the population, leading to estimates of individual abundance that is too large.\nThe practicals in this model address this situation. You are to analyse data from a survey of Risso’s dolphins (Grampus griseus) in the eastern Atlantic Ocean. Not only will you produce estimates of group abundance, but also estimates of abundance of individuals. To prevent bias in the estimates of abundance of individuals, you will apply methods that avoid the size bias problem.\n\n Photo by Wynand Uys on Unsplash"
  },
  {
    "objectID": "09-clusters/clusterslanding.html#lecture-materials",
    "href": "09-clusters/clusterslanding.html#lecture-materials",
    "title": "Analysis of animals in groups",
    "section": "Lecture materials",
    "text": "Lecture materials\n\nLecture discussion\n\nSlides\n\n\nVideo"
  },
  {
    "objectID": "09-clusters/clusterslanding.html#exercise-materials",
    "href": "09-clusters/clusterslanding.html#exercise-materials",
    "title": "Analysis of animals in groups",
    "section": "Exercise materials",
    "text": "Exercise materials\n\n\n\nUsing R package\n\nVideo introduction\n\n\nInstructions\n\n\nSolution and discussion\n\n\nVideo summary\n\n\n\n\nUsing Distance for Windows\n\nVideo introduction\n\n\nInstructions\n\n\nSolution and discussion\n\n\nVideo summary"
  },
  {
    "objectID": "09-clusters/clusterslanding.html#supplemental-materials",
    "href": "09-clusters/clusterslanding.html#supplemental-materials",
    "title": "Analysis of animals in groups",
    "section": "Supplemental materials",
    "text": "Supplemental materials\n\nNo supplements\n\nNo supplemental material"
  },
  {
    "objectID": "09-clusters/R-prac/Pr9-instructions.html#data-organisation",
    "href": "09-clusters/R-prac/Pr9-instructions.html#data-organisation",
    "title": "Analysis of animals that occur in groups",
    "section": "Data organisation",
    "text": "Data organisation\nFrom the first few lines of the Risso’s data frame that organising the data for animals detected in groups is very similar to animals detected individually. There remains Region.Label, Area, Sample.Label, Effort and distance fields. To this is added the field size for each detection, representing the size of the detected group."
  },
  {
    "objectID": "09-clusters/R-prac/Pr9-instructions.html#focus-on-group-size",
    "href": "09-clusters/R-prac/Pr9-instructions.html#focus-on-group-size",
    "title": "Analysis of animals that occur in groups",
    "section": "Focus on group size",
    "text": "Focus on group size\nRisso’s dolphins (and many other species), travel in aggregations. Explore the distribution of observed group sizes in this data set.\n\naveobs.size &lt;- round(mean(risso$size),2)\nhistlabel &lt;- paste0(\"Observed group sizes of Risso's dolphins\\n\",\n                    \"Mean observed size= \", aveobs.size)\nhist(risso$size, nc=15, main=histlabel, xlab=\"Observed group size\")\n\n\n\n\nIt is important to note that the mean size of detected groups is 7.21, because we know the mean size of groups in the population was 6.\nWe can explore the possible reason for this difference between mean size in the population and mean size in our sample by creating this diagnostic plot. This plot should be a standard part of any analysis that involves detection of animals in groups.\n\nwith(risso,scatter.smooth(distance, size, pch=20,\n                          lwd=2, xlab=\"Detection distance\",\n                          ylab=\"Size of detected group\",\n                          main=\"Risso's survey\\nDiagnostic plot\"))\n\n\n\n\nFigure 1: Diagnostic plot for existance of size bias in group size estimates.\n\n\n\n\nNote in Figure 1 the absence of small groups at distances beyond ~2nm. Beyond ~4nm, not groups are detected that are smaller than 6. This pattern is indicative of bias in the estimated size of the average group. We will see the consequence of this bias in average group size when we perform a naive analysis."
  },
  {
    "objectID": "09-clusters/R-prac/Pr9-instructions.html#naive-analysis",
    "href": "09-clusters/R-prac/Pr9-instructions.html#naive-analysis",
    "title": "Analysis of animals that occur in groups",
    "section": "Naive analysis",
    "text": "Naive analysis\nIf we apply distance sampling to the perpendicular distances recorded to the centre of the detected groups, we will estimate the abundance of groups (\\(\\widehat{N_s}\\)), corrected for imperfect detectability. To convert abundance of groups (\\(\\widehat{N_s}\\)) to abundance of individuals (\\(\\widehat{N}\\)), we multiply:\n\\[\\widehat{N_s} \\times \\bar{s} = \\widehat{N}\\] where {s} is the average size of groups in the population (Buckland et al., 2015, sec. 6.3.1.3). We do not know the average size of groups in the population, but rather we estimate it by using the average size of our detected groups.\nBecause there exists a field named size in the risso data frame, the ds software knows observations were of groups. Output from ds will create estimates both of \\(\\widehat{N_s}\\) and \\(\\widehat{N}\\) (if study region Area is also provided), and companion estimates \\(\\widehat{D_s}\\) and \\(\\widehat{D}\\).\nFit the three key function detection models to the data in the usual manner and perform model selection to choose a most appropriate model (also perform absolute goodness of fit, courtesy of `summarize_ds_models).\n\nlibrary(Distance)\nnaive.uniform &lt;- ds(data=risso, key=\"unif\", adjustment=\"cos\")\nnaive.hn &lt;- ds(data=risso, key=\"hn\", adjustment = \"cos\") \nnaive.hr &lt;- ds(data=risso, key=\"hr\", adjustment = NULL) # no adjustments for simplicity\nknitr::kable(summarize_ds_models(naive.uniform, naive.hn, naive.hr, output=\"plain\"),\n             digits=3, caption=\"Model selection for models not considering size bias.\")\n\nAll three models fit. It is a close AIC contest between the unadjusted hazard rate and the half normal with one adjustment. For our purposes, let’s focus upon the hazard rate model, although the inference will be virtually identical were we to use the half normal model for our inference.\n\nplot(naive.hr, nc=40, main=\"Hazard rate model with no adjustments\")\n\nA brief look at the data summary coming from the fitted model. Evaluate the number of detections and numbers of replicate transects.\n\nknitr::kable(naive.hr$dht$clusters$summary)\n\nExamine the estimates of abundance of clusters (\\(\\widehat{N_s}\\)) from the hazard rate model. Note how the following code carefully extracts estimates only for clusters. We could do the same for the estimated density of clusters, but omit that here.\n\nknitr::kable(naive.hr$dht$clusters$N)\n\nCompare this estimate against the number of clusters (4333) in the population we simulated.\nHow well did this model estimate the number of individuals (\\(\\widehat{N}\\)) in the population?\n\nknitr::kable(naive.hr$dht$individuals$N)\n\nCompare this estimate against the number of individuals in the population (26000). The reason for this lies in the estimation of average group size in the population, also estimated in the model object by the average size of detected groups:\n\nknitr::kable(naive.hr$dht$Expected.S)\n\nCompare this estimate against the estimate we produced during our exploratory data analysis plotting the histogram of sizes of observed groups: 7.21."
  },
  {
    "objectID": "09-clusters/R-prac/Prac9_solution.html",
    "href": "09-clusters/R-prac/Prac9_solution.html",
    "title": "Analysis of animals that occur in groups solution",
    "section": "",
    "text": "Solution\n\n\n\nAnalysis of animals that occur in groups"
  },
  {
    "objectID": "09-clusters/R-prac/Pr9-instructions.html",
    "href": "09-clusters/R-prac/Pr9-instructions.html",
    "title": "Analysis of animals that occur in groups",
    "section": "",
    "text": "The data for this practical is simulated (so we can compare estimates derived from our analysis with truth), but the simulation is based upon a series of surveys conducted in the eastern Atlantic 2010-2019 by the U.S. National Marine Fisheries Service for a programme called Atlantic Marine Assessment Program for Protected Species (Palka et al., 2017). Estimates of abundance of Risso’s dolphins (Grampus griseus) were derived from these survey data and reported in Roberts et al. (2022).\nBecause the data are simulated, we know the following characteristics of the population we are studying:\n\n\n\nAttribute\ntrue value\n\n\n\n\nNumber of groups\n4333\n\n\nAverage group size\n6\n\n\nNumber of individuals\n26000\n\n\n\nYou will contrast the estimates you derive from your analyses against these known values."
  },
  {
    "objectID": "09-clusters/R-prac/Pr9-instructions.html#description-of-survey",
    "href": "09-clusters/R-prac/Pr9-instructions.html#description-of-survey",
    "title": "Analysis of animals that occur in groups",
    "section": "",
    "text": "The data for this practical is simulated (so we can compare estimates derived from our analysis with truth), but the simulation is based upon a series of surveys conducted in the eastern Atlantic 2010-2019 by the U.S. National Marine Fisheries Service for a programme called Atlantic Marine Assessment Program for Protected Species (Palka et al., 2017). Estimates of abundance of Risso’s dolphins (Grampus griseus) were derived from these survey data and reported in Roberts et al. (2022).\nBecause the data are simulated, we know the following characteristics of the population we are studying:\n\n\n\nAttribute\ntrue value\n\n\n\n\nNumber of groups\n4333\n\n\nAverage group size\n6\n\n\nNumber of individuals\n26000\n\n\n\nYou will contrast the estimates you derive from your analyses against these known values."
  },
  {
    "objectID": "09-clusters/R-prac/Pr9-instructions.html#analysis-adjusting-for-size-bias-problem",
    "href": "09-clusters/R-prac/Pr9-instructions.html#analysis-adjusting-for-size-bias-problem",
    "title": "Analysis of animals that occur in groups",
    "section": "Analysis adjusting for size bias problem",
    "text": "Analysis adjusting for size bias problem\nBecause we recognize that the size of clusters influences probability of their inclusion in our sample, we can incorporate this concept in the detection function model we construct. As introduced in Module 8, we can add covariates in addition to perpendicular distance into our detection function models. This is what we will do to perhaps overcome the size bias problem.\n\n\n\n\n\n\nAside: average group size as derived parameter\n\n\n\n\n\n\nWhen using group size as a covariate we no longer estimate average group size directly from observed group sizes. Instead, the ds function uses something called Horwitz-Thompson-like estimators to first estimate the abundance of groups. Then, using the same estimation approach, ds estimates the abundance of individuals.\nAfter the two estimates \\(\\widehat{N_s}\\) and \\(\\widehat{N}\\) are produced, their ratio is computed. This ratio is a less biased estimate of average group size in the population.\nSee the next-to-last slide in Module 8 lecture\n\n\n\n\n\nclever.hn &lt;- ds(data=risso, key=\"hn\", formula = ~size) \nclever.hr &lt;- ds(data=risso, key=\"hr\", formula = ~size)\n\nContrast AIC scores between hazard rate and half normal models with and without the size covariate.\n\nAIC(naive.hn, naive.hr, clever.hn, clever.hr)\n\nCompare relative and absolute fit of hazard rate and half normal key functions that include the size covariate.\n\nknitr::kable(summarize_ds_models(clever.hn, clever.hr, output=\"plain\"), digits=3,\n             caption = \"Comparison of hazard rate and half normal models incorporating group size as covariate.\")\n\nUsing the best model based upon AIC, repeat the model output interrogation you conducted (above) with the naive models: examine the estimates of \\(\\widehat{N_s}\\), \\(\\widehat{N}\\) and \\(E(s)\\) (defined as the expected value of group size in the population):\n\nknitr::kable(clever.hr$dht$clusters$N)\n\nCompare this estimate against the number of clusters (4333) in the population we simulated.\nHow well did this model estimate the number of individuals (\\(\\widehat{N}\\)) in the population?\n\nknitr::kable(clever.hr$dht$individuals$N)\n\nCompare this estimate against the number of individuals in the population (26000). The reason for this lies in the estimation of average group size in the population, also estimated in the model object by the average size of detected groups:\n\nknitr::kable(clever.hr$dht$Expected.S)"
  },
  {
    "objectID": "09-clusters/DistWin-prac/Pr9-instructions-DistWin.html",
    "href": "09-clusters/DistWin-prac/Pr9-instructions-DistWin.html",
    "title": "Analysis of animals that occur in groups",
    "section": "",
    "text": "Analysis of animals that occur in groups"
  },
  {
    "objectID": "09-clusters/R-prac/Prac9_solution.html#naive-analysis",
    "href": "09-clusters/R-prac/Prac9_solution.html#naive-analysis",
    "title": "Analysis of animals that occur in groups solution",
    "section": "Naive analysis",
    "text": "Naive analysis\nIf we apply distance sampling to the perpendicular distances recorded to the centre of the detected groups, we will estimate the abundance of groups (\\(\\widehat{N_s}\\)), corrected for imperfect detectability. To convert abundance of groups (\\(\\widehat{N_s}\\)) to abundance of individuals (\\(\\widehat{N}\\)), we multiply:\n\\[\\widehat{N_s} \\times \\bar{s} = \\widehat{N}\\] where {s} is the average size of groups in the population (Buckland et al., 2015, sec. 6.3.1.3). We do not know the average size of groups in the population, but rather we estimate it by using the average size of our detected groups.\nBecause there exists a field named size in the risso data frame, the ds software knows observations were of groups. Output from ds will create estimates both of \\(\\widehat{N_s}\\) and \\(\\widehat{N}\\) (if study region Area is also provided), and companion estimates \\(\\widehat{D_s}\\) and \\(\\widehat{D}\\).\nFit the three key function detection models to the data in the usual manner and perform model selection to choose a most appropriate model (also perform absolute goodness of fit, courtesy of summarize_ds_models).\n\nrissogithub &lt;- \"https://raw.githubusercontent.com/distanceworkshops/async2024-2/main/09-clusters/R-prac/Risso_survey.csv\"\nrisso &lt;- read.csv(rissogithub)\naveobs.size &lt;- round(mean(risso$size),2)\nlibrary(Distance)\nnaive.uniform &lt;- ds(data=risso, key=\"unif\", adjustment=\"cos\")\nnaive.hn &lt;- ds(data=risso, key=\"hn\", adjustment = \"cos\") \nnaive.hr &lt;- ds(data=risso, key=\"hr\", adjustment = NULL) # no adjustments for simplicity\nknitr::kable(summarize_ds_models(naive.uniform, naive.hn, naive.hr, output=\"plain\"),\n             digits=3, caption=\"Model selection for models not considering size bias.\")\n\n\nModel selection for models not considering size bias.\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nKey function\nFormula\nC-vM \\(p\\)-value\nAverage detectability\nse(Average detectability)\nDelta AIC\n\n\n\n\n2\nnaive.hn\nHalf-normal with cosine adjustment term of order 2\n~1\n0.981\n0.548\n0.047\n0.000\n\n\n3\nnaive.hr\nHazard-rate\n~1\n0.981\n0.531\n0.070\n1.264\n\n\n1\nnaive.uniform\nUniform with cosine adjustment terms of order 1,2\nNA\n0.902\n0.581\n0.044\n2.497\n\n\n\n\n\nAll three models fit. It is a close AIC contest between the unadjusted hazard rate and the half normal with one adjustment. For our purposes, let’s focus upon the hazard rate model, although the inference will be virtually identical were we to use the half normal model for our inference.\n\nplot(naive.hr, nc=40, main=\"Hazard rate model with no adjustments\")\n\n\n\n\nA brief look at the data summary coming from the fitted model. Evaluate the number of detections and numbers of replicate transects.\n\nknitr::kable(naive.hr$dht$clusters$summary)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegion\nArea\nCoveredArea\nEffort\nn\nk\nER\nse.ER\ncv.ER\n\n\n\n\nregion\n1300000\n143145.6\n15600\n265\n12\n0.0169872\n0.0008546\n0.0503073\n\n\n\n\n\nExamine the estimates of abundance of clusters (\\(\\widehat{N_s}\\)) from the hazard rate model. Note how the following code carefully extracts estimates only for clusters. We could do the same for the estimated density of clusters, but omit that here.\n\nknitr::kable(naive.hr$dht$clusters$N)\n\n\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\nTotal\n4531.354\n642.8413\n0.1418652\n3431.138\n5984.361\n230.2186\n\n\n\n\n\nCompare this estimate against the number of clusters (4333) in the population we simulated.\nHow well did this model estimate the number of individuals (\\(\\widehat{N}\\)) in the population?\n\nknitr::kable(naive.hr$dht$individuals$N)\n\n\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\nTotal\n32677.05\n4770.298\n0.1459831\n24537.47\n43516.69\n186.701\n\n\n\n\n\nCompare this estimate against the number of individuals in the population (26000). The reason for this lies in the estimation of average group size in the population, also estimated in the model object by the average size of detected groups:\n\nknitr::kable(naive.hr$dht$Expected.S)\n\n\n\n\nRegion\nExpected.S\nse.Expected.S\n\n\n\n\nTotal\n7.211321\n0.138989\n\n\n\n\n\nCompare this estimate against the estimate we produced during our exploratory data analysis plotting the histogram of sizes of observed groups: 7.21."
  },
  {
    "objectID": "09-clusters/R-prac/Prac9_solution.html#analysis-adjusting-for-size-bias-problem",
    "href": "09-clusters/R-prac/Prac9_solution.html#analysis-adjusting-for-size-bias-problem",
    "title": "Analysis of animals that occur in groups solution",
    "section": "Analysis adjusting for size bias problem",
    "text": "Analysis adjusting for size bias problem\nBecause we recognize that the size of clusters influences probability of their inclusion in our sample, we can incorporate this concept in the detection function model we construct. As introduced in Module 8, we can add covariates in addition to perpendicular distance into our detection function models. This is what we will do to perhaps overcome the size bias problem.\n\n\n\n\n\n\nAside: average group size as derived parameter\n\n\n\n\n\n\nWhen using group size as a covariate we no longer estimate average group size directly from observed group sizes. Instead, the ds function uses something called Horwitz-Thompson-like estimators to first estimate the abundance of groups. Then, using the same estimation approach, ds estimates the abundance of individuals.\nAfter the two estimates \\(\\widehat{N_s}\\) and \\(\\widehat{N}\\) are produced, their ratio is computed. This ratio is a less biased estimate of average group size in the population.\nSee the next-to-last slide in Module 8 lecture\n\n\n\n\n\nclever.hn &lt;- ds(data=risso, key=\"hn\", formula = ~size) \nclever.hr &lt;- ds(data=risso, key=\"hr\", formula = ~size)\n\nContrast AIC scores between hazard rate and half normal models with and without the size covariate.\n\nAIC(naive.hn, naive.hr, clever.hn, clever.hr)\n\n          df      AIC\nnaive.hn   2 759.8031\nnaive.hr   2 761.0671\nclever.hn  2 740.7369\nclever.hr  3 737.3162\n\n\nCompare relative and absolute fit of hazard rate and half normal key functions that include the size covariate.\n\nknitr::kable(summarize_ds_models(clever.hn, clever.hr, output=\"plain\"), digits=3,\n             caption = \"Comparison of hazard rate and half normal models incorporating group size as covariate.\")\n\n\nComparison of hazard rate and half normal models incorporating group size as covariate.\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nKey function\nFormula\nC-vM \\(p\\)-value\nAverage detectability\nse(Average detectability)\nDelta AIC\n\n\n\n\n2\nclever.hr\nHazard-rate\n~size\n0.880\n0.503\n0.067\n0.000\n\n\n1\nclever.hn\nHalf-normal\n~size\n0.423\n0.614\n0.032\n3.421\n\n\n\n\n\nUsing the best model based upon AIC, repeat the model output interrogation you conducted (above) with the naive models: examine the estimates of \\(\\widehat{N_s}\\), \\(\\widehat{N}\\) and \\(E(s)\\) (defined as the expected value of group size in the population):\n\nknitr::kable(clever.hr$dht$clusters$N)\n\n\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\nTotal\n4779.932\n659.8679\n0.1380496\n3645.556\n6267.288\n202.2487\n\n\n\n\n\nCompare this estimate against the number of clusters (4333) in the population we simulated.\nHow well did this model estimate the number of individuals (\\(\\widehat{N}\\)) in the population?\n\nknitr::kable(clever.hr$dht$individuals$N)\n\n\n\n\nLabel\nEstimate\nse\ncv\nlcl\nucl\ndf\n\n\n\n\nTotal\n27449.21\n2743.127\n0.0999347\n22541.21\n33425.84\n148.0588\n\n\n\n\n\nCompare this estimate against the number of individuals in the population (26000). The reason for this lies in the estimation of average group size in the population, also estimated in the model object by the average size of detected groups:\n\nknitr::kable(clever.hr$dht$Expected.S)\n\n\n\n\nRegion\nExpected.S\nse.Expected.S\n\n\n\n\nTotal\n5.742594\n0.4046648\n\n\n\n\n\n\n\n\n\n\n\nConclusion\n\n\n\n\n\n\nEstimation of number of clusters (\\(\\widehat{N_s}\\)) is close to the truth when not including cluster size as a covariate.\nHowever, average size of clusters in the sample is an over-estimate of the average size of groups in the population.\n\nThis is because small groups at great distances are not detected, hence not included in the sample.\n\nBecause of this bias in estimate average cluster size, the estimate of number of individuals in the population (\\(\\widehat{N}\\)) is positively biased.\nThis size bias can be reduced by incorporating cluster size as a covariate in the detection function.\n\nWhen this was done, the estimated number of individuals in the population (\\(\\widehat{N}\\)) was closer to the true population size.\n\nIn general, the effect of size bias is magnified as the variability of cluster sizes in the population increases.\nThere is another way of dealing with size bias, regressing ln(cluster size) against estimated detection probability for the detection distance \\(\\widehat{g(x)}\\). This method is implemented in the Distance for Windows software."
  },
  {
    "objectID": "09-clusters/DistWin-prac/Pr9-instructions-DistWin.html#description-of-survey",
    "href": "09-clusters/DistWin-prac/Pr9-instructions-DistWin.html#description-of-survey",
    "title": "Analysis of animals that occur in groups",
    "section": "Description of survey",
    "text": "Description of survey\nThe data for this practical is simulated (so we can compare estimates derived from our analysis with truth), but the simulation is based upon a series of surveys conducted in the eastern Atlantic 2010-2019 by the U.S. National Marine Fisheries Service for a programme called Atlantic Marine Assessment Program for Protected Species (Palka et al., 2017). Estimates of abundance of Risso’s dolphins (Grampus griseus) were derived from these survey data and reported in Roberts et al. (2022).\nBecause the data are simulated, we know the following characteristics of the population we are studying:\n\n\n\nAttribute\ntrue value\n\n\n\n\nNumber of groups\n4333\n\n\nAverage group size\n6\n\n\nNumber of individuals\n26000\n\n\n\nYou will contrast the estimates you derive from your analyses against these known values."
  },
  {
    "objectID": "09-clusters/DistWin-prac/Pr9-instructions-DistWin.html#import-data-into-distance-for-windows",
    "href": "09-clusters/DistWin-prac/Pr9-instructions-DistWin.html#import-data-into-distance-for-windows",
    "title": "Analysis of animals that occur in groups",
    "section": "Import data into Distance for Windows",
    "text": "Import data into Distance for Windows\nPrevious DistWin practicals have provided you with a DistWin project in archive (.zip) format. For this practical, the survey data exist as a comma delimited file (CSV). Before you begin analysis, you will import the file into DistWin. Download the .csv file onto your computer by following this link and save it into a directory you can easily relocate.\n\n\n\n\n\n\nSetup methods\n\n\n\n\n\n\n\nSetup units\n\n\n\n\n\n\n\n\n\nImport source\n\n\n\n\n\n\n\nImport destination\n\n\n\n\n\n\n\n\n\nImport file format\n\n\n\n\n\n\n\nImport file structure\n\n\n\n\n\n\n\n\n\nImport finalise\n\n\n\n\n\n\nOpen Distance for Windows, indicate you want to start a new project, specify the project will analyse data from a survey already completed. You will then indicate it is a line transect survey, with a single observer. The .csv file contains perpendicular distance measurements of clusters of Risso’s dolphins (setup methods above).\nIndicate perpendicular distances and transect lengths are measured in kilometers and study region size is specified in square kilometers (setup units above).\nSkip the next (multipliers) project setup screen. Move to the Data Import Wizard. Specify the .csv file location you downloaded to your computer previously (import source above).\nThe .csv file contains information about the Stratum layer, Sample layer and Observation layer, just as is indicated in the default data import screen as shown (import destination above).\nSpecify the use of the comma as delimiter between fields and that the first row of the .csv file contains field names and not data, therefore the first row should not be imported (import file format above).\nThe next screen asks for definition of each field to be imported into DistWin. As a time-saving feature, the fields in the .csv file are in the order expected by DistWin: stratum fields, sample fields and observation fields. Ticking the box at top left identifies all fields for import (import file structure above).\nThe final screen shows the status of rows of the data file coming into the DistWin project (import finalise above)."
  },
  {
    "objectID": "09-clusters/DistWin-prac/Pr9-instructions-DistWin.html#construct-models",
    "href": "09-clusters/DistWin-prac/Pr9-instructions-DistWin.html#construct-models",
    "title": "Analysis of animals that occur in groups",
    "section": "Construct models",
    "text": "Construct models\n While the focus of this practical is not examining different key function models, start with the basic idea of fitting three key function models to the Risso’s data set. For each of the three key function models, estimate the average cluster size in the population using the first two methods described above (a) as mean size of observed groups and b) using the regression approach). Specification of these two approaches is determined by the radio buttons chosen (figure at right).\nIn addition, employ the third method (adding group size to the detection function model). This method cannot be applied to models with a uniform key function because that model lacks a scale parameter (see covariate lecture for a reminder). When constructing the detection function models using the Cluster size covariate, it is simplest to turn off adjustment terms. \nYou will construct 8 models with which to analyse the Risso’s dolphin survey: - uniform key - average size of detected clusters - size bias regression estimate of population average cluster size - half normal key - average size of detected clusters - size bias regression estimate of population average cluster size - Cluster size as a covariate in the detection function and no adjustments - hazard rate key - average size of detected clusters - size bias regression estimate of population average cluster size - Cluster size as a covariate in the detection function and no adjustments\nTo make comparison among models easier, adjust the Project Browser to remove estimates of density and add additional columns to the Project Browser table for Size bias cluster size (and CV), Abundance of individuals (and confidence interval bounds) as well as bootstrap confidence interval bounds of estimated abundance of individuals. This is because when cluster size is a covariate in the detection function precision of estimated individual abundance can only be determined in DistWin through use of the bootstrap.\nWhen all 8 analyses have been completed, pay particular attention to the confidence intervals on estimated individual abundance, recalling the true abundance of individuals is 26000 in this simulated population.\n\n\n\n\n\n\nIssues to consider\n\n\n\n\n\n\nNote the difference in AIC among models with and without cluster size in the detection function\nContrast the estimates of cluster size in the population among the three forms of analysis\nAre there confidence intervals on estimates of individual abundance that nearly fail to include the true value of 26000?\n\nWhat method of population average cluster size estimation do those have in common?"
  },
  {
    "objectID": "09-clusters/DistWin-prac/Pr9-solution-DistWin.html",
    "href": "09-clusters/DistWin-prac/Pr9-solution-DistWin.html",
    "title": "Analysis of animals that occur in groups",
    "section": "",
    "text": "Analysis of animals that occur in groups\n\n\n\n\n\nDistance for Windows exercise Solution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\n# params\nDelta AIC\nESW/EDR\nSz Bias CS\nSz Bias CS CV\nN\nN LCL\nN UCL\n\n\n\n\n\nhn cos average group size\n2\n22.4\n2.51\n\n\n31655\n25889\n38705\n\n\n\nunif cos size regression\n2\n24.9\n2.66\n6.3\n0.026\n26106\n21665\n31457\n\n\n\nhr poly size regression\n2\n23.9\n2.43\n6.1\n0.026\n27749\n20917\n36813\n\n\n\nhn size bootstrap\n2\n3.3\n2.81\n6.5\n0.020\n25448.62\n22786.55\n27868.41\nbootstrap\n\n\nhr size bootstrap\n3\n0\n2.27\n5.7\n0.183\n27704.15\n23342.76\n34598.29\nbootstrap\n\n\nhr poly average size\n2\n23.7\n2.43\n\n\n32673\n24666\n43278\n\n\n\nhn cos group size regression\n2\n22.4\n2.51\n6.2\n0.026\n27142\n22150\n33258\n\n\n\nunif cos average size\n2\n24.9\n2.66\n\n\n29858\n24837\n35893"
  }
]